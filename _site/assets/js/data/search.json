[
  
  {
    "title": "composer安装",
    "url": "/posts/composer-install/",
    "categories": "",
    "tags": "php, linux",
    "date": "2019-07-30 20:30:00 +0800",
    





    "snippet": "安装[root@localhost bmsource]# php -r &quot;copy(&#39;https://install.phpcomposer.com/installer&#39;, &#39;composer-setup.php&#39;);&quot;[root@localhost bmsource]# php composer-setup.php#移动到bin目录，供全局调用[root@localhost bmsource]# mv composer.phar /usr/local/bin/composer添加国内镜像#全局配置[root@localhost bmsource]# composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/#取消全局配置[root@localhost bmsource]# composer config -g --unset repos.packagist#项目配置[root@localhost bmsource]# composer config repo.packagist composer https://mirrors.aliyun.com/composer/#取消项目配置[root@localhost bmsource]# composer config --unset repos.packagist常用命令安装依赖包install需要事先创建composer.json文件,来描述项目的依赖关系。{    &quot;require&quot;: {        &quot;monolog/monolog&quot;: &quot;1.2.*&quot;    }}[root@localhost test]# composer installrequire可以使用require命令快速的安装一个依赖而不需要手动在composer.json里添加依赖信息[root@localhost test]# composer require monolog/monologupdateupdate 命令用于更新项目里所有的包，或者指定的某些包：# 更新所有依赖$ composer update# 更新指定的包$ composer update monolog/monolog# 更新指定的多个包$ composer update monolog/monolog symfony/dependency-injection# 还可以通过通配符匹配包$ composer update monolog/monolog symfony/*remove移除一个包及其依赖（在依赖没有被其他包使用的情况下），如果依赖被其他包使用，则无法移除：$ composer remove monolog/monologsearch查找包，输出包及其描述信息$ composer search monolog只输出包名可以使用 --only-name 参数：$ composer search --only-name monologshow列出当前项目使用到包的信息：# 列出所有已经安装的包$ composer show# 可以通过通配符进行筛选$ composer show monolog/*# 显示具体某个包的信息$ composer show monolog/monolog参考资料Composer 安装与使用阿里云、腾讯云推出 Composer 全量镜像了"
  },
  
  {
    "title": "图解HTTP笔记",
    "url": "/posts/tujie-http/",
    "categories": "",
    "tags": "http",
    "date": "2019-06-24 14:10:00 +0800",
    





    "snippet": "  介绍了HTTP协议报文的构成，响应状态码，请求与响应的首部字段。为了应对新场景需求的Ajax，Comet，WebSocket等技术。通过HTTPS与用户认证实现安全通信，一些常见的Web攻击技术。了解WebTCP/IP通信传输流发送端：在层与层之间传输数据时，每经过一层时必定会被打上一个该层所属的首部信息。接收端：在层与层传输数据时，每经过一层时会把对应的首部去掉。各协议与HTTP协议的关系URI与URL  URI：统一资源标识符  URL：统一资源定位符，属于URI的子集URI格式  协议名：使用http:或https:等协议方案名获取访问资源时要指定协议类型。不区分字母大小写，最后附加一个冒号:  登录信息（可选）：指定用户名和密码作为从服务器端获取资源时必要的登录信息  服务器地址：使用绝对URI必须指定待访问的服务器地址。如域名，IPv4地址，IPv6地址  服务器端口号（可选）：指定服务器连接的网络端口号  带层次的文件路径：指定服务器上的文件路径来定位特指的资源  查询字符串（可选）：针对已指定的文件路径内的资源，可以使用查询字符串传入任意参数  片段标识符（可选）：标记已获取资源的子资源简单的HTTP协议HTTP协议的作用HTTP协议用于客户端与服务端之间的通信，应用HTTP协议时，必定是一端担任客户端角色，另一端担任服务器端角色。HTTP协议的工作方式HTTP协议通过请求和响应的交换达成通信，请求从客户端发出，最后服务器端响应请求并返回。HTTP支持的方法向请求URI指定的资源发送请求报文时，采用称为方法的命令，方法名区分大小写，注意要使用大写字母。HTTP持久连接持久连接（HTTP Persistent Connections/HTTP Keep-alive）：只要客户端或服务端的任意一端没有明确提出断开连接，则保持TCP连接状态。管线化（pipelining）：不用等待每个请求的响应，直接发送下一个请求。CookieCookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态。HTTP报文内的HTTP信息HTTP报文HTTP报文：由报文首部和报文主体构成，使用CR+LF分割。客户端为请求报文，服务端为响应报文。请求报文与响应报文结构  请求行：用于请求的方法，请求的URI或HTTP版本  状态行：表明响应结果的状态码，原因短语和HTTP版本  首部字段：表示请求和响应的各种条件和属性的各类首部编码传输报文主体与实体主体HTTP报文的主体用于传输请求或响应的实体主体。  报文（message）：HTTP通信的基本单位，由8位组字节流组成，通过HTTP传输  实体（entity）：作为请求或响应的有效载荷数据被传输，由实体首部和实体主体组成常用压缩编码  gzip（GUN zip）  compress（UNIX系统的标准压缩）  deflate（zlib）  identity（不进行编码）发送多种数据类似于发送邮件时的多个附件，HTTP协议也采纳了多部分对象集合，发送的一份报文主体内可含有多类型实体。通常用在图片或文件的上传。  multipart/form-data；在Web表单文件上传时使用使用boundary字符串来划分多部分对象集合指明的各类实体。在boundary字符串指定的各个实体的起始行之前插入--标记（如:--AaB03x），而在多部分对象集合对应的字符串的最后插入--标记（如:--AaB03x--）作为结束。返回结果的HTTP状态码状态码：当客户端向服务器端发送请求时，描述返回的请求结果。            状态码分类      类别      原因短语                  1**      Informational（信息性状态码）      接收的请求正在处理              2**      Success（成功状态码）      请求正常处理完毕              3**      Redirection（重定向状态码）      需要进行附加操作以完成请求              4**      Client Error（客户端错误状态码）      服务器无法处理请求              5**      Server Error（服务端错误状态码）      服务器处理请求出错      2**成功  200 OK：从客户端发来的请求在服务器端被正常处理了  204 No Content：服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分  206 Partial Content：客户端进行了范围请求，服务器成功执行了这部分GET请求3**重定向  301 Moved Permanently：永久性重定向。请求的资源已被分配了新的URI，以后应使用新URI访问资源  302 Found：临时性重定向。请求的资源已被分配了新的URI，用户（本次）能使用新的URI访问  303 See Other：请求对应的资源存在着另一个URI，应使用GET方法重定向获取请求的资源  304 Not Modified：客户端发送附带条件（If-Match,If-Modified-Since,If-None-Match,If-Range,If-Unmodified-Since）的请求，服务器端允许请求访问资源，但条件未满足  307 Temporary Redirect：临时重定向4**客户端错误  400 Bad Request：请求报文中存在语法错误  401 Unauthorized：发送的请求需要有通过HTTP认证（BASIC认证，DIGEST认证）的认证信息  403 Forbidden：对请求资源的访问被服务器拒绝了  404 Not Found：服务器上无法找到请求的资源5**服务器错误  500 Internal Server Error：服务器端在执行请求时发生了错误  503 Service Unavailable：服务器暂时处于超负载或正在进行停机维护与HTTP协作的Web服务器虚拟主机在一台HTTP服务器上可通过虚拟主机（Virtual Host）搭建多个Web站点。通信数据转发代理代理是一种有转发功能的程序，它扮演了位于服务器和客户端中间人的角色，接收由客户端发来的请求并转发给服务器，同时接收服务器返回的响应并转发给客户端。代理的作用：利用缓存技术减少网络带宽的流量；针对特定网站进行访问控制  缓存代理（Caching Proxy）：预先将资源副本保存在代理服务器上，供请求获取  透明代理（Transparent Proxy）：转发请求或响应时，不对报文做任何加工网关网关是转发其他服务器通信数据的服务器，接收从客户端发来的请求时，它就像自己拥有资源的源服务器一样对请求处理。网关的作用：提高通信的安全性；使通信线路上的服务器提供非HTTP协议服务隧道隧道是在相隔较远的客户端与服务器之间进行中转，并保持双方通信连接的程序。隧道的作用：建立一条与其他服务器的通信线路，通过SSL加密手段，确保客户端能与服务器进行安全通信缓存缓存：代理服务器或客户端本地磁盘内保存的副本资源。缓存的有效性需要根据客户端的请求、缓存的有效性等因素，向源服务器确认资源的有效性，从而确认是否需要更新缓存。客户端缓存缓存的功能同代理服务器，缓存的位置在客户端浏览器中，同样也需要根据有效性更新缓存。HTTP首部http首部字段在客户端与服务器之间以HTTP协议进行通信的过程中，无论是请求还是响应都会使用首部字段，起到传递额外重要信息的作用。首部字段结构首部字段由首部字段名和字段值构成，使用:分隔。格式：首部字段名:字段值如：Content-Type:text/htmlKeep-Alive:timeout=5,max=1004种首部字段类型  通用首部字段（General Header Fields）：请求报文和响应报文都会使用的首部  请求首部字段（Request Header Fields）：从客户端向服务器端发送请求报文时使用的首部  响应首部字段（Response Header Fields）：从服务器端向客户端返回响应报文时使用的首部  实体首部字段（Entity Header Fields）：请求报文和响应报文的实体部分使用的首部按代理转发区分缓存代理（端到端首部 End-to-end Header）：在此类别中的首部会转发给请求/响应对应的最终接收目标，且必须保存在由缓存生成的响应中，必须被转发。非缓存代理（逐跳首部 Hop-by-hop Header）：在此类别中的首部只对单次转发有效，会因为通过缓存或代理而不再转发，如果要使用此首部需提供Connection首部字段。  属于逐跳首部的字段，除此之外都是端到端首部  Connection  Keep-Alive  Proxy-Authenticate  Proxy-Authorization  Trailer  TE  Transfer-Encoding  Upgrade通用首部字段            首部字段名      说明                  Cache-Control      控制缓存的行为              Connection      逐跳首部，连接的管理              Date      创建报文的日期时间              Pragma      报文指令              Trailer      报文末端的首部一览              Transfer-Encoding      指定报文主体的传输编码方式              Upgrade      升级为其他协议              Via      代理服务器的相关信息              Warning      错误通知      Cache-Control通过指定Cache-Control的指令，来控制缓存的工作机制。指令的参数是可选的，多个指令之间通过,分隔。Cache-Control:private,max-age=0,no-cache请求的缓存指令响应的缓存指令Connection  控制不再转发给代理的首部字段  管理持久连接（keep-alive,close）请求首部字段            首部字段名      说明                  Accept      用户代理可处理的媒体类型              Accept-Charset      优先的字符集              Accept-Encoding      优先的内容编码              Accept-Language      优先的语言（自然语言）              Authorization      Web认证信息              Expect      期待服务器的特性行为              From      用户的电子邮箱地址              Host      请求资源所在的服务器              If-Match      比较实体标记（ETag）              If-None-Match      比较实体标记（与If-Match相反）              If-Modified-Since      比较资源的更新时间              If-Unmodified-Since      比较资源的更新时间（与If-Modified-Since相反）              If-Range      资源未更新时发送实体Byte的范围请求              Max-Forwards      最大传输逐跳数              Proxy-Authorization      代理服务器要求客户端的认证信息              Range      实体的字节范围请求              Referer      对请求中URI的原始获取方              TE      传输编码的优先级              User-Agent      HTTP客户端程序的信息      Accept告知服务端用户代理能够处理的媒体类型及相对优先级，使用type/subtype格式表示，可指定多种媒体类型，使用,分隔。可用媒体类型媒体类型优先级，使用q=来表示权重值（范围：0-1）。不指定权重时，默认权重为q=1.0。当服务器提供多种内容时，优先返回权值较高的媒体类型。Authorization用户代理的认证信息。格式：Authorization:Basic 认证信息python:认证信息=base64.b64encode(&quot;%s:%s&quot; % (username,password))响应首部字段            首部字段名      说明                  Accept-Ranges      是否接收字节范围请求              Age      推算资源采集经过的时间              ETag      资源的匹配信息              Location      令客户端重定向到指定的URI              Proxy-Authenticate      代理服务器对客户端的认证信息              Retry-After      对再次发起请求的时机要求              Server      HTTP服务器的安装信息              Vary      代理服务器缓存的管理信息              WWW-Authenticate      服务器对客户端的认证信息      实体首部字段            首部字段名      说明                  Allow      资源可支持的HTTP方法              Content-Encoding      实体主体适用的编码方式              Content-Language      实体主体的自然语言              Content-Length      实体主体的大小（单位：字节）              Content-Location      替代对应资源的URI              Content-MD5      实体主体的报文摘要              Content-Range      实体主体的位置范围              Content-Type      实体主体的媒体类型              Expires      实体主体过期的日期时间              Last-Modified      资源的最后修改日期时间      Cookie首部字段            首部字段名      说明      首部类型                  Set-Cookie      开始状态管理所使用的Cookie信息(服务端-&amp;gt;客户端)      响应首部字段              Cookie      服务器接收到的Cookie信息(客户端-&amp;gt;服务端)      请求首部字段      Set-Cookie            属性      说明                  NAME=VALUE      赋予Cookie的名称和值(必填)              expires=DATE      Cookie有效期(不指定的话默认为浏览器关闭为止)              path=PATH      将服务器上文件目录作为Cookie的适用对象(默认值是设置 Cookie 时的当前目录)              domain=域名      作为Cookie适用对象的域名(默认值是设置 Cookie 时的域名)              Secure      仅在https安全通信时才会发送Cookie              HttpOnly      增加限制，使Cookie不能被JavaScript访问      HTTP的追加协议HTTP自身改进AjaxAjax（异步JavaScript与XML技术）：可异步加载数据，以达到局部更新Web页面。缺点：利用Ajax实时地从服务器获取内容，可能会导致大量的请求产生，如果服务器内容未更新，还会有很多无效请求。Comet接收到请求时，Comet先将响应挂起，当服务器端有内容更新时，再返回响应，达到实时更新的目的。缺点：为了保留响应，一次连接的持续时间变长，为了维持连接会消耗更多的资源。WebSocket由客户端发起连接，一旦建立WebSocket协议的通信连接后，所有的通信都依靠这个专用协议进行，可互相发送JSON、XML、HTML、图片等任意数据格式。  推送功能：不必等待客户端请求，就可以直接从服务端向客户端发送数据  减少通信量：只要WebSocket连接后，就可以一直通信；WebSocket的首部信息也较少为了实现WebSocket通信，在HTTP连接建立后，需要完成一次握手。#握手-请求GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket //告诉服务器现在发送的是WebSocket协议Connection: Upgrade Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== //是一个Base64encode的值，这个是浏览器随机生成的，用于验证服务器端返回数据是否是WebSocket助理Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 Origin: http://example.com#握手-响应HTTP/1.1 101 Switching Protocols Upgrade: websocket //依然是固定的，告诉客户端即将升级的是Websocket协议，而不是mozillasocket，lurnarsocket或者shitsocketConnection: Upgrade Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk= //这个则是经过服务器确认，并且加密过后的 Sec-WebSocket-Key,也就是client要求建立WebSocket验证的凭证Sec-WebSocket-Protocol: chatHTTPS安全通信HTTP的缺点  通信使用明文（不加密），内容可能会被窃听  不验证通信方的身份，有可能遭遇伪装  无法证明报文的完整性，有可能已遭篡改HTTPSHTTPS（HTTP Secure）：HTTP+通信加密+证书+完整性保护HTTPS并非是应用层的一种新协议，只是HTTP通信接口部分用SSL（Secure Socket Layer 安全套接层）和TLS（Transport Layer Security 安全层传输协议）协议代替而已。通常，HTTP直接和TCP通信，当使用SSL时，则变为先和SSL通信，再由SSL和TCP通信。所谓HTTPS，就是身披SSL协议外壳的HTTPSSL是独立于HTTP的协议，所以不光是HTTP协议，其他运行在应用层的SMTP和Telnet等协议均可配合SSL协议使用。可以说，SSL是当今世界上应用最为广泛的网络安全技术。在采用了SSL之后，HTTP就拥有了HTTPS的加密、证书和完整性保护这些功能。用户身份认证BASIC认证（基本认证）不够灵活，达不到多数Web网站期望的安全性等级（直接发送明文密码BASE64编码），因此它并不常用。DIGEST认证（摘要认证）采用质询响应方式，相比BASIC认证，密码泄露的可能性就降低了。相对HTTPS认证较弱，因此适用范围有限。SSL客户端认证借助HTTPS的客户端证书完成认证，凭借客户端证书认证，服务器可确认访问是否来自已登录的客户端。FormBase认证（表单认证）将客户端发送到服务端的账号和密码与数据库中的信息进行匹配，再借助Cookie与Session的机制来完成认证。。  Web攻击技术攻击模式主动攻击攻击者直接访问web应用，把攻击代码传入的攻击模式。主要有SQL注入攻击，OS命令攻击。被动攻击利用圈套策略执行攻击代码的攻击模式，在被动攻击过程中，攻击者不直接对目标Web应用访问发起攻击。攻击类型SQL注入攻击(主动)SQL注入（SQL Injection）是指针对Web应用使用的数据库，通过运行非法的SQL而产生的攻击。该安全隐患有可能引起极大的威胁，有时会直接导致个人信息及机密信息的泄露。  非法查看或篡改数据库内的数据  规避认证  执行和数据库服务器业务关联的程序等OS命令注入攻击(主动)OS命令注入攻击（OS Command Injection）是指通过Web应用，执行非法的操作系统命令达到攻击的目的。只要在能调用Shell函数的地方就有存在被攻击的风险。Dos攻击(主动)DoS攻击（Denial of Service attack）是一种让运行中的服务呈停止状态的攻击。有时也叫作服务停止或拒绝服务攻击  集中利用访问请求造成资源过载，资源用尽的同时，实际上也就呈停止状态  通过攻击安全漏洞使服务停止跨站脚本攻击(被动)跨站脚本攻击（Cross-Site Scripting，XSS）是指通过存在安全漏洞的Web网站注册用户的浏览器内运行非法的HTML标签或者JavaScript脚本进行攻击的一种攻击。  利用虚假输入表单骗取用户个人信息  利用脚本窃取用户的Cookie值，被害者在不知情的情况下，帮助攻击者发送恶意请求  显示伪造的文章或者图片HTTP首部注入攻击(被动)HTTP首部注入攻击（HTTP Header Injection）是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主体的一种攻击。会话管理疏忽引发的漏洞(被动)  会话劫持（Session Hijack）：攻击者通过某种手段拿到了用户的会话ID，并非法使用此会话ID伪装成用户，达到攻击的目的  会话固定攻击（Session Fixation）：强制用户使用攻击者指定的会话ID  跨站点请求伪造（Cross-Site Request Forgeries，CSRF）：攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新参考资料图解HTTPHTTP首部Connection实践浅谈php中使用websocketSwoole WebSocket"
  },
  
  {
    "title": "图解TCP/IP笔记",
    "url": "/posts/tujie-tcp-ip/",
    "categories": "",
    "tags": "tcp/ip",
    "date": "2019-05-23 14:10:00 +0800",
    





    "snippet": "网络基础知识计算机与网络发展的7个阶段年代内容说明20世纪50年代批处理Batch Processing：事先将用户程序和数据装入卡带或磁带，让计算机按照一定的顺序读取，使用户所要执行的这些程序和数据能够一并得到批量处理20世纪60年代分时系统Time Sharing System：多个终端与同一个计算机连接，允许多个用户同时使用一台计算机系统。特性：1.多路性2.独占性3.交互性4.及时性20世纪70年代计算机之间的通信20世纪80年代计算机网络的产生20世纪90年代互联网的普及2000年以互联网为中心的时代通过IP（Internet Protocol）网可将，个人电脑，手机终端，电视机，电话，相机，家用电器等结合到一起。2010年从&quot;单纯建立连接&quot;到&quot;安全建立连接&quot;协议协议是计算机与计算机之间通过网络实现通信事先达成的一种“约定”。这种“约定”使那些由不同厂商的设备、不同的CPU以及不同的操作系统组成的计算机之间，只要遵循相同的协议就能够实现通信。反之，如果使用的协议不同，就无法通信。举例说明：协议：人会的语言（如汉语，英语）通信：人的聊天数据：聊天的内容只有双方使用同样的语言，才能够互相交流。分组交换协议将大数据拆分成多个较小的包（Packet）进行传输。包=报文首部（分组序号+源主机地址+目标主机地址+数据处理规则等）+原始数据协议分层与OSI参考模型OSI的7个分层。各个分层的作用。传输方式分类面向有连接型与面向无连接型  面向有连接型：在发送数据之前，需要在收发主机之间建立一条通信线路。  面向无连接型：不要建立和断开连接，发送端可在任何时候发送数据，接收端不知道何时会接收到数据，需要定时确认是否收到数据。电路交换与分组交换  电路交换(不能共享连接)：主要用于以前的电话网络。相互通信的计算机独占一条连接的电路。  分组交换(能共享连接)：主要用于现在的TCP/IP。将发送的数据拆分成多个数据包（包含首部），按顺序发送到分组交换机（路由器），交换机将数据缓存到本地，再顺序发送给目标计算机。可共享连接。接收端数量  单播（UniCast）：1对1通信。如早期固定电话。  广播（BroadCast）：1对多通信，将消息发送给所有与主机相连的机器。如电视播放。  多播（MultiCast）：类似于广播，不过要限定一定主机作为接收端。如电视会议。  任播（AnyCast）：在特定的多个主机中选出一台进行通信。如DNS根域名解析服务器。地址  唯一性：一个地址必须明确的表示一个主体对象，在同一个通信网络中不允许有两个相同地址的通信主体存在。可对由多个设备组成的一组通信对象赋予唯一的通信地址。  层次性：便于高效的从很多地址中找出通信的目标地址。如ip地址的分层(127.0.0.1)。网络的构成要素设备作用网卡计算机联网的设备。中继器（Repeater）/1层交换机从物理层上延长网络的设备。将电缆传过来的电信号或光信号经由中继器波形调整和放大再传给另一个电缆（不能无限连接）。网桥（Bridge）/2层交换机从数据链路层上延长网络的设备。根据物理地址（MAC地址）进行处理。路由器（Router）/3层交换机通过网络层转发分组数据的设备。根据IP地址进行处理。4-7层交换机处理传输层以上各层网络传输的设备。如负载均衡器，广域网加速器，特殊应用访问加速，防火墙等。网关（Gateway）转换协议的设备。负责将从传输层到应用层的数据进行转换和转发的设备。如代理服务器TCP/IP基础知识TCP/IP出现的背景TCP/IP的标准化含义：利用IP进行通信时所必须用到的协议群的统称。TCP/IP的规范为RFC（Request For Comment），记录了协议规范内容，协议的实现和运用的相关信息，以及实验方面的信息。  RFC规范特性  开放性：允许任何人加入组织并进行讨论  实用性：先开发，再写规范，在标准确定时已经在很多设备上进行了验证RFC制定流程通常包括如下阶段TCP/IP协议分层模型TCP/IP与OSI在分层模块上稍有区别，OSI参考模型注重的是通信协议必要的功能是什么，TCP/IP主要的是在计算机上实现协议应该开发哪种程序。硬件（物理层）以太网或电话线路等物理层设备。网络接口层（数据链路层）利用以太网中的数据链路层进行通信。互联网层（网络层）互联网层使用IP协议，IP协议基于IP地址转发分包数据。  ARP（Address Resolution Protocol 地址解析协议）：从分组数据包的IP地址中解析出物理（MAC）地址。  IP（Internet Protocol 网络协议，非可靠性传输协议）：使用IP地址作为主机标识，跨越网络传送数据包，整个互联网都能收到数据。  ICMP（Internet Control Message Protocol 控制报文协议）：在IP数据包因为异常到不了目标地址时，通知发送端出现异常。    传输层  在应用程序之间实现通信。  TCP（Transmission Control Protocol 传输控制协议）：面向有连接的、可靠的、基于字节流的传输层通信协议。由于复杂的规则，不利于视频会议等场合。  UDP（User Datagram Protocol 用户数据报协议）：面向无连接的、不可靠的传输层协议。由于规则简单，可用于视频、音频等传输场合。应用层（会话层，表示层，应用层）一般在应用程序中实现了OSI模型中会话层，表示层，应用层的功能。TCP/IP应用的架构大多数属于客户端/服务端模型。  WWW：浏览器与服务端使用HTTP（HyperText Transfer Protocol，应用层）协议传输HTML（HyperText Markup Language，表示层）数据  EMail（电子邮件）：使用SMTP（Simple Mail Transfer Protocol，应用层）协议传输的MIME（表示层）邮件数据  FTP（文件传输）：使用FTP（File Transfer Protocol）协议传输文件数据，需要建立2个TCP连接，一个用于发出传输请求时用到的控制连接，一个用于传输数据时用到的数据连接  TELNET与SSH（远程登录）：登录到远程的计算机，运行那台计算机上的功能  SNMP（网络管理）：使用SNMP（Simple Network Management Protocol，应用层）协议来管理网络，管理信息可通过MIB（Management Information Base，表示层）访问TCP/IP分层模型与通信示例数据包首部每个分层中，都会对所发送的数据附加一个首部，首部中包含了该层的必要信息（如发送的目标地址以及协议相关信息），为协议提供的信息为包首部，所要发送的内容为数据。数据包传输过程通过从主机A向主机B发送电子邮件来看TCP/IP的通信过程。经过数据链路的包分组数据包经过以太网的数据链路时大致流程如下。  包首部中包含的必要信息：  1.发送端与接收端地址  2.上一层的协议类型（用于数据到接受端后向上层传递时的依据）数据链路数据链路的作用数据链路层的协议：定义了通过通信媒介（双绞线电缆、同轴电缆、光纤、电波、红外线等）直接互连的设备之间传输的规范。网络拓扑定义：网络的连接和构成的形态，分为总线型、环形，星型、网状型等数据链路的相关技术MAC地址作用：用于识别数据链路中互连的节点。MAC地址长度为48位（二进制），但是一般使用16进制表示，则为6个16进制数值连接。  第1位：单播地址（0）/多播地址（1）  第2位：全局地址（0）/本地地址（1）  第3-24位：由IEEE管理，并保证各厂商之间不重复  第25-48位：有厂商管理，并保证产品之间不重复通信介质通信介质类型：  共享介质型网络（半双工通信）：多个设备共享通信介质  非共享介质型网络（全双工通信）：多个设备不共享通信介质，直连交换机，由交换机转发数据帧共享介质型网络中的介质访问控制方式：  争用方式（Contention）：争夺获取数据传输的权利，通常是先到先得的方式占用信道发送数据  令牌传递方式：沿着令牌环发送“令牌”，获得令牌的站可以发送数据半双工通信与全双工通信区别：  半双工通信：只发送或只接收的通信方式，如无线电收发器  全双工通信：同时发送与接收的通信方式，如电话根据MAC地址转发以太网交换机：拥有多个端口的网桥，根据数据链路层中的每个帧的目标MAC地址，决定从哪个网络端口发送数据。转发表（Forwarding Table）：记录源MAC地址与接受数据的网络端口的对应关系环路检测技术  生成树方式：  源路由法：VLANVLAN：在交换机上按照端口划分出不同的网段，从而限制了广播数据的传输范围、减少了网络负载、提交了网络安全性。TAG VLAN：数据经过交换机时，加入VLAN ID可实现跨网段的数据传输。数据链路的传输方式以太网以太网连接形式：以太网帧格式：  FCS（Frame Check Sequence）：帧检测序列，用来检测数据帧是否损坏。  类型：网络层协议类型无线通信定义：通常使用电磁波、红外线、激光等方式进行传输数据。PPP定义（Point-to-Point Protocol）：点对点，即1对1的连接计算机的协议。IP协议网络层的作用作用：实现终端节点（需要直接相连）间的通信（end-to-end），可跨越多种数据链路。以外出旅行为例：  数据链路层：旅途中所需要的机票、车票、船票等，用于2个相邻目的地间的交通工具  网络层：旅途行程表，用于确定什么时候该坐哪种交通工具，从而完成整个旅程IP基础知识IP地址定义：网络层的地址，用于在连接到网络中的所有主机中识别出进行通信的目标地址。IP属于面向无连接型的传输，为了传输的可靠性，上一层的TCP采用面向有连接型的传输。  简化：面向连接比面向无连接处理相对复杂  提速：每次通信之前都要事先建立连接，会降低处理速度路由控制定义：Routing，将分组数据发送到最终目的地址的功能。不管网络多么复杂，也可以通过路由控制确定到达目标地址的通路。Hop中文叫“跳”，它是指网络中的一个区间，IP包正是在网络中一个跳间被转发。数据链路实现某一个区间（一跳）内的通信，而IP实现直至最终目标地址的通信（点对点）。为了将数据包发送给目标主机，所有主机都维护者一张路由控制表（Routing Table），该表记录IP数据在下一步应该发给哪一个路由器。IP包将根据这个路由表在各个数据链路上传输。以快递运输为例：  IP数据包：送的包裹  数据链路：送货车  网络层：送货目的地  路由控制：转运站IP地址IP地址（IPv4）在计算机内部由32位二进制表示，在日常使用中由4个10进制表示，如192.168.1.1。由“网络标识”与“主机标识”组成。  网络标识：在数据链路的每个段配置不同的值，相互连接的每个段不能重复  主机标识：同一网段内的主机标识不能重复，但网络标识必须相同IP数据包分组与合并处理每种数据链路的最大传输单元（MTU）不一定相同，当发送的报文比较大时，在路由器中会对报文进行分片，被主机接收时进行合并。IPV4与IPv6IP协议相关技术DNSDNS（Domain Name System）：管理主机名和IP地址之间对应关系的系统。ARPARP（Address Resolution Protocol）：以目标IP地址为线索，定位下一个应该接收数据分包的网络设备对应的MAC地址。如果目标主机不在同一个链路上，则可通过ARP查询下一跳路由的MAC地址。Tips：ARP只适用于IPv4，IPv6需要使用ICMPv6来探索邻居信息。RARP（Reverse Address Resolution Protocol）：从MAC地址定位IP地址的一种协议。ICMPICMP（Internet Control Message Protocol）：控制报文协议，确认IP包是否成功送达目标地址，通知在发送过程中IP包被废弃的具体原因，改善网络设置等。如ping命令，就是典型的ICMP应用。ICMP消息类型：DHCPDHCP（Dynamic Host Configuration Protocol）：动态主机配置协议，自动设置IP地址，统一管理IP地址分配。NATNAT（Network Address Translator）：在本地网络中使用私有地址，在连接互联网时转而使用全局IP地址。NAPT（Network Address Ports Translator）：除了转换IP地址，还可以转换TCP，UDP的端口。IP隧道在一个网络环境中，网络A与B使用IPv6，如果处于中间位置的网络C支持IPv4的话，网络A与网络B之间将无法直接进行通信。为了能让它们之间正常通信，需要采用IP隧道功能。IP隧道中可以将那些从网络A发过来的IPv6包统和为一个数据，再为之追加一个IPv4的首部转发给网络C，这种在网络层的首部后面继续追加网络层首部的通信方法叫做IP隧道。TCP与UDP传输层的作用TCPTCP是面向连接的，可靠的流协议。流是指不间断的数据结构，你可以把它想象成排水管道中的水流。当应用程序采用TCP发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给客户端。因此在发送端发送消息时，可以设置一个表示长度或间隔的字段信息。UDPUDP是面向无连接的，不可靠的数据报协议。TCP与UDP使用场景  TCP：用于在传输层有必要实现可靠传输的情况。因为它具备顺序控制、重发控制等机制。  UDP：用于对高速传输和实时性有较高要求的通信或广播通信。Socket在日常使用TCP或UDP时，会用到操作系统提供的类库，这种类库一般被称为API，对于TCP或UDP来说会广泛使用到套接字（Socket）的API。应用程序使用套接字时，可以设置对端的IP地址、端口号，并实现数据的发送与接收。端口号端口号用来识别同一台计算机中进行通信的不同应用程序。区分不同通信源IP地址+目标IP地址+协议号+源端口号+目标端口号端口号确定方法知名端口号  标准既定的端口号：每个端口号有固定的使用目的。知名端口号:【0-1023】。已注册但可用:【1024-49151】。  时许分配法：根据请求动态分配端口号。动态端口号:【49152-65535】TCPTCP（Transmission Control Protocol）：面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。TCP的特点及目的TCP通过检验和、序列号、确认应答、重发控制、连接管理、以及窗口控制等机制来实现可靠传输。解决了数据的破坏、重发以及分片顺序混乱等问题。通过序列号与确认应答提高可靠性  应答标记：  ACK：确认应答  NACK：非确认应答序列号：按顺序给发送数据的每一个字节标记编号。接收端查询接收数据TCP首部中的序列号和数据长度，将自己下一步需要接收的序号作为ACK返送回去。重发超时如何确定重发超时：在重发数据之前，等待ACK到来的那个特定时间间隔。通常比【往返时间+偏差时间】稍大一点，为0.5的整数倍。连接管理一个TCP连接的建立与断开，正常过程至少需要来回发送7个包才能完成，也就是常说的3次握手，2次挥手。TCP以段为单位发送数据MSS（Maximum Segment Size）：最大消息长度，用于对大数据的分割度量，数据重发时的度量。在建立TCP连接时根据通信双方接口能够适应的MSS决定（取小值）。利用窗口控制提高速度窗口大小：无需等待确认应答而可以继续发送数据的最大值。滑动窗口控制：使用缓冲区，通过对多个段同时进行确认应答来提高发送性能。缓冲区里的数据会保留到发送成功为止。窗口控制与重发控制快速的重发服务：接收端在没有收到自己所期望序号的数据时，会对之前收到的数据进行确认应答。发送端则一旦收到某个确认应答后，又连续收到3次同样的确认应答，则认为数据段已丢失，需要进行重发。流控制流控制：TCP提供了一种机制，可以让发送端根据接收端的实际接收能力动态的调整发送的数据量。拥塞控制提高网络利用率规范TCP首部UDPUDP（User Datagram Protocol）：不提供复杂的控制机制，利用IP提供面向无连接的通信服务。因此，它不会负责：流量控制、丢包重发等。  UDP应用场景：  包总量较少的通信（DNS、SNMP等）  视频、音频等多媒体通信（即时通讯）  限定于LAN等特定网络中的应用通信  广播通信（广播、多播）UDP首部  源端口号：发送端端口号，字段长16位，可为0（表示不需要返回）  目标端口号：接收端端口号，字段长16位  包长度：UDP的首部长度+数据长度。单位为字节(byte)  校验和：用于提供可靠的UDPshoubu和数据路由协议路由控制的定义路由控制：互联网是由路由器连接的网络组合而成，为了能让数据包正确到达目标主机，路由器必须在途中进行正确的转发。静态路由（Static Routing）：事先设置好路由器和主机中并将路由信息固定的一种方法。动态路由（Dynamic Routing）：让路由器协议在运行过程中自动的设置路由控制信息。路由控制范围IGP（Interior Gateway Protocol）：内部网关协议，自治系统内部动态路由采用的协议。EGP（Exterior Gateway Protocol）：外部网关协议，自治系统之间的路由控制采用的是域间路由协议。路由算法距离向量算法距离向量（Distance Vector）：根据距离（代价）和方向决定目标网络或目标主机位置的方法。链路状态算法链路状态（Link-State）：路由器在了解网络整体连接状态的基础上生成路由控制表的方法。路由协议            路由协议名      下一层协议      方式      适用范围      循环检测                  RIP      UDP      距离向量      域内      不可以              RIP2      UDP      距离向量      域内      不可以              OSFP      IP      链路状态      域内      不可以              BGP      TCP      路径向量      对外连接      可以      RIPRIP（Routing Information Protocol）：距离向量型的一种路由协议，广泛用于LAN。  广播路由：将路由控制信息定期（30秒一次）向全网广播  确定路由：RIP基于距离向量算法决定路径。距离（Metrics）的单位为“跳数”，指所经过的路由器个数。RIP希望尽可能少通过路由器将数据包转发到目标IP地址OSPFOSPF（Open Shortest Path First）：根据OSI的IS-IS协议提出的链路状态型路由协议，即使网络中环路，也能进行稳定的路由控制。BGPBGP（Border Gateway Protocol）：边界网关协议是连接不同组织机构（或者说连接不同自治系统）的一种协议。MPLS应用协议远程登录远程登录：从本地计算机登录到网络的另一个终端计算功能的应用。TELNET利用TCP的一条连接，通过连接向主机发送文字命令并在主机上执行。通常情况下TELNET客户端的命令为telnet。telnet 主机名 端口号SSHSSH（Secure SHell）：加密的远程登录系统，可加密通信内容，即使被窃听也无法破解所发送的密码，具体命令以及命令返回的结果。  可以使用更强的认证机制  可以转发文件  可以使用端口转发功能文件传输FTP：是在两个相连的计算机之间进行文件传输时使用的协议。FTP工作时需要使用2条TCP连接，一条用来控制（端口21），一条用来数据传输（端口随机分配）。电子邮件SMTP（Simple Mail Transfer Protocol）：电子邮件传输协议POP3（Post Office Protocol）：接收邮件时使用的协议邮件地址邮件地址：使用电子邮件时需要拥有的地址，相当于通信地址与姓名。数据格式MIME（Multipurpose Internet Mail Extension）：由首部和正文部分组成。如果MIME首部的“Content-Type”中指定“Multipart/Mixed”，并以“boundary==”后面的字符串作为分隔符，可将多个MIME消息组合成为一个MIME消息。这就叫做multipart。发送与接收协议SMTP：发送电子邮件的协议，使用的端口25。建立TCP连接后，在这个连接上进行控制，应答以及数据的发送。POP：从POP服务器接收邮件，需要用户验证。IMAP（Internet Mail Access Protocol）：在服务器上保存和管理邮件。WWW万维网（WWW，World Wide Web）：将互联网中的信息以超文本形式展示的系统。使用WEB浏览器来显示WWW信息。URIURL（Uniform Resource Locator）：表示互联网中资源（文件）的具体位置。  URI（Uniform Resource Identifier）：不局限于标记互联网资源，可作为所有资源的识别码。  uri schemesHTMLHTML（HyperText Markup Language）：记述Web页的一种语言（数据格式），可指定浏览器中显示文字，文字的大小和颜色等。HTTPHTML（HyperText Transfer Protocol）：Http默认使用80端口，在建立TCP连接后，在这个TCP连接上进行请求的应答以及数据报文的发送。    HTTP1.0：每一个命令和应答都会触发一次TCP连接的建立与断开  HTTP1.1：一个TCP连接上发送多个命令和应答网络管理SNMP（Simple Network Management Protocol）：基于UDP/IP的协议，管理端叫做管理器（Manager，网络终端监控），被管理端叫做代理（路由器，交换机）。MIB（Management Information Base）：SNMP中交互的信息，是在树形结构的数据库中为每个项目附件编号的一种信息结构。参考资料图解TCP/IP"
  },
  
  {
    "title": "mysql超时时间",
    "url": "/posts/timeout/",
    "categories": "",
    "tags": "mysql",
    "date": "2019-05-15 11:20:00 +0800",
    





    "snippet": "  介绍mysql中一些常用的超时时间的作用。概述通过如下命令可以获取到所有与timeout相关的配置，下面来看看这些配置大致都有什么作用。#查看会话级别（session）的变量mysql&amp;gt; show variables like &#39;%timeout%&#39;;+-----------------------------+----------+| Variable_name               | Value    |+-----------------------------+----------+| connect_timeout             | 10       || delayed_insert_timeout      | 300      || have_statement_timeout      | YES      || innodb_flush_log_at_timeout | 1        || innodb_lock_wait_timeout    | 60       || innodb_rollback_on_timeout  | OFF      || interactive_timeout         | 10       || lock_wait_timeout           | 31536000 || net_read_timeout            | 30       || net_write_timeout           | 60       || rpl_stop_slave_timeout      | 31536000 || slave_net_timeout           | 60       || wait_timeout                | 10       |+-----------------------------+----------+#查看全局级别（global）的变量mysql&amp;gt; show global variables like &#39;%timeout%&#39;;Tips：在设置变量时，如果想要在全局生效需要加入global前缀，如set global wait_timeout=20。connect_timeout定义            属性      值                  命令行格式      –connect-timeout=#              系统变量名      connect_timeout              作用域      Global              可动态配置      Yes              类型      Integer              默认值      10              最小值      2              最小值      31536000      服务器在返回错误握手信息前等待的时间，也可以说是握手超时时间。  mysql大致连接过程：  1.监听到连接请求（会进行3次握手）  2.服务端创建线程处理请求（客户端此时阻塞，等待服务端消息）  3.服务端与客户端交互验证用户名密码  4.验证通用，握手完成在整个连接握手过程中可能会出现出错，这个connect_timeout值就是指这个超时时间。测试#1.使用telnet连接[root@DEV-HROEx64 ~]# telnet localhost 3306Trying ::1...Connected to localhost.Escape character is &#39;^]&#39;.N5.7.11-log5+             -Tn)EF&amp;gt;g&#39;uQR7mysql_native_password#2.查看连接信息mysql&amp;gt; show full processlist;+-------+----------------------+--------------------+----------------+---------+------+-----------------------+-----------------------+| Id    | User                 | Host               | db             | Command | Time | State                 | Info                  |+-------+----------------------+--------------------+----------------+---------+------+-----------------------+-----------------------+| 23693 | unauthenticated user | ::1:52495          | NULL           | Connect |    4 | Receiving from client | NULL                  |+-------+----------------------+--------------------+----------------+---------+------+-----------------------+-----------------------+             #3.等待10s，服务器关闭连接Connection closed by foreign hostinteractive_timeout &amp;amp; wait_timeout定义interactive_timeout            属性      值                  命令行格式      –interactive-timeout=#              系统变量名      interactive_timeout              作用域      Global, Session              可动态配置      Yes              类型      Integer              默认值      28800              最小值      1      服务器在关闭交互式连接（客户端在通过mysql_real_connect连接时，使用CLIENT_INTERACTIVE 参数）之前等待活动的秒数。wait_timeout            属性      值                  命令行格式      –wait-timeout=#              系统变量名      wait_timeout              作用域      Global, Session              可动态配置      Yes              类型      Integer              默认值      28800              最小值      1              最大值（other）      31536000              最大值（windows）      2147483      服务器在关闭非交互式连接（客户端在通过mysql_real_connect连接时，不使用CLIENT_INTERACTIVE 参数）之前等待活动的秒数。以上2个变量都是定义服务器在自动关闭连接前等待的时间，区别是如果连接是交互式连接则使用interactive_timeout，如果连接是非交互式连接（如程序代码中的连接）则使用wait_timeout。测试交互式连接  SecureCRT，Navivat Premium等连接工具#1.设置交互连接超时时间10smysql&amp;gt; set global interactive_timeout=10;#2.退出，重新进入，当前wait_timeout=10mysql&amp;gt; show variables like &#39;%timeout%&#39;;+-----------------------------+----------+| Variable_name               | Value    |+-----------------------------+----------+| connect_timeout             | 10       || delayed_insert_timeout      | 300      || have_statement_timeout      | YES      || innodb_flush_log_at_timeout | 1        || innodb_lock_wait_timeout    | 60       || innodb_rollback_on_timeout  | OFF      || interactive_timeout         | 10       || lock_wait_timeout           | 31536000 || net_read_timeout            | 30       || net_write_timeout           | 60       || rpl_stop_slave_timeout      | 31536000 || slave_net_timeout           | 60       || wait_timeout                | 10       |+-----------------------------+----------+#3.等待10s，再执行如上命令，就会出现超时重连的信息了mysql&amp;gt; show variables like &#39;%timeout%&#39;;ERROR 2006 (HY000): MySQL server has gone awayNo connection. Trying to reconnect...Connection id:    22933Current database: *** NONE ***+-----------------------------+----------+| Variable_name               | Value    |+-----------------------------+----------+| connect_timeout             | 10       || delayed_insert_timeout      | 300      || have_statement_timeout      | YES      || innodb_flush_log_at_timeout | 1        || innodb_lock_wait_timeout    | 60       || innodb_rollback_on_timeout  | OFF      || interactive_timeout         | 10       || lock_wait_timeout           | 31536000 || net_read_timeout            | 30       || net_write_timeout           | 60       || rpl_stop_slave_timeout      | 31536000 || slave_net_timeout           | 60       || wait_timeout                | 10       |+-----------------------------+----------+非交互式连接  程序代码中连接#1.设置非交互连接超时时间20smysql&amp;gt; set global wait_timeout=20;#2.建立连接后持续查看进程mysql&amp;gt; show full processlist;+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| Id    | User       | Host                | db          | Command | Time | State    | Info                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| 22974 | hrodbadmin | 10.100.50.115:34504 | interview   | Sleep   |    1 |          | NULL                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+mysql&amp;gt; show full processlist;+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| Id    | User       | Host                | db          | Command | Time | State    | Info                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| 22974 | hrodbadmin | 10.100.50.115:34504 | interview   | Sleep   |    15 |          | NULL                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+mysql&amp;gt; show full processlist;+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| Id    | User       | Host                | db          | Command | Time | State    | Info                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| 22974 | hrodbadmin | 10.100.50.115:34504 | interview   | Sleep   |    20 |          | NULL                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+#3.当sleep超过20s后连接被自动关闭mysql&amp;gt; show full processlist;+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+| Id    | User       | Host                | db          | Command | Time | State    | Info                  |+-------+------------+---------------------+-------------+---------+------+----------+-----------------------+innodb_lock_wait_timeout &amp;amp; innodb_rollback_on_timeout定义innodb_lock_wait_timeout            属性      值                  命令行格式      –innodb-lock-wait-timeout=#              系统变量名      innodb_lock_wait_timeout              作用域      Global, Session              可动态配置      Yes              类型      Integer              默认值      50              最小值      1              最大值      1073741824      InnoDB事务等待行锁的超时时间，当一个事务尝试获取被另一个事务锁定的行时会出现，超时会出现如下错误：ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction当错误出现时，会回滚当前语句，而不是整个事务（除非设置了innodb_rollback_on_timeout）。innodb_rollback_on_timeout            属性      值                         命令行格式      –innodb-rollback-on-timeout[={OFF      ON}]              系统变量名      innodb_rollback_on_timeout                     作用域      Global                     可动态配置      No                     类型      Boolean                     默认值      OFF             默认情况下，InnoDB只回滚事务中超时的最后一条语句。如果设置了	innodb_rollback_on_timeout=ON，则事务超时将导致InnoDB中止并回滚整个事务。测试准备test表，里面包含2条数据。mysql&amp;gt; select * from test;+----+-------+| id | cname |+----+-------+|  1 | a     ||  2 | b     |+----+-------+#事务1 #1.开启事务begin;#2.加行锁select * from test where id=2 for update;#事务2 #1.开启事务begin;#2.不请求行锁delete from test where id=1;#3.请求行锁delete from test where id=2;##请求超时，出现如下错误##[Err] 1205 - Lock wait timeout exceeded; try restarting transaction#4.数据查询，id=1的数据被删除了select * from test;+----+-------+| id | cname |+----+-------+|  2 | b     |+----+-------+如果想要id=1的数据不被删除，需要在启动mysql时设置innodb_rollback_on_timeout=Onlock_wait_timeout定义            属性      值                  命令行格式      –lock-wait-timeout=#              系统变量名      lock_wait_timeout              作用域      Global, Session              可动态配置      Yes              类型      Integer              默认值      31536000              最小值      1              最大值      31536000      尝试获取元数据锁的超时时间，适用于所有使用元数据锁的语句。包括表、视图、存储过程和存储函数上的DML（select,update,delete,insert）和DDL（create,alter,drop）操作，以及锁表、用读锁刷新表和处理程序语句。测试#事务1#1.开启事务begin;#2.执行查询，获取表的元数据锁select * from test;#事务2#1.开启事务begin;#2.修改表结构的元数据（drop,alter）drop table test;##请求超时，出现如下错误##[Err] 1205 - Lock wait timeout exceeded; try restarting transactionnet_read_timeout &amp;amp; net_write_timeout定义net_read_timeout            属性      值                  命令行格式      –net-read-timeout=#              系统变量名      net_read_timeout              作用域      Global, Session              可动态配置      Yes              类型      Integer              默认值      30              最小值      1      当服务器从客户端获取数据时（如导入数据），等待从连接获取数据的超时时间。net_write_timeout            属性      值                  命令行格式      –net-write-timeout=#              系统变量名      net_write_timeout              作用域      Global, Session              可动态配置      Yes              类型      Integer              默认值      30              最小值      1      当服务器向客户端写入数据时（如执行查询），等待将数据写入连接的超时时间。总结  connect_timeout：用于连接过程中的超时控制  interactive_timeout与wait_timeout：用于连接空闲阶段的超时控制  net_read_timeout与net_write_timeout：用于连接繁忙阶段的超时控制参考资料Server System VariablesInnoDB Startup Options and System Variablesmysqltimeout知多少浅谈 DML、DDL、DCL的区别"
  },
  
  {
    "title": "Git学习-入门",
    "url": "/posts/git-study-introduction/",
    "categories": "",
    "tags": "git",
    "date": "2019-04-05 14:10:00 +0800",
    





    "snippet": "  介绍使用git中一些常用命令来进行版本管理。安装与配置windows安装下载地址从下载地址选择合适的版本下载，按照提示进行安装即可。用户配置当用户提交代码时，git服务器可知道是谁进行了操作。$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot;配置文件位置C:\\Users(用户)\\$USER\\.gitconfigSSH Key配置如果使用GitHub作为代码服务器，为了能与其进行交互，需要创建SSK key并配置到GitHub上。1.创建SSH Key#一路回车就可以$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot;#如果成功在用户目录可以看到id_rsa与id_rsa.pub文件$ ll /c/Users/zwtisme/.ssh/total 9-rw-r--r-- 1 zwtisme 197121 1823 三月   21 06:23 id_rsa-rw-r--r-- 1 zwtisme 197121  398 三月   21 06:23 id_rsa.pub2.将Key添加到GitHub右上角用户-&amp;gt;设置-&amp;gt;SSH and GPG keys-&amp;gt;New SSH Key。将id_rsa.pub里的内容填写进去。linux安装版本地址下载地址[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.21.0.tar.gz[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# tar -zxf git-2.21.0.tar.gz [root@iZwz9i8fd8lio2yh3oerizZ bmsource]# cd git-2.21.0[root@iZwz9i8fd8lio2yh3oerizZ git-2.21.0]# ./configure --prefix=/usr/local/git[root@iZwz9i8fd8lio2yh3oerizZ git-2.21.0]# make &amp;amp;&amp;amp; make install用户配置当用户提交代码时，git服务器可知道是谁进行了操作。$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot;配置文件位置/root/.gitconfigSSH Key配置如果使用GitHub作为代码服务器，为了能与其进行交互，需要创建SSK key并配置到GitHub上。1.创建SSH Key#一路回车就可以$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot;#如果成功在用户目录可以看到id_rsa与id_rsa.pub文件[root@iZwz9i8fd8lio2yh3oerizZ /]# ll /root/.sshtotal 12-rw------- 1 root root 1679 Apr  7 10:59 id_rsa-rw-r--r-- 1 root root  398 Apr  7 10:59 id_rsa.pub2.将Key添加到GitHub右上角用户-&amp;gt;设置-&amp;gt;SSH and GPG keys-&amp;gt;New SSH Key。将id_rsa.pub里的内容填写进去。创建版本库版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。版本库可以从远程仓库克隆，也可以在本地创建之后再推送到远程。克隆远程仓库#定位到本机任意目录$ cd /d/gitstudy2_tmp/#执行克隆命令$ git clone git@github.com:izwt/gitstudy2.git#进入仓库，查看状态$ cd gitstudy2/$ git statusOn branch masterYour branch is up to date with &#39;origin/master&#39;.本地创建#定位到本机任意目录$ cd /d/gitstudy2_tmp/#创建git目录$ mkdir gitstudy3$ cd gitstudy3/#将目录变为git仓库$ git init#查看状态$ git statusOn branch master本地版本库管理在实际工作中，大部分时间都是在本地版本库里进行操作。本地版本库一般分为3个部分，工作区、暂存区、本地分支库。工作区状态查看当前工作区是否有文件修改。$ git statusOn branch masterNo commits yetUntracked files:  (use &quot;git add &amp;lt;file&amp;gt;...&quot; to include in what will be committed)        file1.txt文件修改比较查看工作区文件与本地分支上的差异。$ git diffdiff --git a/file1.txt b/file1.txtindex 9f37f61..2563660 100644--- a/file1.txt+++ b/file1.txt@@ -1,3 +1,4 @@ file1 file11 file111+file1111文件添加将修改的文件添加到暂存区。#添加所有修改文件$ git add .On branch masterNo commits yetChanges to be committed:  (use &quot;git rm --cached &amp;lt;file&amp;gt;...&quot; to unstage)        new file:   file1.txt#添加某个修改文件$ git add file1.txt#添加匹配的修改文件$ git add file*文件提交将暂存区文件提交到本地分支。$ git commit -m &#39;new file1&#39;[master (root-commit) c62fa91] new file1 1 file changed, 3 insertions(+) create mode 100644 file1.txt版本提交历史查看版本所有的提交历史。$ git logcommit c83cf70958f5e9b15d5a92d2b4dd12137b669ef4 (HEAD -&amp;gt; master)Author: zwtisme &amp;lt;903628963@qq.com&amp;gt;Date:   Sun Apr 7 12:07:10 2019 +0800    change file1 1commit c62fa9142441d4da4778ceaaaa77050b7e908a83Author: zwtisme &amp;lt;903628963@qq.com&amp;gt;Date:   Sun Apr 7 11:37:14 2019 +0800    new file1#单行显示$ git log --pretty=onelinec83cf70958f5e9b15d5a92d2b4dd12137b669ef4 (HEAD -&amp;gt; master) change file1 1c62fa9142441d4da4778ceaaaa77050b7e908a83 new file1版本回退撤销工作区修改撤销工作区某个文件的修改。$ git checkout -- file1.txt如果文件已添加到暂存区，可先将文件回退到工作区，再撤销修改。#将文件从暂存区退回$ git reset HEAD file1.txt#撤销修改$ git checkout -- file1.txt回退到历史版本需要将工作区文件恢复到某个历史版本。#查看版本信息，当指向为daa07a$ git log --pretty=onelinedaa07a26f742ef888713015a99004cae8da3dae4 (HEAD -&amp;gt; master) change file1 2c83cf70958f5e9b15d5a92d2b4dd12137b669ef4 change file1 1c62fa9142441d4da4778ceaaaa77050b7e908a83 new file1#恢复到指定版本#字符串代表git上的版本号前面几个字符$ git reset --hard c83cf7#查看版本信息，已经切换到c83cf7$ git log --pretty=onelinec83cf70958f5e9b15d5a92d2b4dd12137b669ef4 (HEAD -&amp;gt; master) change file1 1c62fa9142441d4da4778ceaaaa77050b7e908a83 new file1查看版本库，历史执行命令。$ git reflogc83cf70 (HEAD -&amp;gt; master) HEAD@{0}: reset: moving to c83cf7daa07a2 HEAD@{1}: commit: change file1 2c83cf70 (HEAD -&amp;gt; master) HEAD@{2}: commit: change file1 1c62fa91 HEAD@{3}: commit (initial): new file1分支管理查看分支查看本地分支信息，*表示当前所在分支。$ git branch -av  dev    c83cf70 change file1 1* master c83cf70 change file1 1新建分支$ git branch dev2切换分支$ git checkout dev2文件贮藏如果当前分支有文件修改，且还不能提交，这时又需要新建分支进行修改，可将当前工作区贮藏起来，用于之后的恢复。$ git stashSaved working directory and index state WIP on dev: 9f666fb 冲突合并查看所有贮藏信息。$ git stash liststash@{0}: WIP on dev: 9f666fb 冲突合并恢复贮藏信息。#恢复上一个贮藏版本，自动删除贮藏信息$ git stash pop#恢复指定贮藏版本，不自动删除贮藏信息，需手动删除$ git stash apply stash@{0}删除贮藏信息。$ git stash drop stash@{0}Dropped stash@{0} (e690f81c7f33eb997476a2a24343b203993c3754)删除分支$ git branch -d dev2Deleted branch dev2 (was c83cf70).#强制删除未合并的分支$ git branch -D feature合并分支将其他分支合并到当前分支。$ git merge masterUpdating c83cf70..e67c9f6Fast-forward file1.txt | 1 + 1 file changed, 1 insertion(+)默认情况下，如果没有文件冲突，Git会使用Fast forward模式合并，这种模式下，如果删除分支，会丢掉分支信息。合并分支时，加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。$ git merge --no-ff -m &quot;merge with no-ff&quot; dev查看分支合并图。$ git log --graph --pretty=oneline --abbrev-commit解决冲突如果当前分支与需要合并的分支都对某些文件进行修改，在执行合并命令时，会提示文件冲突，需要手动解决冲突（合并文件的修改），然后再提交。#合并分支，提示文件冲突$ git merge masterAuto-merging file1.txtCONFLICT (content): Merge conflict in file1.txtAutomatic merge failed; fix conflicts and then commit the result.#查看冲突文件$ git statusOn branch devYou have unmerged paths.  (fix conflicts and run &quot;git commit&quot;)  (use &quot;git merge --abort&quot; to abort the merge)Unmerged paths:  (use &quot;git add &amp;lt;file&amp;gt;...&quot; to mark resolution)        both modified:   file1.txt#查看某个文件冲突内容#head:代表当前分支内容#master:代表需要合并的分支内容。$ cat file1.txtfile1file11file111file1111file11111&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEADfile11=======file1111&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; master#手动修改文件后提交$ git add file1.txt$ git commit -m &#39;冲突合并&#39;[dev 9f666fb] 冲突合并远程仓库克隆仓库默认只会获取master分支。#克隆$ git clone git@github.com:izwt/gitstudy2.git#分支$ git branch* master创建远程克隆如果远程上是一个空的仓库，则需要创建。1.在GitHub上创建空的仓库2.本地仓库与远程库关联$ git remote add origin git@github.com:izwt/gitstudy.git3.将本地仓库分支推送到远程#第一次git push -u origin master#之后git push origin master查看远程分支$ git remote -vorigin  git@github.com:izwt/gitstudy2.git (fetch)origin  git@github.com:izwt/gitstudy2.git (push)获取其他分支$ git checkout --track origin/devSwitched to a new branch &#39;dev&#39;Branch &#39;dev&#39; set up to track remote branch &#39;dev&#39; from &#39;origin&#39;.#或者$ git checkout -b dev origin/devSwitched to a new branch &#39;dev&#39;Branch &#39;dev&#39; set up to track remote branch &#39;dev&#39; from &#39;origin&#39;.创建分支跟踪操作过程中提示，提示分支未跟踪远程，则添加跟踪。$ git branch --set-upstream-to=origin/dev dev推送分支将本地修改的分支推送到远程。$ git push origin masterEnumerating objects: 4, done.Counting objects: 100% (4/4), done.Delta compression using up to 4 threadsCompressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 272 bytes | 68.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:izwt/gitstudy2.git   a9c0378..741bc0c  master -&amp;gt; master拉取分支从远程分支拉取最新的内容到本地分支。$ git pullremote: Enumerating objects: 4, done.remote: Counting objects: 100% (4/4), done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.From github.com:izwt/gitstudy2   a9c0378..741bc0c  master     -&amp;gt; origin/masterUpdating a9c0378..741bc0cFast-forward file1.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 file1.txt参考资料git官方文章git文档廖雪峰教程git-cheatsheet"
  },
  
  {
    "title": "RabbitMQ学习-队列数据同步",
    "url": "/posts/14-rabbitmq-study-queue-data-sync/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2019-04-01 14:10:00 +0800",
    





    "snippet": "  介绍RabbitMQ镜像集群中，镜像队列的数据同步规则。概要镜像队列集群的队列创建后默认只在一个节点上，当集群配置为镜像集群时，队列会被镜像到所有节点上。消息发布到信道后，会被投递到主队列及镜像队列中。一个镜像队列包含一个主队列（master）和多个从队列（slave）。非同步队列rabbitmq中同步（synchronised）是用来表示master和slave之间的数据状态是否一致的。如果slave包含master中的所有message，则这个slave是synchronised；如果这个slave并没有包含所有master中的message，则这个slave是unsynchronised。何时出现非同步队列新节点加入当新slave加入到镜像队列时，此时新slave是空的，而master中这时可能已有消息。假设这时master包含了10条消息，当第11条消息被添加到这个镜像队列中，新slave会从第11条消息开始接收。这时新slave就是unsynchronised状态。如果前10条消息从镜像队列中被消费掉了, 新slave会自动变成synchronised状态。旧节点重新加入当节点由于异常关闭或其他情况重启加入集群后，如果节点内有消息，那么节点就是unsynchronised状态。当出现如下情况（同样也适用于新节点加入），slave会变成synchronised状态：  master消息数为0  master中旧有的消息被消费完疑问：旧节点重新加入后，可用消息会显示为master的，此时旧节点状态可能还是未同步，内部处理机制是否是未同步的节点，是不提供服务的吗？选主模式理论上越早加入的slave节点，状态越有机会是同步的，所以rabbitmq通过这种方式选主。当master出现异常因消失时，最老的slave（状态需要为已同步）被提升成master。同步模式在设置集群策略时，可使用【ha-sync-mode】参数来控制使用手动同步（manual）还是自动同步（automatic），默认为手动同步。手动如果镜像队列被设置成manual模式，当一个slave加入或重新加入队列时的行为，队列会根据消息情况来决定是否为同步状态，否则就为未同步状态。当然也可通过命令来进行同步。#手动同步队列[root@DEV-mHRO64 redis]# rabbitmqctl sync_queue queue_name自动如果镜像队列被设置成automatic模式，当一个新slave加入或已有slave重新加入时，slave会自动同步master中的所有消息，在所有消息被同步完成之前，队列的所有操作都会被阻塞（blocking）。区别  manual：不保证数据可靠性，在某些情况下可能会丢失消息，但是保证了队列的可用性  automatic：提高了数据的可靠性，但是当有新slave加入时，可能会出现队列的暂时不可用同步测试针对上面不同的同步场景，进行相应的测试。新节点加入手动模式原有节点情况，队列中包含2条消息新加入一个节点，因为原先队列有消息，所以新slave为未同步状态队列中还在不断的增加消息当队列中旧消息消费后，新slave变为同步状态自动模式原有节点情况，队列中包含2条消息新加入一个节点，rabbitmq执行自动同步（阻塞队列使用），所以新slave为同步状态旧节点重新加入手动模式原有节点情况，队列中包含2条消息，总共有3个队列某个节点由于各种原因停止服务了，只有2个队列了队列中还在不断的消费消息当节点重新加入到集群后，为未同步状态队列中还在不断的消费消息与增加消息，当队列中旧消息消费后，节点变为同步状态自动模式原有节点情况，队列中包含2条消息，总共有3个队列某个节点由于各种原因停止服务了，只有2个队列了队列中还在不断的消费消息当节点重新加入到集群后，自动进行同步，为同步状态选主测试原有节点情况，rabbit@DEV-HROEx64为master节点。将原有master节点关闭，rabbit@DEV-mHRO64切换为master节点。在启动rabbit@DEV-HROEx64节点，此节点变成了slave节点。Tips：未同步的slave是不能选为master的，如果不存在已同步的slave，则队列将不能使用。参考资料"
  },
  
  {
    "title": "mysql-事务隔离级别",
    "url": "/posts/mysql-transaction-isolation-levels/",
    "categories": "",
    "tags": "mysql",
    "date": "2019-03-28 14:10:00 +0800",
    





    "snippet": "  介绍mysql中事务并发时可能出现的问题及事务隔离级别。概述mysql事务的四大特性ACID，即原子性（automicity）、一致性(insistency)、隔离性(isolation)、持久性(durability)。隔离性最为重要，如果没有设置隔离级别，就可能会出现脏读、不可重复读、幻读。MySQL默认是innodb引擎，默认的隔离级别是repeatable read。事务并发的问题脏读定义当前事务读取了其他事务未提交的数据。测试#A窗口#设置隔离级别set @@session.tx_isolation = &#39;read-uncommitted&#39;;select @@session.tx_isolation,@@global.tx_isolation;#第一次查询start transaction;select * from test;id	cname2	a#第二次查询，B窗口事务不提交，结果为未提交的数据select * from test;id	cname2	aa#第三次查询，B窗口事务回滚，结果恢复到第一次查询select * from test;id	cname2	a#B窗口start transaction;update test set cname=&#39;aa&#39; where id=2;rollback;commit;不可重复读定义  可重复读：当前事务读取了数据后，其他事务对数据的修改，不管有无提交，都不会影响当前事务多次读取的结果。  不可重复读：当前事务读取了数据后，其他事务对数据进行了修改会影响当前事务多次读取的结果。可重复读测试#A窗口#设置隔离级别set @@session.tx_isolation = &#39;repeatable-read&#39;;select @@session.tx_isolation,@@global.tx_isolation;#第一次查询start transaction;select * from test;id	cname2	a#第二次查询，B窗口事务不提交，查询结果不变select * from test;id	cname2	a#第三次查询，B窗口事务提交，查询结果不变select * from test;id	cname2	a#B窗口start transaction;update test set cname=&#39;aa&#39; where id=2;rollback;commit;不可重复读测试#A窗口#设置隔离级别set @@session.tx_isolation = &#39;read-committed&#39;;select @@session.tx_isolation,@@global.tx_isolation;#第一次查询start transaction;select * from test;id	cname2	a#第二次查询，B窗口事务不提交，查询结果不变select * from test;id	cname2	a#第三次查询，B窗口事务提交，查询结果变化select * from test;id	cname2	aa#B窗口start transaction;update test set cname=&#39;aa&#39; where id=2;rollback;commit;幻读定义当前事务读取了数据行后，其他事务对数据行进行新增或删除，会影响当前事务多次读取的数据行。幻读测试#A窗口#设置隔离级别set @@session.tx_isolation = &#39;read-committed&#39;;select @@session.tx_isolation,@@global.tx_isolation;#第一次查询start transaction;select * from test;id	cname2	aa#第二次查询，B窗口事务不提交，查询结果不变select * from test;id	cname2	a#第三次查询，B窗口事务提交，查询结果变化select * from test;id	cname2	aa4   b#B窗口start transaction;insert into test(cname) values(&#39;b&#39;);rollback;commit;不幻读测试#A窗口#设置隔离级别set @@session.tx_isolation = &#39;serializable&#39;;select @@session.tx_isolation,@@global.tx_isolation;#第一次查询start transaction;select * from test;id	cname2	aa#第二次查询，B窗口事务不能提交，查询结果不变select * from test;id	cname2	aa#B窗口start transaction;insert into test(cname) values(&#39;b&#39;);#此时不能回滚或提交rollback;commit;不可重复读与幻读的区别结果2种问题都会出现事务中多次读取数据与第一次读取的数据不一致的现象。控制的数据控制不可重复读，需要锁定的是满足条件（可理解为行锁）的数据；控制幻读，需要锁定的是满足条件及附近的数据（可理解为表锁）。执行的操作不可重复读针对的是update，幻读针对的是insert与delete。事务隔离级别不同隔离级别对应的并发处理问题：            隔离级别      脏读      不可重复读(结果是否发生变化)      幻读                  READ UNCOMMITTED      Y      Y      Y              READ COMMITTED      N      Y      Y              REPEATABLE READ      N      N      Y              SERIALIZABLE      N      N      N      read uncommitted读未提交，select语句以非锁定方式执行，会读取到其他事务未提交的数据，此隔离级别会导致脏读。read committed读已提交，值会读取到其他事务已提交的数据。repeatable read该事务隔离级别只会读取已提交的结果，与read committed不同的是，repeatable-read在开启事务的情况下，同一条件的查询返回的结果永远是一致的，无论其它事物是否提交了新的数据。serializableSerializable隔离级别 ，读用读锁，写用写锁，读锁和写锁互斥，这么做可以有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。修改隔离级别Tips：如果是mysql8及以后版本，需要将tx_isolation修改为transaction_isolation。查看#sessionmysql&amp;gt; select @@session.tx_isolation;+------------------------+| @@session.tx_isolation |+------------------------+| READ-UNCOMMITTED       |+------------------------+#globalmysql&amp;gt; select @@global.tx_isolation;+-----------------------+| @@global.tx_isolation |+-----------------------+| READ-UNCOMMITTED      |+-----------------------+修改#sessionmysql&amp;gt; set @@session.tx_isolation = &#39;read-committed&#39;;#globalmysql&amp;gt; set @@global.tx_isolation = &#39;read-uncommitted&#39;;参考资料Transaction Isolation LevelsSET TRANSACTION Syntax"
  },
  
  {
    "title": "RabbitMQ学习-配置",
    "url": "/posts/11-rabbitmq-study-configuration/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2019-03-15 15:10:00 +0800",
    





    "snippet": "  介绍RabbitMQ中的参数配置。概要rabbitmq在启动时会使用很多默认的配置，这些配置一般在开发或测试环境是可以的。当在线上环境时，某些配置可能需要根据实际情况进行调整。环境变量rabbitmq的环境变量可用于配置某些服务器参数：节点名称，rabbitmq配置文件位置，节点间通信端口，ErlangVM标志等。rabbitmq的环境变量除了内置的，还可通过shell或rabbitmq-env.conf进行设置。Tips：变量优先级为，shell&amp;gt;rabbitmq-env.conf&amp;gt;内置shell环境变量#局部设置[root@DEV-HROEx64 mnesia]# RABBITMQ_NODE_PORT=5674 rabbitmq-server -detached#全局直接设置[root@DEV-HROEx64 mnesia]# export RABBITMQ_NODE_PORT=5674#移除设置[root@DEV-HROEx64 mnesia]# export -n RABBITMQ_NODE_PORT#全局文件设置[root@DEV-HROEx64 mnesia]# vim /etc/profile[root@DEV-HROEx64 mnesia]# 写入配置保存[root@DEV-HROEx64 mnesia]# source /etc/profileTips：变量名需要携带RABBITMQ_前缀。rabbitmq-env配置文件配置文件的位置一般固定为${install-prefix}/etc/rabbitmq/rabbitmq-env.conf，如果文件不存在，可手动创建。Tips：区别于shell的设置，文件中的变量不需要携带RABBITMQ_前缀。可设置变量文件及目录相关的配置，$RABBITMQ_HOME为解压的rabbitmq目录。            名称      默认值/说明                  RABBITMQ_CONFIG_FILE      $RABBITMQ_HOME/etc/rabbitmq/rabbitmq.conf  配置文件路径              RABBITMQ_MNESIA_BASE      $RABBITMQ_HOME/var/lib/rabbitmq/mnesia  mnesia数据库路径              RABBITMQ_MNESIA_DIR      $RABBITMQ_MNESIA_BASE/$RABBITMQ_NODENAME  节点数据路径              RABBITMQ_LOG_BASE      $RABBITMQ_HOME/var/log/rabbitmq  日志路径              RABBITMQ_LOGS      $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME.log  节点日志路径              RABBITMQ_SASL_LOGS      $RABBITMQ_LOG_BASE/$RABBITMQ_NODENAME-sasl.log              RABBITMQ_PLUGINS_DIR      $RABBITMQ_HOME/plugins  可用组件路径              RABBITMQ_ENABLED_PLUGINS_FILE      $RABBITMQ_HOME/etc/rabbitmq/enabled_plugins  已启用组件              RABBITMQ_PID_FILE      $RABBITMQ_MNESIA_DIR.pid  pid文件      其他配置            名称      默认值/说明                  RABBITMQ_NODE_IP_ADDRESS      空，绑定到所有网络接口  需要绑定到的网络接口              RABBITMQ_NODE_PORT      5672  服务端口              RABBITMQ_DIST_PORT      RABBITMQ_NODE_PORT + 20000  节点间和CLI工具通信的端口              RABBITMQ_DISTRIBUTION_BUFFER_SIZE      128000  节点间通信连接的传出数据缓冲区大小(千字节)限制，不要低于64M              RABBITMQ_IO_THREAD_POOL_SIZE      128  用于I / O的线程数，不要使用低于32              RABBITMQ_NODENAME      rabbit@$HOSTNAME  节点名称，不同节点名称需唯一              RABBITMQ_CONFIG_FILE      $RABBITMQ_HOME/etc/rabbitmq/rabbitmq  主配置文件路径              RABBITMQ_ADVANCED_CONFIG_FILE      $RABBITMQ_HOME/etc/rabbitmq/advanced  “高级”配置文件路径              RABBITMQ_CONF_ENV_FILE      $RABBITMQ_HOME/etc/rabbitmq/rabbitmq-env.conf  环境变量配置路径      配置文件虽然RabbitMQ中的某些设置可以使用环境变量进行配置，但大多数设置都是使用配置文件配置的，通常名为rabbitmq.conf，包括核心服务器和插件的配置。配置文件位置根据不同的安装方式，配置文件一般在/etc/rabbitmq/或{rabbit_install_dir}/etc/rabbitmq/，如果不存在的话可手动创建。在rabbitmq启动时，可在日志文件的顶部查看加载的配置文件路径。Starting RabbitMQ 3.7.13 on Erlang 20.3 Copyright (C) 2007-2019 Pivotal Software, Inc. Licensed under the MPL.  See http://www.rabbitmq.com/2019-03-16 13:57:13.007 [info] &amp;lt;0.256.0&amp;gt;  node           : rabbit@vagrant home dir       : /root config file(s) : /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.conf cookie hash    : OIhbODu2Q0A6XyOqVBfFrA== log(s)         : /usr/local/rabbitmq/var/log/rabbitmq/rabbit@vagrant.log                : /usr/local/rabbitmq/var/log/rabbitmq/rabbit@vagrant_upgrade.log database dir   : /usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@vagrant如果开启web管理页面的话，也可以在节点的信息中查看配置文件路径。配置文件格式在RabbitMQ 3.7.0之前，RabbitMQ配置文件使用Erlang术语配置格式，新版本仍然支持该格式以实现向后兼容性。不过建议运行3.7.0或更高版本的用户考虑新的sysctl格式。老格式配置示例[  {rabbit, [{ssl_options, [{cacertfile,           &quot;/path/to/testca/cacert.pem&quot;},                           {certfile,             &quot;/path/to/server_certificate.pem&quot;},                           {keyfile,              &quot;/path/to/server_key.pem&quot;},                           {verify,               verify_peer},                           {fail_if_no_peer_cert, true}]}]}]新格式配置示例ssl_options.cacertfile           = /path/to/testca/cacert.pemssl_options.certfile             = /path/to/server_certificate.pemssl_options.keyfile              = /path/to/server_key.pemssl_options.verify               = verify_peerssl_options.fail_if_no_peer_cert = true新格式虽然易于理解与编辑，但是如果需要使用深层嵌套的数据结构来表达配置时，还是需要使用老格式的方式，如LDAP功能。配置查看可使用rabbitmqctl environment 命令显示当前的有效配置，配置为用户设置的与系统默认配置的合并结果。可设置变量rabbitmq.conf配置示例advanced.config配置示例参考资料配置环境变量配置文件及目录配置"
  },
  
  {
    "title": "RabbitMQ学习-虚拟主机",
    "url": "/posts/11-rabbitmq-study-virtual-hosts/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2019-03-12 14:10:00 +0800",
    





    "snippet": "  介绍RabbitMQ中虚拟主机的作用及使用方法。概要Rabbit的vhost类似于物理服务器上的虚拟机，每个vhost本质上是一个mini版的Rabbit服务器，拥有自己的队列、交换器、绑定等。不同的vhost有独立的权限机制，在逻辑上是完全分离的，可以安全保密的为不同的应用提供服务。当在Rabbit内新建用户时，用户可被指派给多个vhost，且只能访问指派vhost内的队列、交换器、队列。当在集群的某个节点上创建vhost时，整个集群都会创建该vhost，解决了多应用的维护成本。vhost的维护1.新建虚拟主机[root@DEV-HROEx64 mnesia]# rabbitmqctl add_vhost vhost_testCreating vhost &quot;vhost_test&quot;2.删除虚拟主机[root@DEV-HROEx64 mnesia]# rabbitmqctl delete_vhost vhost_testDeleting vhost &quot;vhost_test&quot;3.显示所有虚拟主机[root@DEV-HROEx64 mnesia]# rabbitmqctl list_vhostsListing vhosts/vhost_testvhost与用户绑定1.新建用户[root@DEV-HROEx64 mnesia]# rabbitmqctl add_user user_test 1234562.关联用户到虚拟主机[root@DEV-HROEx64 mnesia]# rabbitmqctl set_permissions -p vhost-test user-test &quot;.*&quot; &quot;.* &quot;.*&quot;3.设置用户角色如果希望用户可以使用web端进行集群的管理，可通过如下设置实现。#授予用户管理员权限[root@DEV-HROEx64 mnesia]# rabbitmqctl set_user_tags user_test administrator参考资料Virtual Hosts"
  },
  
  {
    "title": "redis的集群",
    "url": "/posts/redis-cluster/",
    "categories": "",
    "tags": "redis",
    "date": "2018-10-12 15:30:00 +0800",
    





    "snippet": "  介绍如果搭建redis集群，以及如何对集群进行扩展与收缩前言为了提高缓存服务器的写请求处理能力与数据存储能力可使用redis集群，根据实际业务情况对集群进行扩展与收缩准备工作由于机器的限制，此文章中的redis实例都是在一台机器上启动的，通过不同的port来模拟不同的redis实例。[root@vagrant redis-6386]# ps -ef|grep redisroot      2943     1  0 15:29 ?        00:00:01 ./redis-server *:6381 [cluster]root      2952     1  0 15:39 ?        00:00:00 ./redis-server *:6382 [cluster]root      2960     1  0 15:40 ?        00:00:00 ./redis-server *:6383 [cluster]root      2968     1  0 15:40 ?        00:00:00 ./redis-server *:6384 [cluster]root      2976     1  0 15:41 ?        00:00:00 ./redis-server *:6385 [cluster]root      2984     1  0 15:42 ?        00:00:00 ./redis-server *:6386 [cluster]数据分布数据分区redis集群采用虚拟槽分区，所有的键根据哈希函数映射到[0-16383]整数槽内，计算公式：slot=CRC16（key）&amp;amp;16383，每一个节点负责维护一部分槽以及槽所映射的键值数据，有如下一些特点：  解耦数据和节点之间的关系，简化了节点扩容和收缩难度  节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据  支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景集群功能限制不同于单机环境，集群环境有如下一些限制：集群客户端支持下面的操作么？  key批量操作支持有限。如mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mget、mget等操作可能存在于多个节点上因此不被支持  key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能  key作为数据分区的最小粒度，因此不能将一个大的键值对象如hash、list等映射到不同的节点  不支持多数据库空间。单机下的Redis可以支持16个数据库，集群模式下只能使用一个数据库空间，即db0  复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构集群搭建节点准备为了搭建集群需要准备多个redis节点，通常至少需要6个（3主3从）才能组建一个高可用的集群。节点配置同单机模式，除了以下几个相关的配置：#开启集群模式cluster-enabled yes#节点超时时间，单位毫秒cluster-node-timeout 15000#集群配置文件（nodes-{port}.conf）cluster-config-file &quot;nodes-6379.conf&quot;在启动节点时，如果没有配置文件则会根据cluster-config-file自动创建一个，否则使用配置文件来初始化集群信息。redis会自动维护此配置文件，不需要手动修改，以免错误。配置文件中的节点id在集群初始化的时候会创建一次，之后会一直重用。#配置文件[root@vagrant redis-6381]# cat nodes-6381.conf da2bd0c5419300bbe390dab920872aee71ae7d1d :0@0 myself,master - 0 0 0 connectedvars currentEpoch 0 lastVoteEpoch 0#集群节点状态[root@vagrant redis-6381]# ./redis-cli -p 6381 cluster nodesda2bd0c5419300bbe390dab920872aee71ae7d1d :6381@16381 myself,master - 0 0 0 connected手动部署节点握手当所有节点都启动后，彼此之间是不知道其它节点的存在的。可以在任意节点上执行cluster meet {ip} {port}命令，握手状态会通过消息在集群内传播，这样其他节点会自动发现新节点并发起握手流程。[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster meet 127.0.0.1 6382OK[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster meet 127.0.0.1 6383OK[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster meet 127.0.0.1 6384OK[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster meet 127.0.0.1 6385OK[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster meet 127.0.0.1 6386OK执行命令后，可在任意节点查看集群节点状态。#6381[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster nodes75cb527086abcb65ab2dcf7f96cc539d1293a6a3 127.0.0.1:6383@16383 master - 0 1539503506009 2 connected9291db5efb3254f60ec828525dfa9f62983be18b 127.0.0.1:6386@16386 master - 0 1539503502994 5 connected02a0f13dd1455bd849afd268b5d0bfc82a28cbf8 127.0.0.1:6385@16385 master - 0 1539503503000 4 connectededbbe9a0fb92076ac4bf896337ec7c5237124b86 127.0.0.1:6384@16384 master - 0 1539503505005 0 connectedda2bd0c5419300bbe390dab920872aee71ae7d1d 127.0.0.1:6381@16381 myself,master - 0 1539503502000 3 connected6c1722030a1e5fc1fd0d076819dad662a4941db1 127.0.0.1:6382@16382 master - 0 1539503505000 1 connected#6386[root@vagrant redis-6386]# ./redis-cli -p 6386 cluster nodesedbbe9a0fb92076ac4bf896337ec7c5237124b86 127.0.0.1:6384@16384 master - 0 1539503942475 0 connected02a0f13dd1455bd849afd268b5d0bfc82a28cbf8 127.0.0.1:6385@16385 master - 0 1539503943000 4 connected75cb527086abcb65ab2dcf7f96cc539d1293a6a3 127.0.0.1:6383@16383 master - 0 1539503941469 2 connected9291db5efb3254f60ec828525dfa9f62983be18b 127.0.0.1:6386@16386 myself,master - 0 1539503942000 5 connected6c1722030a1e5fc1fd0d076819dad662a4941db1 127.0.0.1:6382@16382 master - 0 1539503943480 1 connectedda2bd0c5419300bbe390dab920872aee71ae7d1d 127.0.0.1:6381@16381 master - 0 1539503940460 3 connected节点槽分配在节点完成互相握手后，集群还是不能使用的，只有当16384个槽被完全分配到节点上时，集群才进入可使用状态。#集群信息[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster infocluster_state:failcluster_slots_assigned:0cluster_slots_ok:0cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:0...#不能使用集群[root@vagrant redis-6386]# ./redis-cli -p 6381 set a 1(error) CLUSTERDOWN Hash slot not served槽（slot）是redis集群中数据的分区单位，每个key经过CRC16计算会映射到一个固定的槽，只有节点分配了槽，才能响应和这些槽关联的键命令。通过cluster addslots将槽平均分配给3个节点。[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster addslots {0..5461}OK[root@vagrant redis-6386]# ./redis-cli -p 6382 cluster addslots {5462..10922}OK[root@vagrant redis-6386]# ./redis-cli -p 6383 cluster addslots {10923..16383}OK#集群信息[root@vagrant redis-6386]# ./redis-cli -p 6383 cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3...可看到集群已经变为可使用状态，测试使用集群设置键值对#在6381执行提示moved信息，因为&#39;a&#39;计算出来的槽为15495，在6383上[root@vagrant redis-6386]# ./redis-cli -p 6381 set a 1(error) MOVED 15495 127.0.0.1:6383#命令增加&#39;-c&#39;代表自动进行命令转向，在6383执行[root@vagrant redis-6386]# ./redis-cli -p 6381 -c set a 1OK[root@vagrant redis-6386]# ./redis-cli -p 6381 -c get a&quot;1&quot;查看槽与节点的分配关系#集群节点状态[root@vagrant redis-6386]# ./redis-cli -p 6383 cluster nodes923c5d325b6dcbcca94276195206e24cdd37039b 127.0.0.1:6382@16382 master - 0 1539508163000 1 connected 5462-10922edbbe9a0fb92076ac4bf896337ec7c5237124b86 127.0.0.1:6384@16384 master - 0 1539508165000 0 connectedb9cb94e45c16cb2aadc60eefc29bee386b7a9ef7 127.0.0.1:6381@16381 master - 0 1539508166253 7 connected 0-546102a0f13dd1455bd849afd268b5d0bfc82a28cbf8 127.0.0.1:6385@16385 master - 0 1539508165248 4 connected9291db5efb3254f60ec828525dfa9f62983be18b 127.0.0.1:6386@16386 master - 0 1539508164244 5 connected0235798b70ba10533e04d3cc7c6e2345f4481d9f 127.0.0.1:6383@16383 myself,master - 0 1539508164000 2 connected 10923-16383目前还有3个节点没有使用，为了实现集群的高可用性，这3个节点作为槽节点的从节点，当出现故障时进行故障转移。集群模式下，reids节点角色分为主节点和从节点，首次启动的节点和被分配槽的节点都是主节点，从节点负责复制主节点槽信息和相关的数据。使用cluster replicate {nodeId}命令让一个节点成为某个主节点的从节点。[root@vagrant redis-6386]# ./redis-cli -p 6384 cluster replicate b9cb94e45c16cb2aadc60eefc29bee386b7a9ef7OK[root@vagrant redis-6386]# ./redis-cli -p 6385 cluster replicate 923c5d325b6dcbcca94276195206e24cdd37039bOK[root@vagrant redis-6386]# ./redis-cli -p 6386 cluster replicate 0235798b70ba10533e04d3cc7c6e2345f4481d9fOK查看集群节点状态和复制关系[root@vagrant redis-6386]# ./redis-cli -p 6381 cluster nodes02a0f13dd1455bd849afd268b5d0bfc82a28cbf8 127.0.0.1:6385@16385 slave 923c5d325b6dcbcca94276195206e24cdd37039b 0 1539509091000 4 connd923c5d325b6dcbcca94276195206e24cdd37039b 127.0.0.1:6382@16382 master - 0 1539509093853 1 connected 5462-109220235798b70ba10533e04d3cc7c6e2345f4481d9f 127.0.0.1:6383@16383 master - 0 1539509091000 2 connected 10923-163839291db5efb3254f60ec828525dfa9f62983be18b 127.0.0.1:6386@16386 slave 0235798b70ba10533e04d3cc7c6e2345f4481d9f 0 1539509092849 5 conndb9cb94e45c16cb2aadc60eefc29bee386b7a9ef7 127.0.0.1:6381@16381 myself,master - 0 1539509093000 7 connected 0-5461edbbe9a0fb92076ac4bf896337ec7c5237124b86 127.0.0.1:6384@16384 slave b9cb94e45c16cb2aadc60eefc29bee386b7a9ef7 0 15395090920自动部署对于集群的维护，如果使用手动执行相关命令的话，比较费时且很容易出现错误。可以通过redis提供的redis-trib.rb工具来进行集群的管理。Tips：在最新的redis版本里，已经不再支持redis-trib.rb工具，可以直接使用redis-cli --cluster来进行集群的管理，使用方式同redis-trib.rbruby环境redis-trib.rb是采用Ruby实现的Redis集群管理工具，所以使用前需要安装Ruby依赖环境。安装ruby[root@vagrant /]# cd /bmsource/[root@vagrant bmsource]# wget https://cache.ruby-lang.org/pub/ruby/2.3/ruby-2.3.1.tar.gz[root@vagrant bmsource]# tar xvf ruby-2.3.1.tar.gz[root@vagrant bmsource]# cd ruby-2.3.1[root@vagrant ruby-2.3.1]# ./configure -prefix=/usr/local/bin/[root@vagrant ruby-2.3.1]# make[root@vagrant ruby-2.3.1]# make install#复制可执行文件到/usr/local/bin/[root@vagrant ruby-2.3.1]# cd /usr/local/bin/bin[root@vagrant bin]# cp ruby /usr/local/bin/[root@vagrant bin]# cp gem /usr/local/bin/安装ruby gem redis依赖root@vagrant bin]# cd /bmsource/[root@vagrant bmsource]# wget http://rubygems.org/downloads/redis-3.3.0.gem[root@vagrant bmsource]# gem install -l redis-3.3.0.gem#查看包是否已安装[root@vagrant bmsource]# gem list执行redis-trib.rb命令确认环境是否正确[root@vagrant bmsource]# cd /usr/local/bin/redis-6381/[root@vagrant redis-6381]# ./redis-trib.rb Usage: redis-trib &amp;lt;command&amp;gt; &amp;lt;options&amp;gt; &amp;lt;arguments ...&amp;gt;  create          host1:port1 ... hostN:portN                  --replicas &amp;lt;arg&amp;gt;  ...节点准备同手动部署，首先准备6个集群节点。[root@vagrant redis-6382]# ps -ef|grep redisroot     18040     1  0 18:22 ?        00:00:00 ./redis-server *:6381 [cluster]root     18049     1  0 18:23 ?        00:00:00 ./redis-server *:6383 [cluster]root     18054     1  0 18:23 ?        00:00:00 ./redis-server *:6384 [cluster]root     18059     1  0 18:23 ?        00:00:00 ./redis-server *:6385 [cluster]root     18064     1  0 18:23 ?        00:00:00 ./redis-server *:6386 [cluster]root     18071     1  0 18:23 ?        00:00:00 ./redis-server *:6382 [cluster]集群创建使用redis-trib.rb create创建集群，--replicas 1用于指定主节点拥有的从节点个数[root@vagrant redis-6382]# ./redis-trib.rb create --replicas 1 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385 127.0.0.1:6386创建程序首先会给出主节点，从节点，槽的分配概况&amp;gt;&amp;gt;&amp;gt; Creating cluster&amp;gt;&amp;gt;&amp;gt; Performing hash slots allocation on 6 nodes...Using 3 masters:127.0.0.1:6381127.0.0.1:6382127.0.0.1:6383Adding replica 127.0.0.1:6385 to 127.0.0.1:6381Adding replica 127.0.0.1:6386 to 127.0.0.1:6382Adding replica 127.0.0.1:6384 to 127.0.0.1:6383&amp;gt;&amp;gt;&amp;gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381   slots:0-5460 (5461 slots) masterM: e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382   slots:5461-10922 (5462 slots) masterM: 0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383   slots:10923-16383 (5461 slots) masterS: f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384   replicates e19b36f039d4c56db0e48c9ffda0d00555a9576aS: 4010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385   replicates 0113a3532640fe678bd652bac626e4fc2fc32916S: c9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386   replicates 9b53bc798f30f0c3aad64ae787ef97bfb520ed62Can I set the above configuration? (type &#39;yes&#39; to accept): yes查看分配情况，如果觉得没问题可以输入yes来执行实际分配&amp;gt;&amp;gt;&amp;gt; Nodes configuration updated&amp;gt;&amp;gt;&amp;gt; Assign a different config epoch to each node&amp;gt;&amp;gt;&amp;gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.......&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)M: 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381   slots:0-5460 (5461 slots) master   1 additional replica(s)S: c9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386   slots: (0 slots) slave   replicates 9b53bc798f30f0c3aad64ae787ef97bfb520ed62M: 0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383   slots:10923-16383 (5461 slots) master   1 additional replica(s)M: e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382   slots:5461-10922 (5462 slots) master   1 additional replica(s)S: 4010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385   slots: (0 slots) slave   replicates 0113a3532640fe678bd652bac626e4fc2fc32916S: f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384   slots: (0 slots) slave   replicates e19b36f039d4c56db0e48c9ffda0d00555a9576a[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.最后的输出报告说明：16384个槽全部被分配，集群创建成功。这里需要注意给redis-trib.rb的节点地址必须是不包含任何槽/数据的节点，否则会拒绝创建集群。集群检查集群创建好后，还可以通过./redis-trib.rb check来检查集群的完整性，只需在集群中的任意节点执行即可。[root@vagrant redis-6382]# ./redis-trib.rb check 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)M: 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381   slots:0-5460 (5461 slots) master   1 additional replica(s)S: c9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386   slots: (0 slots) slave   replicates 9b53bc798f30f0c3aad64ae787ef97bfb520ed62M: 0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383   slots:10923-16383 (5461 slots) master   1 additional replica(s)M: e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382   slots:5461-10922 (5462 slots) master   1 additional replica(s)S: 4010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385   slots: (0 slots) slave   replicates 0113a3532640fe678bd652bac626e4fc2fc32916S: f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384   slots: (0 slots) slave   replicates e19b36f039d4c56db0e48c9ffda0d00555a9576a[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.集群伸缩原理redis的集群伸缩是在不影响集群对外服务的前提下，对集群增加节点（扩容）与减少节点（收缩）。redis集群可以方便的进行节点上下线控制，原理是依赖于槽和数据在节点中的灵活移动。扩容准备新节点为了扩容集群首先需要准备节点，节点的配置最好与集群中其他节点一致，从机数量也可保持与集群中主节点的从机数一致。[root@vagrant redis-6388]# ps -ef|grep redisroot     18625     1  0 14:02 ?        00:00:00 ./redis-server *:6387 [cluster]root     18638     1  0 14:03 ?        00:00:00 ./redis-server *:6388 [cluster]...加入集群可使用cluster meet命令，这里推荐使用redis-trib.rb add-node命令加入新节点，此命令可以帮助检查新节点是否属于其他集群或者已经包含数据。[root@vagrant redis-6388]# ./redis-trib.rb add-node 127.0.0.1:6387 127.0.0.1:6381 #在加入节点时指定主节点[root@vagrant redis-6388]# ./redis-trib.rb add-node --slave --master-id 96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6388 127.0.0.1:6381 添加好节点后，集群节点变为如下[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539758431000 6 connd8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 slave 96db27a74fd2717b9e65a7b843831de53158e273 0 1539758433949 7 connd0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383@16383 master - 0 1539758433000 3 connected 10923-16383e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539758431939 2 connected 5461-109224010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385@16385 slave 0113a3532640fe678bd652bac626e4fc2fc32916 0 1539758431000 5 connd9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539758431000 1 connected 0-5460f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539758430000 4 connd96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master - 0 1539758432000 0 connected迁移槽和数据新的节点加入到集群后，需要将现有主节点上的槽迁移到新节点上，同时确保迁移后每个节点上的槽数是均衡的。根据以上规则得到每个节点有哪些槽需要被迁移，确定好计划后就开始逐个将数据从源节点转移到目标节点。数据转移流程：  对目标节点发送cluster setslot {slot} importing {sourceNodeId}命令，让目标节点准备导入槽的数据  对源节点发送cluster setslot {slot} migrating {targetNodeId}命令，让源节点准备迁出槽的数据  源节点循环执行cluster getkeysinslot {slot} {count}命令，获取count个属于槽{slot}的键  在源节点上执行migrate {targetIp} {targetPort} “” 0 {timeout} keys {keys…}命令，把获取的键通过流水线（pipeline）机制批量迁移到目标节点  重复执行步骤（3,4）直到槽下所有的键值数据迁移到目标节点  向集群内所有主节点发送cluster setslot {slot} node {targetNodeId}命令，通知槽分配给目标节点。为了保证槽节点映射变更及时传播，需要遍历发送给所有主节点更新被迁移的槽指向新节点手动执行命令将槽1180从6381节点迁移到6387节点。#1.节点6387准备导入槽1180数据[root@vagrant redis-6388]# ./redis-cli -p 6387 cluster setslot 1180 importing 9b53bc798f30f0c3aad64ae787ef97bfb520ed62OK#6387槽1180导入状态开启#如果需要可通过&quot;cluster setslot 1180 stable&quot;取消槽迁移[root@vagrant redis-6388]# ./redis-cli -p 6387 cluster nodes96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 myself,master - 0 1539765189000 0 connected [1180-&amp;lt;-9b53bc798f30f0c3aad64ae787ef97bfb520ed62]#2.节点6381准备导出槽1180数据[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster setslot 1180 migrating 96db27a74fd2717b9e65a7b843831de53158e273OK#6381槽1180导出状态开启[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodes9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539766397000 1 connected 0-5460 [1180-&amp;gt;-96db27a74fd2717b9e65a7b843831de53158e273]#3.批量获取槽1180的键[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster getkeysinslot 1180 1001) &quot;aa&quot;#4.批量转移键[root@vagrant redis-6388]# ./redis-cli -p 6381 migrate 127.0.0.1 6387 &quot;&quot; 0 5000 keys aaOK#键已经不在源节点了，回复&quot;ASK&quot;引导客户端找到真实数据节点[root@vagrant redis-6388]# ./redis-cli -p 6381 get aa(error) ASK 1180 127.0.0.1:6387#5.通知所有主节点槽1180已经被分配给节点6387[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster setslot 1180 node 96db27a74fd2717b9e65a7b843831de53158e273OK[root@vagrant redis-6388]# ./redis-cli -p 6382 cluster setslot 1180 node 96db27a74fd2717b9e65a7b843831de53158e273OK[root@vagrant redis-6388]# ./redis-cli -p 6383 cluster setslot 1180 node 96db27a74fd2717b9e65a7b843831de53158e273OK[root@vagrant redis-6388]# ./redis-cli -p 6387 cluster setslot 1180 node 96db27a74fd2717b9e65a7b843831de53158e273OK#6.槽与数据迁移完成[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539767465226 6 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 slave 96db27a74fd2717b9e65a7b843831de53158e273 0 1539767466233 8 connected0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383@16383 master - 0 1539767464222 3 connected 10923-16383e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539767467240 2 connected 5461-109224010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385@16385 slave 0113a3532640fe678bd652bac626e4fc2fc32916 0 1539767468243 5 connected9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539767466000 1 connected 0-1179 1181-5460f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539767467000 4 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master - 0 1539767466000 8 connected 1180对于线上环境的redis集群，由于迁移槽与数据量都会比较大，最好还是使用redis-trib.rb reshard命令。#命令说明#host:port：必传参数，集群内任意节点地址，用来获取整个集群信息#--from：制定源节点的id，如果有多个源节点，使用逗号分隔，如果是all源节点变为集群内所有主节点，在迁移过程中提示用户输入#--to：需要迁移的目标节点的id，目标节点只能填写一个，在迁移过程中提示用户输入#--slots：需要迁移槽的总数量，在迁移过程中提示用户输入#--yes：当打印出reshard执行计划时，是否需要用户输入yes确认后再执行reshard#--timeout：控制每次migrate操作的超时时间，默认为60000毫秒#--pipeline：控制每次批量迁移键的数量，默认为10redis-trib.rb reshard host:port --from &amp;lt;arg&amp;gt; --to &amp;lt;arg&amp;gt; --slots &amp;lt;arg&amp;gt; --yes --timeout &amp;lt;arg&amp;gt; --pipeline &amp;lt;arg&amp;gt;使用redis-trib.rb来迁移剩余的slot#1.开启迁移，显示集群信息，提示输入迁移槽个数[root@vagrant redis-6388]# ./redis-trib.rb reshard 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)M: 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381   slots:0-1179,1181-5460 (5460 slots) master   1 additional replica(s)...[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? #2.输入4096，提示输入目标idHow many slots do you want to move (from 1 to 16384)? 4096What is the receiving node ID? #3.输入目标id，提示输入源idWhat is the receiving node ID? 96db27a74fd2717b9e65a7b843831de53158e273Please enter all the source node IDs.  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.  Type &#39;done&#39; once you entered all the source nodes IDs.Source node #1:#4.输入3个源id，显示迁移计划，提示输入yes...Moving slot 1361 from 9b53bc798f30f0c3aad64ae787ef97bfb520ed62Moving slot 1362 from 9b53bc798f30f0c3aad64ae787ef97bfb520ed62Moving slot 1363 from 9b53bc798f30f0c3aad64ae787ef97bfb520ed62...Do you want to proceed with the proposed reshard plan (yes/no)?#5.输入yes开始迁移，显示迁移状态...Moving slot 1338 from 127.0.0.1:6381 to 127.0.0.1:6387: Moving slot 1339 from 127.0.0.1:6381 to 127.0.0.1:6387: Moving slot 1340 from 127.0.0.1:6381 to 127.0.0.1:6387: Moving slot 1341 from 127.0.0.1:6381 to 127.0.0.1:6387: ...#6.迁移结束查看节点状态[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539768765984 6 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 slave 96db27a74fd2717b9e65a7b843831de53158e273 0 1539768763000 8 connected0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383@16383 master - 0 1539768762000 3 connected 12288-16383e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539768762972 2 connected 6827-109224010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385@16385 slave 0113a3532640fe678bd652bac626e4fc2fc32916 0 1539768764981 5 connected9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539768764000 1 connected 1366-5460f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539768763000 4 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master - 0 1539768763977 8 connected 0-1365 5461-6826 10923-12287#7.查看集群的平衡性[root@vagrant redis-6388]# ./redis-trib.rb rebalance 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.*** No rebalancing needed! All nodes are within the 2.0% threshold.收缩由于业务或硬件更换可能需要从集群下线节点，一般流程如下：  首先需要确定下线节点是否有负责的槽，如果有，需要把槽迁移到其他节点，保证节点下线后整个集群槽节点映射的完整性  当下线节点不再负责槽或者本身是从节点时，就可以通知集群内其他节点忘记下线节点，当所有的节点忘记该节点后可以正常关闭下线迁移槽下线节点需要迁移槽，原理与扩容迁移槽的过程一致，这里下线6383（master）与6385（slave），需要把主节点6383上的槽均匀迁移到另外3个主节点上。每次执行redis-trib.rb reshard只能有一个目标节点，所以需要执行3此reshard命令。#第一次迁移1365个槽-&amp;gt;6381[root@vagrant redis-6388]# ./redis-trib.rb reshard 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)...[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 1365What is the receiving node ID? 9b53bc798f30f0c3aad64ae787ef97bfb520ed62Please enter all the source node IDs.  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.  Type &#39;done&#39; once you entered all the source nodes IDs.Source node #1:0113a3532640fe678bd652bac626e4fc2fc32916Source node #2:done#第二次迁移1365个槽-&amp;gt;6382[root@vagrant redis-6388]# ./redis-trib.rb reshard 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)...[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 1365What is the receiving node ID? e19b36f039d4c56db0e48c9ffda0d00555a9576aPlease enter all the source node IDs.  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.  Type &#39;done&#39; once you entered all the source nodes IDs.Source node #1:0113a3532640fe678bd652bac626e4fc2fc32916Source node #2:done#第一次迁移1366个槽-&amp;gt;6387[root@vagrant redis-6388]# ./redis-trib.rb reshard 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)...[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 1365What is the receiving node ID? 96db27a74fd2717b9e65a7b843831de53158e273Please enter all the source node IDs.  Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.  Type &#39;done&#39; once you entered all the source nodes IDs.Source node #1:0113a3532640fe678bd652bac626e4fc2fc32916Source node #2:done全部迁移完成后查看集群节点状态，确保迁移结果是正确的#集群状态[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539831140899 9 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 slave 96db27a74fd2717b9e65a7b843831de53158e273 0 1539831137000 8 connected0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383@16383 master - 0 1539831140000 3 connectede19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539831137000 10 connected 6827-10922 13653-150174010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385@16385 slave 0113a3532640fe678bd652bac626e4fc2fc32916 0 1539831139000 5 connected9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539831138000 9 connected 1366-5460 12288-13652f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539831139895 10 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master - 0 1539831137884 11 connected 0-1365 5461-6826 10923-12287 15018-16383#检查集群[root@vagrant redis-6388]# ./redis-trib.rb check 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 127.0.0.1:6381)M: 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381   slots:1366-5460,12288-13652 (5460 slots) master   1 additional replica(s)S: c9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386   slots: (0 slots) slave   replicates 9b53bc798f30f0c3aad64ae787ef97bfb520ed62S: 8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388   slots: (0 slots) slave   replicates 96db27a74fd2717b9e65a7b843831de53158e273M: 0113a3532640fe678bd652bac626e4fc2fc32916 127.0.0.1:6383   slots: (0 slots) master   0 additional replica(s)M: e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382   slots:6827-10922,13653-15017 (5461 slots) master   1 additional replica(s)S: 4010a79852155581fffc9e632398898619a5db90 127.0.0.1:6385   slots: (0 slots) slave   replicates 96db27a74fd2717b9e65a7b843831de53158e273S: f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384   slots: (0 slots) slave   replicates e19b36f039d4c56db0e48c9ffda0d00555a9576aM: 96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387   slots:0-1365,5461-6826,10923-12287,15018-16383 (5463 slots) master   2 additional replica(s)[OK] All nodes agree about slots configuration.&amp;gt;&amp;gt;&amp;gt; Check for open slots...&amp;gt;&amp;gt;&amp;gt; Check slots coverage...[OK] All 16384 slots covered.忘记节点redis提供了cluster forget {downNodeId}来将被忘记节点加入到禁用列表中，不过需要在60s内在所有节点上执行此命令，否则节点会恢复通信，此种方式不适合在线上环境使用。这里使用redis-trib.rb del-node来忘记节点，为了避免从节点的全量复制，优先下线从节点，再下线主节点。[root@vagrant redis-6388]# ./redis-trib.rb del-node 127.0.0.1:6381 4010a79852155581fffc9e632398898619a5db90&amp;gt;&amp;gt;&amp;gt; Removing node 4010a79852155581fffc9e632398898619a5db90 from cluster 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Sending CLUSTER FORGET messages to the cluster...&amp;gt;&amp;gt;&amp;gt; SHUTDOWN the node.[root@vagrant redis-6388]# ./redis-trib.rb del-node 127.0.0.1:6381 0113a3532640fe678bd652bac626e4fc2fc32916&amp;gt;&amp;gt;&amp;gt; Removing node 0113a3532640fe678bd652bac626e4fc2fc32916 from cluster 127.0.0.1:6381&amp;gt;&amp;gt;&amp;gt; Sending CLUSTER FORGET messages to the cluster...&amp;gt;&amp;gt;&amp;gt; SHUTDOWN the node.查看集群节点与redis进程信息，确认节点已下线#集群信息[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539840155493 9 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 slave 96db27a74fd2717b9e65a7b843831de53158e273 0 1539840154000 11 connectede19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539840155000 10 connected 6827-10922 13653-150179b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539840154000 9 connected 1366-5460 12288-13652f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539840156497 10 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master - 0 1539840154000 11 connected 0-1365 5461-6826 10923-12287 15018-16383#redis进程[root@vagrant redis-6388]# ps -ef|grep redisroot     18040     1  0 Oct16 ?        00:03:40 ./redis-server *:6381 [cluster]root     18054     1  0 Oct16 ?        00:03:35 ./redis-server *:6384 [cluster]root     18064     1  0 Oct16 ?        00:03:34 ./redis-server *:6386 [cluster]root     18071     1  0 Oct16 ?        00:03:40 ./redis-server *:6382 [cluster]root     18625     1  0 Oct17 ?        00:02:02 ./redis-server *:6387 [cluster]root     18855     1  0 Oct17 ?        00:01:53 ./redis-server *:6388 [cluster]Tips：对于已下线的节点，如果需要重新启动的话，最好删除掉持久化文件（aof或rdb）与集群配置文件（nodes-{port}.conf），否则在启动时会加载故障转移redis自身实现了故障转移，不需要依赖sentinel来进行故障转移。故障发现主观下线当cluster-note-timeout时间内某节点无法与另一个节点顺利完成ping消息通信时，则将该节点标记为主观下线状态。客观下线当集群中半数以上持有槽的主节点都标记某个节点是主观下线时，触发客观下线流程。向集群广播一条fail消息，通知所有的节点将故障节点标记为客观下线。Tips：如果在cluster-node-time*2时间内无法收集到一半以上槽节点的下线报告，那么之前的下线报告将会过期，因此不能将cluster-node-time设置得过小。故障恢复故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的从节点中选出一个替换它，从而保证集群的高可用。主要流程：  资格检查  准备选举时间  发起选举  选举投票  替换主节点资格检查获取有资格进行故障替换的从节点，主从断线时间&amp;lt;=cluster-node-timeout*cluster-slave-alidity-factor（默认为10）准备选举时间从节点根据自身复制偏移量设置延迟选举时间，如复制偏移量最大的节点slave b-1延迟1秒执行，保证复制延迟低的从节点优先发起选举发起选举当从节点判断到达故障选举时间后，在集群内广播选举消息（FAILOVER_AUTH_REQUEST），并记录已发送过消息的状态，保证该从节点在一个配置纪元内只能发起一次选举。选举投票只有拥有槽的主节点才能对选举进行投票，且在一个配置纪元内只能投票一次，当从节点收集到N(所有槽主节点)/2+1个持有槽主节点投票时，从节点即可执行替换主节点操作。Tips：因为故障的主节点也在投票数内，如果在一台物理机上部署多个主节点时，当物理机出现故障可能会导致故障转移失败，所以部署集群时主节点最好部署在多台物理机上。替换主节点当确定由哪个主节点替换主节点后，即可进行一下操作：  当前从节点取消复制变为主节点  执行clusterDelSlot操作撤销故障主节点负责的槽，并执行clusterAddSlot把这些槽委派给自己  向集群广播自己的pong消息，通知集群内所有的节点当前从节点变为主节点并接管了故障主节点的槽信息故障转移时间通过上面的流程可以得知故障转移需要花费的时间（failover_time）&amp;lt;=cluster-node-timeout +cluster-node-timeout/2 + 1000  主观下线（pfail）识别时间=cluster-node-timeout  主观下线状态消息传播时间&amp;lt;=cluster-node-timeout/2  从节点转移时间&amp;lt;=1000毫秒因此故障转移时间跟cluster-node-timeout参数息息相关（默认15秒），配置时可以根据业务容忍度做出适当调整。故障转移测试下面对现有集群模拟故障转移#初始集群信息[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539853344532 9 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 slave 96db27a74fd2717b9e65a7b843831de53158e273 0 1539853346544 11 connectede19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539853346000 10 connected 6827-10922 13653-150179b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539853345000 9 connected 1366-5460 12288-13652f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539853345539 10 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master - 0 1539853347551 11 connected 0-1365 5461-6826 10923-12287 15018-16383使用kill -9 {pid}强制关闭6387主节点。#查看最新集群信息，故障已转移，6388变为新主节点[root@vagrant redis-6388]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539853959000 9 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 master - 0 1539853958000 12 connected 0-1365 5461-6826 10923-12287 15018-16383e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539853959841 10 connected 6827-10922 13653-150179b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539853960000 9 connected 1366-5460 12288-13652f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539853960853 10 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 master,fail - 1539853943825 1539853941716 11 disconnected重启6387节点，启动后发现自己负责的槽已被指派给另一个节点，则以现有集群配置为准，变为新主节点6388的从节点。[root@vagrant redis-6387]# ./redis-server redis.conf [root@vagrant redis-6387]# ./redis-cli -p 6381 cluster nodesc9a2731b7db540b7937b4bde854be8a0817258f0 127.0.0.1:6386@16386 slave 9b53bc798f30f0c3aad64ae787ef97bfb520ed62 0 1539854292000 9 connected8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 127.0.0.1:6388@16388 master - 0 1539854294121 12 connected 0-1365 5461-6826 10923-12287 15018-16383e19b36f039d4c56db0e48c9ffda0d00555a9576a 127.0.0.1:6382@16382 master - 0 1539854293116 10 connected 6827-10922 13653-150179b53bc798f30f0c3aad64ae787ef97bfb520ed62 127.0.0.1:6381@16381 myself,master - 0 1539854291000 9 connected 1366-5460 12288-13652f9a65ed5171b9a66e70b4a12474386c4f9b47e35 127.0.0.1:6384@16384 slave e19b36f039d4c56db0e48c9ffda0d00555a9576a 0 1539854292000 10 connected96db27a74fd2717b9e65a7b843831de53158e273 127.0.0.1:6387@16387 slave 8dc6f1d391ea4ae1f2fbc1ced10f2af356c34c31 0 1539854292113 12 connected集群运维集群完整性默认情况下当集群16384个槽任何一个没有指派到节点时整个集群不可用。执行任何键命令返回（error）CLUSTERDOWNHash slot not served错误。建议将参数cluster-require-full-coverage配置为no，当主节点故障只影响它负责槽的相关命令执行，不会影响其他主节点的可用性。[root@vagrant redis-6381]# ./redis-cli -p 6381 config get cluster-require-full-coverage1) &quot;cluster-require-full-coverage&quot;2) &quot;yes&quot;读写分离集群模式下从节点是不能处理读写请求的，发送过来的命令会重定向到相应槽的主节点上。如果需要从节点可以处理读的请求，需要使用readyonly命令来设置客户端的只读状态。[root@vagrant redis-6381]# ./redis-cli -p 6384127.0.0.1:6384&amp;gt; get b(error) MOVED 3300 127.0.0.1:6381127.0.0.1:6384&amp;gt; readonlyOK127.0.0.1:6384&amp;gt; get b(nil)Tips：readonly命令是连接级别生效，因此每次新建连接时都需要执行readonly开启只读状态。执行readwrite命令可以关闭连接只读状态。手动故障转移当需要对主节点迁移或自动故障转移失败时，可手动进行故障转移。在需要故障转移的主节点对应的从节点里，选取一个可变为主节点的从节点执行cluster failover命令，此从节点就会变为新主节点。#6386为6383的从节点[root@vagrant redis-6381]# ./redis-cli -p 6381 cluster nodes8613c01624d779fe892002ef48e2ea3ebcdc4c6b 127.0.0.1:6386@16386 slave 7d024eba97453219dda1375cfbf2bf9105841299 0 1539934116000 6 connected7d024eba97453219dda1375cfbf2bf9105841299 127.0.0.1:6383@16383 master - 0 1539934117445 3 connected 10923-16383#在6386上执行故障转移[root@vagrant redis-6381]# ./redis-cli -p 6386 cluster failoverOK#6383变为6386的从节点[root@vagrant redis-6381]# ./redis-cli -p 6381 cluster nodes8613c01624d779fe892002ef48e2ea3ebcdc4c6b 127.0.0.1:6386@16386 master - 0 1539934245070 7 connected 10923-163837d024eba97453219dda1375cfbf2bf9105841299 127.0.0.1:6383@16383 slave 8613c01624d779fe892002ef48e2ea3ebcdc4c6b 0 1539934249094 7 connected默认情况下转移期间客户端请求会有短暂的阻塞，但不会丢失数据，流程如下：  从节点通知主节点停止处理所有客户端请求  主节点发送对应从节点延迟复制的数据  从节点接收处理复制延迟的数据，直到主从复制偏移量一致为止，保证复制数据不丢失  从节点立刻发起投票选举（这里不需要延迟触发选举）。选举成功后断开复制变为新的主节点，之后向集群广播主节点pong消息，故障转移细节见10.6故障恢复部分  旧主节点接受到消息后更新自身配置变为从节点，解除所有客户端请求阻塞，这些请求会被重定向到新主节点上执行  旧主节点变为从节点后，向新的主节点发起全量复制流程数据迁移当准备使用redis集群时，一般都需要把数据从单机迁移到集群环境，推荐使用唯品会开源的redis-migrate-tool。下面尝试使用此工具，进行一次redis单机到集群的数据迁移。1.环境准备准备redis单机环境，6387（master），6388（slave）[root@vagrant redis-6388]# ps -ef|grep redisroot     12689     1  0 10:33 ?        00:00:00 ./redis-server *:6387    root     12694     1  0 10:33 ?        00:00:00 ./redis-server *:6388[root@vagrant redis-6388]# ./redis-cli -p 6387 info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6388,state=online,offset=14,lag=1...准备redis集群环境[root@vagrant redis-6386]# ps -ef|grep redisroot     12709     1  0 10:52 ?        00:00:00 ./redis-server *:6381 [cluster]root     12714     1  0 10:52 ?        00:00:00 ./redis-server *:6382 [cluster]root     12719     1  0 10:52 ?        00:00:00 ./redis-server *:6383 [cluster]root     12724     1  0 10:52 ?        00:00:00 ./redis-server *:6384 [cluster]root     12729     1  0 10:52 ?        00:00:00 ./redis-server *:6385 [cluster]root     12734     1  0 10:53 ?        00:00:00 ./redis-server *:6386 [cluster][root@vagrant redis-6386]# ./redis-cli -p 6381 cluster nodes1b1025d40c5e4d46941996ca382a2a07069dadb8 127.0.0.1:6382@16382 master - 0 1539919113086 2 connected 5461-109223561068ac19a730fe98fb9e90fc85c7487319d17 127.0.0.1:6385@16385 slave 1b1025d40c5e4d46941996ca382a2a07069dadb8 0 1539919114089 5 connecteddbc68e4e6ad2fccbe4383899a9e9f8156bfe8caa 127.0.0.1:6384@16384 slave 17bd7b9527f6ec1bb55976925ce7813d7acde6e0 0 1539919112081 4 connected8613c01624d779fe892002ef48e2ea3ebcdc4c6b 127.0.0.1:6386@16386 slave 7d024eba97453219dda1375cfbf2bf9105841299 0 1539919111076 6 connected7d024eba97453219dda1375cfbf2bf9105841299 127.0.0.1:6383@16383 master - 0 1539919111000 3 connected 10923-1638317bd7b9527f6ec1bb55976925ce7813d7acde6e0 127.0.0.1:6381@16381 myself,master - 0 1539919112000 1 connected 0-5460准备redis单机数据，确保测试数据在集群内分别属于不同的节点，用于之后检查数据迁移的准确性#槽15495，节点6383[root@vagrant redis-6386]# ./redis-cli -p 6387 set a 100OK#槽3300，节点6381[root@vagrant redis-6386]# ./redis-cli -p 6387 set b 200OK#槽7365，节点6382[root@vagrant redis-6386]# ./redis-cli -p 6387 set c 300OK2.工具安装#安装依赖库[root@vagrant redis-migrate-tool-master]# yum install libtool#安装redis-migrate-tool[root@vagrant bmsource]# wget https://github.com/vipshop/redis-migrate-tool/archive/master.zip -O redis-migrate-tool.zip[root@vagrant bmsource]# unzip redis-migrate-tool.zip [root@vagrant bmsource]# cd redis-migrate-tool-master/[root@vagrant redis-migrate-tool-master]# autoreconf -fvi[root@vagrant redis-migrate-tool-master]# ./configure [root@vagrant redis-migrate-tool-master]# make#查看工具帮助信息[root@vagrant redis-migrate-tool-master]# src/redis-migrate-tool -hThis is redis-migrate-tool-0.1.0Usage: redis-migrate-tool [-?hVdIn] [-v verbosity level] [-o output file]                  [-c conf file] [-C command]                  [-f source address] [-t target address]                  [-p pid file] [-m mbuf size] [-r target role]                  [-T thread number] [-b buffer size]...3.迁移数据迁移配置文件rmt.conf[source]type: singleservers :-127.0.0.1:6387[target]type: redis clusterservers:-127.0.0.1:6381[common]listen: 0.0.0.0:8888执行命令迁移数据[root@vagrant redis-migrate-tool-master]# src/redis-migrate-tool -c rmt.conf -o rmt.log -d查看rmt.log文件，发现存在以下报错，查看仓库问题，此工具还不支持redis4.x版本...[2018-10-19 14:53:51.678] rmt_redis.c:1643 rdb file node127.0.0.1:6387-1539932031654768-21118.rdb write complete[2018-10-19 14:53:51.678] rmt_redis.c:6446 ERROR: Can&#39;t handle RDB format version -782133880[2018-10-19 14:53:51.678] rmt_redis.c:6715 ERROR: Rdb file for node[127.0.0.1:6387] parsed failed...参考资料redis开发与运维redis cluster探索与思考redis集群规范redis集群管理工具数据迁移工具"
  },
  
  {
    "title": "redis的哨兵",
    "url": "/posts/redis-sentinel/",
    "categories": "",
    "tags": "redis",
    "date": "2018-10-09 15:30:00 +0800",
    





    "snippet": "  介绍使用redis哨兵进行自动故障转移前言为了增强缓存服务器的高可用可使用redis的哨兵监控，来实现主节点发生故障时的自动转移。准备工作由于机器的限制，此文章中的redis实例都是在一台机器上启动的，通过不同的port来模拟不同的redis实例。[root@vagrant redis-6383]# ps -ef|grep redisroot      4104     1  0 13:14 ?        00:00:00 ./redis-server *:6380    root      4113     1  0 13:18 ?        00:00:00 ./redis-server *:6381    root      4121     1  0 13:19 ?        00:00:00 ./redis-server *:6382    root      4129     1  0 13:19 ?        00:00:00 ./redis-server *:6383 配置文件哨兵节点对应的配置文件为sentinel.conf，有如下一些配置项						名称			说明			可选值							bind			允许访问节点的ip			protected-mode=yes时设置			自定义							protected-mode			保护模式			设置为no，确保网络在内网环境			yes|no							port			端口			整数							daemonize			守护进程			yes|no							pidfile			进程文件			自定义							logfile			日志文件			自定义							sentinel announce-ip			对外宣称ip或port			自定义							sentinel announce-port							dir			工作目录			自定义							sentinel monitor			&amp;lt;master-name&amp;gt; &amp;lt;ip&amp;gt; &amp;lt;redis-port&amp;gt; &amp;lt;quorum&amp;gt;			监控的主节点			quorum：			1.至少有quorum个哨兵节点认为不可达，才会故障转移			2.至少有max(quorum,num(哨兵个数)/2+1)个哨兵节点参与选举才能进行故障转移			整数							sentinel auth-pass			&amp;lt;master-name&amp;gt; &amp;lt;password&amp;gt;			主节点密码			自定义							sentinel down-after-milliseconds			&amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt;			节点不可达的判断时间			整数							sentinel parallel-syncs			&amp;lt;master-name&amp;gt; &amp;lt;numreplicas&amp;gt;			新主节点出来后，同时有几个从节点进行复制操作			整数							sentinel failover-timeout			&amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt;			故障转移超时时间			整数							sentinel notification-script			&amp;lt;master-name&amp;gt; &amp;lt;script-path&amp;gt;			配置脚本记录故障转移期间的事件			自定义							sentinel client-reconfig-script			&amp;lt;master-name&amp;gt; &amp;lt;script-path&amp;gt;			配置脚本记录故障转移结束后的处理结果			自定义							&amp;nbsp;			&amp;nbsp;			&amp;nbsp;			如果想动态的调整配置，可通过如下命令sentinel set &amp;lt;param&amp;gt; &amp;lt;value&amp;gt;						参数			使用方法							quorum			sentinel set master1 quorum 2							auth-pass			sentinel set master1 auth-pass password							down-after-milliseconds			sentinel set master1 down-after-milliseconds 1000							parallel-syncs			sentinel set master1 parallel-syncs 1							failover-timeout			sentinel set master1 failover-timeout&amp;nbsp;5000							notification-script			sentinel set master1 notification-script&amp;nbsp;/x.sh							client-reconfig-script			sentinel set master1 client-reconfig-script&amp;nbsp;/y.sh			在调整配置时需要注意以下几点：  只对当前调整的节点有效  配置调整成功会直接刷新配置文件  所有的哨兵节点配置最好是一致的部署拓扑结构这里以1个主节点，3个从节点，4个哨兵节点来组成一个Redis Sentinel。数据节点主节点主要配置如下：#6380#端口port 6380#守护进程daemonize yes#rdb文件dbfilename &quot;dump.rdb&quot;#工作目录dir &quot;./&quot;#日志文件logfile &quot;redis-server.log&quot;主节点启动[root@vagrant redis-6380]# ./redis-server redis.conf #检查服务状态[root@vagrant redis-6380]# ps -ef|grep redisroot      4156     1  0 14:07 ?        00:00:00 ./redis-server *:6380    从节点主要配置如下，增加了slaveof配置：#6381,6382,6383#端口port 6381#守护进程daemonize yes#rdb文件dbfilename &quot;dump.rdb&quot;#工作目录dir &quot;./&quot;#日志文件logfile &quot;redis-server.log&quot;#设置复制主节点slaveof 127.0.0.1 6380从节点启动[root@vagrant redis-6381]# ./redis-server redis.conf [root@vagrant redis-6382]# ./redis-server redis.conf [root@vagrant redis-6383]# ./redis-server redis.conf #检查服务状态[root@vagrant redis-6383]# ps -ef|grep redisroot      4156     1  0 14:07 ?        00:00:00 ./redis-server *:6380    root      4164     1  0 14:13 ?        00:00:00 ./redis-server *:6381    root      4175     1  0 14:14 ?        00:00:00 ./redis-server *:6382    root      4183     1  0 14:15 ?        00:00:00 ./redis-server *:6383    主从关系主节点视角：[root@vagrant redis-6383]# ./redis-cli -p 6380 info replication# Replicationrole:masterconnected_slaves:3slave0:ip=127.0.0.1,port=6381,state=online,offset=210,lag=1slave1:ip=127.0.0.1,port=6382,state=online,offset=210,lag=1slave2:ip=127.0.0.1,port=6383,state=online,offset=210,lag=1从节点视角：[root@vagrant redis-6383]# ./redis-cli -p 6381 info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6380master_link_status:up哨兵节点哨兵配置#26380,26381,26382,26383#端口port 26380#守护进程daemonize yes#工作目录dir &quot;./&quot;#日志文件logfile &quot;redis-sentinel.log&quot;#监控的主节点sentinel monitor master1 127.0.0.1 6380 2#节点不可达判断时间sentinel down-after-milliseconds master1 1000#同时向新主节点发起复制操作的节点个数sentinel parallel-syncs master1 1#故障转移超时时间sentinel failover-timeout master1 5000Tips：不要手动设置sentinel myid值，此值会自动生成哨兵启动[root@vagrant redis-6380]# ./redis-sentinel sentinel.conf [root@vagrant redis-6381]# ./redis-sentinel sentinel.conf [root@vagrant redis-6382]# ./redis-sentinel sentinel.conf [root@vagrant redis-6383]# ./redis-sentinel sentinel.conf 配置变化当哨兵节点都启动完成后，配置文件会被自动修改掉。减少的配置：sentinel parallel-syncs master1 1增加的配置：#最后的数字表示是第几次进行故障转移sentinel config-epoch master1 0sentinel leader-epoch master1 0#自动发现3个从节点sentinel known-slave master1 127.0.0.1 6382sentinel known-slave master1 127.0.0.1 6383sentinel known-slave master1 127.0.0.1 6381#自动发现除自身的3个哨兵节点sentinel known-sentinel master1 127.0.0.1 26381 29e2457f28a8fecd77f253b542f10523878c4e59sentinel known-sentinel master1 127.0.0.1 26380 699c1928d7ebe3b9f3a8395e824313e1e8f66a7esentinel known-sentinel master1 127.0.0.1 26382 8b1933d36031e2b9ee581f8269ac4bd427bb6063sentinel current-epoch 0哨兵确认检查哨兵的状态是否与配置的一致[root@vagrant redis-6383]# ./redis-cli -p 26380 info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=master1,status=ok,address=127.0.0.1:6380,slaves=3,sentinels=4API哨兵节点作为一个特殊的redis节点，有如下一些专属的apisentinel masters查看所有被监控的主节点信息[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel masters1)  1) &quot;name&quot;    2) &quot;master1&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;6382&quot;    ...sentinel master 查看某个主节点的信息[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel master master1 1) &quot;name&quot; 2) &quot;master1&quot; 3) &quot;ip&quot; 4) &quot;127.0.0.1&quot; 5) &quot;port&quot; 6) &quot;6382&quot; ...sentinel slaves 查看某个主节点下从节点的信息[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel slaves master11)  1) &quot;name&quot;    2) &quot;127.0.0.1:6380&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;6380&quot;    ...2)  1) &quot;name&quot;    2) &quot;127.0.0.1:6381&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;6381&quot;    ...3)  1) &quot;name&quot;    2) &quot;127.0.0.1:6383&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;6383&quot;    ...sentinel sentinels 查看某个主节点下哨兵的信息，不包括当前使用哨兵[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel sentinels master11)  1) &quot;name&quot;    2) &quot;f1b42cce7da99809b392a51b366cde7b3b6f6048&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;26383&quot;    ...2)  1) &quot;name&quot;    2) &quot;8b1933d36031e2b9ee581f8269ac4bd427bb6063&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;26382&quot;    ...3)  1) &quot;name&quot;    2) &quot;29e2457f28a8fecd77f253b542f10523878c4e59&quot;    3) &quot;ip&quot;    4) &quot;127.0.0.1&quot;    5) &quot;port&quot;    6) &quot;26381&quot;sentinel get-master-addr-by-name 查看某个主节点的ip与port信息[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel get-master-addr-by-name master11) &quot;127.0.0.1&quot;2) &quot;6382&quot;sentinel reset 重置匹配主节点的配置，清除主节点的相关状态（例如故障转移），重新发现从节点和哨兵节点[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel reset master1(integer) 1sentinel failover 对主节点进行强制故障转移[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel failover master1OKsentinel ckquorum 检查当前的可达哨兵节点数是否达到quorum个数，如果达不到则无法进行故障转移[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel ckquorum master1OK 4 usable Sentinels. Quorum and failover authorization can be reachedsentinel flushconfig将哨兵节点的配置更新到磁盘[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel flushconfigOKsentinel remove 取消当前哨兵节点对某个主节点的监控[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel remove master1OKsentinel monitor    对当前哨兵节点添加对某个主节点的监控[root@vagrant redis-6383]# ./redis-cli -p 26380 sentinel monitor master1 127.0.0.1 6381 2OKsentinel set   动态修改哨兵的配置，只对当前哨兵生效。修改成功后会立即更新配置文件，不同于redis.conf需要执行config rewrite。[root@vagrant redis-6380]# ./redis-cli -p 26380 sentinel set master1 quorum 3OKsentinel is-master-down-by-addrSentinel节点之间用来交换对主节点是否下线的判断，根据参数的不同，还可以作为Sentinel领导者选举的通信方式原理定时监控任务1.间隔10s每个sentinel通过主从节点获取info信息，更新拓扑结构。主要作用如下：  通过主节点获取从节点信息，sentinel节点不需要显式配置从节点的原因  自动感知新加入的从节点  节点不可达或故障转移后，更新最新的拓扑信息2.间隔2s每个sentinel节点向所有redis数据节点的__sentinel__:hello频道发送该sentinel节点的信息及主节点的信息，同时也订阅所有数据节点上的__sentinel__:hello频道来获取其他sentinel节点的信息与主节点信息。主要作用如下：  发现新的sentinel节点，与它们建立连接  sentinel节点之间交换主节点的状态，用于客观下线以及领导者选举的判断#接收到的消息[root@vagrant redis-6383]# ./redis-cli -p 6381 subscribe __sentinel__:helloReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;__sentinel__:hello&quot;3) (integer) 11) &quot;message&quot;2) &quot;__sentinel__:hello&quot;3) &quot;127.0.0.1,26381,29e2457f28a8fecd77f253b542f10523878c4e59,7,master1,127.0.0.1,6381,7&quot;1) &quot;message&quot;2) &quot;__sentinel__:hello&quot;3) &quot;127.0.0.1,26382,8b1933d36031e2b9ee581f8269ac4bd427bb6063,7,master1,127.0.0.1,6381,7&quot;1) &quot;message&quot;2) &quot;__sentinel__:hello&quot;3) &quot;127.0.0.1,26383,f1b42cce7da99809b392a51b366cde7b3b6f6048,7,master1,127.0.0.1,6381,7&quot;1) &quot;message&quot;2) &quot;__sentinel__:hello&quot;3) &quot;1.1.1.1,26380,699c1928d7ebe3b9f3a8395e824313e1e8f66a7e,7,master1,127.0.0.1,6381,7&quot;&amp;lt;Sentinel节点IP&amp;gt; &amp;lt;Sentinel节点端口&amp;gt; &amp;lt;Sentinel节点runId&amp;gt; &amp;lt;Sentinel节点配置版本&amp;gt;&amp;lt;主节点名字&amp;gt; &amp;lt;主节点Ip&amp;gt; &amp;lt;主节点端口&amp;gt; &amp;lt;主节点配置版本&amp;gt;3.间隔1s每个sentinel节点会向主节点、从节点、其余sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。主观下线与客观下线主观下线当sentinel每隔1秒对主节点、从节点、其他sentinel节点发送ping命令做心跳检测时，如果这些节点超过down-after-milliseconds没有进行有效回复，sentinel节点就认为此节点主观下线。客观下线当主观下线的节点为主节点时，sentinel会向其他sentinel节点发送sentinel ismaster-down-by-addr命令来获取其他sentinel节点对主节点的判断，如果超过quorum个sentinel节点认为主节点为主观下线，则sentinel会认为主节点为客观下线。命令说明：sentinel is-master-down-by-addr {ip} {port} {current_epoch} {runid}  ip：主节点ip  port：主节点端口  current_epoch：当前配置纪元  runid：”*“交换对主节点下线的判定，否则当runid等于当前Sentinel节点的runid时，作用是当前Sentinel节点希望目标Sentinel节点同意自己成为领导者的请求[root@vagrant redis-6383]# ./redis-cli -h 127.0.0.1 -p 26380 sentinel is-master-down-by-addr 127.0.0.1 6381 7 &#39;*&#39;1) (integer) 02) &quot;*&quot;3) (integer) 0返回结果说明：  down_state：目标Sentinel节点对于主节点的下线判断，1是下线，0是在线  leader_runid：当leader_runid等于“*”时，代表返回结果是用来做主节点是否不可达判断的，当leader_runid等于具体的runid，代表目标节点同意runid成为领导者  领导者纪元sentinel leader选举实际完成故障转移只需要一个sentinel节点，redis使用了raft算法来实现leader的选举，基本上最先完成客观下线的节点就是leader，大致过程如下：  每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他Sentinel节点发送sentinel is-master-down-by-addr命令，要求将自己设置为领导者  收到命令的Sentinel节点，如果没有同意过其他Sentinel节点的sentinelis-master-down-by-addr命令，将同意该请求，否则拒绝  如果该Sentinel节点发现自己的票数已经大于等于max（quorum，num（sentinels）/2+1），那么它将成为领导者  如果此过程没有选举出领导者，将进入下一次选举故障转移sentinel leader执行故障转移的大致流程如下：1.在从节点中选出一个节点作为新的主节点  过滤：“不健康”（主观下线、断线）、5秒内没有回复过Sentinel节点ping响应、与主节点失联超过down-after-milliseconds*10秒  选择slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续  选择复制偏移量最大的从节点（复制的最完整），如果存在则返回，不存在则继续  选择runid最小的从节点2.sentinel leader对选出来的节点执行slaveof no one让其变为主节点3.sentinel leader向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和parallel-syncs参数有关4.sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点参考资料sentinel.confsentinel topicredis开发与运维"
  },
  
  {
    "title": "redis的主从",
    "url": "/posts/redis-master-slave/",
    "categories": "",
    "tags": "redis",
    "date": "2018-10-02 15:30:00 +0800",
    





    "snippet": "  介绍redis的主从复制前言为了提高缓存服务器的并发处理量可使用redis的主从复制特性，来实现负载均衡。准备工作由于机器的限制，此文章中的redis实例都是在一台机器上启动的，通过不同的port来模拟不同的redis实例。[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ps -ef|grep redisroot     11946     1  0 Sep15 ?        00:35:48 ./redis-server 127.0.0.1:6379root     23867     1  0 16:45 ?        00:00:00 ./redis-server 127.0.0.1:6381root     23972     1  0 16:49 ?        00:00:00 ./redis-server 127.0.0.1:6382root     24000     1  0 16:51 ?        00:00:00 ./redis-server 127.0.0.1:6383配置复制建立redis实例默认都是主节点，每个从节点只能有一个主节点，而主节点可以有多个从节点，复制的数据只能从主节点到从节点。可通过如下方式配置：  配置文件：在redis.conf中增加slaveof {master-host} {master-port}的配置，启动服务时自动生效  服务启动：在执行redis-server命令启动服务时，增加--slaveof {master-host} {master-port}的参数  命令使用：在启动服务后，进入实例执行slaveof {master-host} {master-port}生效Tips：为了可维护性，线上环境一般都是使用配置文件的方式将6382，6383配置为6381的从机，查看各实例的复制状态信息#6381127.0.0.1:6381&amp;gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6383,state=online,offset=168,lag=0slave1:ip=127.0.0.1,port=6382,state=online,offset=168,lag=1#6382127.0.0.1:6382&amp;gt; info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6381#6383127.0.0.1:6383&amp;gt; info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6381在主节点设置了键值对后，可在从节点获取[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ./redis-cli -p 6381 set a 11OK[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ./redis-cli -p 6382 get a&quot;11&quot;[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ./redis-cli -p 6383 get a&quot;11&quot;复制断开如果希望某个从节点，不再归属于某个主节点，可使用slaveof no one命令，命令处理流程：  断开与主节点的复制关系  从节点提升为主节点，数据保留#断开6383的复制[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ./redis-cli -p 6383 slaveof no oneOK#6383复制状态[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ./redis-cli -p 6383 info replication# Replicationrole:masterconnected_slaves:0#6381复制状态[root@iZwz9i8fd8lio2yh3oerizZ redis-6383]# ./redis-cli -p 6381 info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6382,state=online,offset=2780,lag=1如果想切换某个从节点到新的主节点，可使用{master-host} {master-port}命令，命令处理流程：  断开与旧主节点的复制关系  与新主节点建立复制关系  删除从节点上的所有数据  从新主节点复制数据#6383旧值[root@iZwz9i8fd8lio2yh3oerizZ redis-6379]# ./redis-cli -p 6383  get a&quot;11&quot;#复制新主节点[root@iZwz9i8fd8lio2yh3oerizZ redis-6379]# ./redis-cli -p 6383 slaveof 127.0.0.1 6379OK#新值[root@iZwz9i8fd8lio2yh3oerizZ redis-6379]# ./redis-cli -p 6383  get a&quot;100&quot;#复制状态#6379[root@iZwz9i8fd8lio2yh3oerizZ redis-6379]# ./redis-cli -p 6379  info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6383,state=online,offset=276,lag=1#6383[root@iZwz9i8fd8lio2yh3oerizZ redis-6379]# ./redis-cli -p 6383  info replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6379安全性当出于安全考虑对主节点通过requirepass设置密码后，从节点如果想复制主节点需要设置masterauth为主节点的密码。只读由于数据复制只能从主节点到从节点，在从节点上的的任何修改都不会影响主节点，而且会造成主从节点的数据不一致，所以从节点一般都是配置为只读的slave-read-only=yes。传输延迟在线上环境时，主从节点一般部署在不同的机器上，所以需要考虑网络延迟问题，redis中的repl-disable-tcp-nodelay配置用于控制是否关闭TCP_NODELAY，默认为关闭状态：  关闭：主节点产生的命令数据无论大小都会及时地发送给从节点，这样主从之间延迟会变小，但增加了网络带宽的消耗。适用于主从之间的网络环境良好的场景，如同机架或同机房部署  开启：主节点会合并较小的TCP数据包从而节省带宽。默认发送时间间隔取决于Linux的内核，一般默认为40毫秒。这种配置节省了带宽但增大主从之间的延迟。适用于主从网络环境复杂或带宽紧张的场景，如跨机房部署拓补redis的复制结构可以支持单层或多层复制关系，一般可分为如下3种一主一从最简单的复制拓补结构，一般用途：  主节点故障转移  主节点关闭持久化，从节点开启持久化，提高主节点的性能一主多从最常用的复制拓补结构，一般用途：  主节点故障转移  读写分离，降低主节点压力  在从节点执行如：keys，sort等耗时命令Tips：如果主节点的从节点过多且主节点的写并发较多的情况下，会过度消耗网络带宽与影响主节点的性能，线上环境一般2-3个从节点。树状主从比较复杂的复制拓补结构，一般用途：  从节点数量较多，通过从节点将数据向别的从节点复制，提高原始主节点的性能#原始主节点6381role:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6382,state=online,offset=12855,lag=1#从节点6382复制6381role:slavemaster_host:127.0.0.1master_port:6381master_link_status:upmaster_last_io_seconds_ago:5master_sync_in_progress:0slave_repl_offset:12659slave_priority:100slave_read_only:1connected_slaves:1slave0:ip=127.0.0.1,port=6383,state=online,offset=12659,lag=0#从节点6383复制6382role:slavemaster_host:127.0.0.1master_port:6382#验证数据[root@iZwz9i8fd8lio2yh3oerizZ redis-6382]# ./redis-cli -p 6381 set c 88OK[root@iZwz9i8fd8lio2yh3oerizZ redis-6382]# ./redis-cli -p 6382 get c&quot;88&quot;[root@iZwz9i8fd8lio2yh3oerizZ redis-6382]# ./redis-cli -p 6383 get c&quot;88&quot;原理复制过程复制过程可分为如下6步：  保存主节点信息：还没建立复制流程，主节点连接状态为下线（master_link_status:down）  主从建立socket连接：每秒运行复制的定时任务，尝试与主节点建立socket连接，如果连接失败会记录失败日志  发送ping命令：检查主从socket是否可用，主节点当前是否可接受处理命令  权限验证：如果主节点设置了密码（requirepass），从节点需要配置（masterauth）  数据同步：主从连接成功后，主节点会把数据同步给从节点，是耗时最长的一步  命令持续复制：主节点会持续把写命令发送给从节点数据同步数据同步分为如下2种方式：  全量同步：当主从首次复制时，主节点会把全部数据一次性发给从节点，可能会对主从节点与网络造成较大的开销  部分同步：主要用于处理主从复制因网络闪断等原因造成的数据丢失，如果条件允许，当从节点重新连上主节点后，主节点只会发送丢失的数据，避免较大的网络开销psync命令依赖的组件：  主从节点各自的复制偏移量：主节点为master_repl_offset，从节点自身为slave_repl_offset与上报的为offset  主节点复制积压缓冲区  主节点运行id复制偏移量主节点，处理完写入命令后会累加命令的字节长度master_repl_offset# Replicationrole:master...master_repl_offset:108从节点每秒会向主节点上报自己的复制偏移量offset# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6382,state=online,offset=108,lag=0从节点，收到主节点的写入命令后，会累加自身的偏移量slave_repl_offset# Replicationrole:slave...slave_repl_offset:108Tips：可通过复制偏移量来判断主从节点数据是否一致。如果master_repl_offset-slave_offset较大，则可能有网络延迟或命令阻塞需要进一步检查。复制积压缓冲区用于记录主节点的最近写入命令，可用于部分复制及复制命令丢失的补救# Replicationrole:master...#开启复制缓冲区repl_backlog_active:1#缓冲区最大长度repl_backlog_size:1048576#起始偏移量，计算当前缓冲区的可用范围repl_backlog_first_byte_offset:1#已保存数据的有效长度repl_backlog_histlen:3120通过上面的指标可计算获取，复制积压缓冲区内的可用偏移量范围[repl_backlog_first_byte_offset，repl_backlog_first_byte_offset+repl_backlog_histlen]。如果从节点的offset不在此范围内，在处理复制请求时，主节点会对从节点进行全量复制。主节点运行idredis实例的唯一识别id，可用于从节点识别复制的是哪个主节点，当id变化时就不能部分复制而需要使用全量复制了。# Replicationrole:master...master_replid:ee1821344611dbc7b6587b563246a22435422808全量复制在主从第一次建立复制关系时使用的是全量复制，大致流程如下：  发送psync命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行ID，所以发送psync ? -1  主节点根据psync ? -1解析出当前为全量复制，回复+FULLRESYNC响应  从节点接收主节点的响应数据保存runid和偏移量offset    9845:S 03 Oct 15:29:46.742 * Trying a partial resynchronization (request 633fdc82b069b57678c1ae9aa4054220f7b7d334:1).9845:S 03 Oct 15:29:46.743 * Full resync from master: a0326cdd26badbf2130d76095188c991494e7bbf:0        主节点执行bgsave保存RDB文件到本地    9869:M 03 Oct 15:29:46.742 * Starting BGSAVE for SYNC with target: disk9869:M 03 Oct 15:29:46.743 * Background saving started by pid 99259925:C 03 Oct 15:29:46.746 * DB saved on disk9925:C 03 Oct 15:29:46.747 * RDB: 0 MB of memory used by copy-on-write9869:M 03 Oct 15:29:46.841 * Background saving terminated with success        主节点发送RDB文件给从节点，从节点把接收的RDB文件保存在本地并直接作为从节点的数据文件    9845:S 03 Oct 15:29:46.842 * MASTER &amp;lt;-&amp;gt; SLAVE sync: receiving 202 bytes from master        如果在从节点接受RDB数据期间，主节点又响应了写命令，这些命令会保存在复制客户端缓冲内，待从节点加载完RDB文件后，主节点再把缓冲区内的数据发给从节点    #对于主节点，当发送完所有的数据后就认为全量复制完成9869:M 03 Oct 15:29:46.841 * Synchronization with slave 127.0.0.1:6382 succeeded        从节点接收完主节点传送来的全部数据后会清空自身旧数据    9845:S 03 Oct 15:29:46.842 * MASTER &amp;lt;-&amp;gt; SLAVE sync: Flushing old data        从节点清空数据后开始加载RDB文件，对于较大的RDB文件，这一步操作依然比较耗时    9845:S 03 Oct 15:29:46.842 * MASTER &amp;lt;-&amp;gt; SLAVE sync: Loading DB in memory9845:S 03 Oct 15:29:46.842 * MASTER &amp;lt;-&amp;gt; SLAVE sync: Finished with success        从节点成功加载完RDB后，如果当前节点开启了AOF持久化功能，它会立刻做bgrewriteaof操作    9845:S 03 Oct 15:29:46.843 * Background append only file rewriting started by pid 99269845:S 03 Oct 15:29:46.869 * AOF rewrite child asks to stop sending diffs.9926:C 03 Oct 15:29:46.869 * Parent agreed to stop sending diffs. Finalizing AOF...9926:C 03 Oct 15:29:46.869 * Concatenating 0.00 MB of AOF diff received from parent.9926:C 03 Oct 15:29:46.869 * SYNC append only file rewrite performed9926:C 03 Oct 15:29:46.870 * AOF rewrite: 0 MB of memory used by copy-on-write9845:S 03 Oct 15:29:46.942 * Background AOF rewrite terminated with success      全量复制的主要开销如下：  主节点bgsave时间  RDB文件网络传输时间  从节点清空数据时间  从节点加载RDB的时间  可能的AOF重写时间Tips：如果主节点的数据量较大，开启新的从节点进行全量复制时，最好能挑选主节点压力比较小的时间来进行2个复制缓冲区的区别，理解的不一定是对的：  复制积压缓冲区：当主从复制关系正常运转后，同步保存主节点发送给从节点的写命令，用于之后的主从节点的网络闪断的部分复制  复制客户端缓冲区：用于全量复制时，保存从节点接受RDB文件期间主节点产生的写命令部分复制当主从复制关系正常运转后，如果出现网络闪断等命令丢失情况时，从节点会向主节点要求补发丢失的数据，如果主节点的复制积压缓冲区内存在这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。大致流程如下：  当主从节点之间网络出现中断  主节点继续响应请求，保存最近的写命令到复制积压缓冲区（默认为1MB）  当主从节点网络恢复后，从节点会再次连上主节点  从节点向主节点发送pysnc{runid}{offset}命令，请求部分复制  主节点检查runid是否与自身一致且offset之后的数据是否在缓冲区内，检查成功返回+CONTINUE，告知从节点可部分复制  主节点根据偏移量把复制积压缓冲区里的数据发送给从节点心跳主从建立复制关系后，彼此之间通过长连接发送心跳命令来检查网络及服务是否正常。  主从模拟成对方的客户端进行通信，client list查看信息，flags=M（主），flags=S（从）  主节点每隔repl-ping-slave-period（默认10秒）发送ping，检查从节点存活性与连接状态  从节点每隔1秒发送replconf ack{offset}，上报复制偏移量检查复制数据是否丢失。主节点用来判断超时时间（info replication的lag参数），如果超过repl-timeout则认为从节点下线异步复制主节点处理完客户端的写命令后，会直接返回给客户端，再异步将写命令发送给从节点，主从之间的数据可能会有延迟，正常情况下延迟在1秒内。如果需要查看延迟的字节量，可通过查看replication信息，master_repl_offset-slave_offset=延迟的字节量。[root@vagrant redis-6380]# ./redis-cli -p 6382 info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6381,state=online,offset=244823,lag=1slave1:ip=127.0.0.1,port=6380,state=online,offset=244823,lag=1master_repl_offset:244823常见问题读写分离数据延迟由于Redis复制数据的异步性，再加上网络带宽与命令阻塞的情况，在主节点写入数据后立即在从节点获取可能会获取不到数据。可尝试考虑如下方案：  redis集群水平扩展，降低单集群的数据量，从而提高复制速度  定时监控主从偏移量差异，如果差异较大，redis客户端（需要代码控制，成本较大）控制暂时不使用某个从机，待偏移量减少后再使用从节点故障当某个从节点发生故障时，redis客户端（代码控制）需要能捕获，从而更换别的从节点进行服务的提供。主从配置不一致对于内存的配置或对内存会产生影响的配置，如maxmemory，hash-max-ziplist-entries等参数，必须要主从配置一致。其它的配置（如持久化策略）可按照实际情况，进行主从的差异化配置。规避全量复制如果redis产生全量复制且数据量比较大时则会非常消耗资源，以下是产生全量复制的场景，可以通过一些方法合理的处理。第一次建立复制第一次建立复制，不可避免的会进行一次全量复制，如果想为主节点添加从节点，最好在服务低峰的时间段进行。节点运行ID不匹配当从节点发现保存的主节点运行id与实际的主节点运行id不一致时，会进行全量复制。此情况一般是由于主节点故障重启后运行id发生改变产生，最好使用sentinel来进行故障的自动转移。复制积压缓冲区不足当主从间进行部分复制时，如果从机请求复制的偏移量已经不在主机的复制积压缓存区内时，就会变为全量复制。可根据主机每秒的偏移量增大数*网络中断时间，计算得到合理的缓冲区大小并进行设置。参考资料sentinel.confredis开发与运维redis学习笔记——主从同步（复制）"
  },
  
  {
    "title": "网站架构基础",
    "url": "/posts/web-architecture/",
    "categories": "",
    "tags": "架构",
    "date": "2018-09-26 20:50:00 +0800",
    





    "snippet": "  介绍网站的基础架构前言此文是转自Jonathan Fulton写的博客，简洁明了的介绍了大部分网站都可适用的架构，并结合Storyblocks网站进行了响应用户请求的流程说明。概述网站架构图请求处理流程The above diagram is a fairly good representation of our architecture at Storyblocks. If you&#39;re not an experienced web developer, you&#39;ll likely find it complicated. The walk through below should make it more approachable before we dive into the details of each component.A user searches on Google for “Strong Beautiful Fog And Sunbeams In The Forest”. The first result happens to be from Storyblocks, our leading stock photo and vectors site. The user clicks the result which redirects their browser to the image details page. Underneath the hood the user’s browser sends a request to a DNS server to lookup how to contact Storyblocks, and then sends the request.The request hits our load balancer, which randomly chooses one of the 10 or so web servers we have running the site at the time to process the request. The web server looks up some information about the image from our caching service and fetches the remaining data about it from the database. We notice that the color profile for the image has not been computed yet, so we send a “color profile” job to our job queue, which our job servers will process asynchronously, updating the database appropriately with the results.Next, we attempt to find similar photos by sending a request to our full text search service using the title of the photo as input. The user happens to be a logged into Storyblocks as a member so we look up his account information from our account service. Finally, we fire off a page view event to our data firehose to be recorded on our cloud storage system and eventually loaded into our data warehouse, which analysts use to help answer questions about the business.The server now renders the view as HTML and sends it back to the user&#39;s browser, passing first through the load balancer. The page contains Javascript and CSS assets that we load into our cloud storage system, which is connected to our CDN, so the user’s browser contacts the CDN to retrieve the content. Lastly, the browser visibly renders the page for the user to see.架构节点下面介绍的是网站架构图里的各个组成部分DNSDNS stands for “Domain Name Server” and it&#39;s a backbone technology that makes the world wide web possible. At the most basic level DNS provides a key/value lookup from a domain name (e.g., google.com) to an IP address (e.g., 85.129.83.120), which is required in order for your computer to route a request to the appropriate server. Analogizing to phone numbers, the difference between a domain name and IP address is the difference between “call John Doe” and “call 201-867–5309.” Just like you needed a phone book to look up John&#39;s number in the old days, you need DNS to look up the IP address for a domain. So you can think of DNS as the phone book for the internet.There&#39;s a lot more detail we could go into here but we&#39;ll skip over it because it&#39;s not critical for our 101-level intro.Load BalancerBefore diving into details on load balancing, we need to take a step back to discuss horizontal vs. vertical application scaling. What are they and what&#39;s the difference? Very simply put in this StackOverflow post, horizontal scaling means that you scale by adding more machines into your pool of resources whereas “vertical” scaling means that you scale by adding more power (e.g., CPU, RAM) to an existing machine.In web development, you (almost) always want to scale horizontally because, to keep it simple, stuff breaks. Servers crash randomly. Networks degrade. Entire data centers occasionally go offline. Having more than one server allows you to plan for outages so that your application continues running. In other words, your app is “fault tolerant.” Secondly, horizontal scaling allows you to minimally couple different parts of your application backend (web server, database, service X, etc.) by having each of them run on different servers. Lastly, you may reach a scale where it&#39;s not possible to vertically scale any more. There is no computer in the world big enough to do all your app&#39;s computations. Think Google&#39;s search platform as a quintessential example though this applies to companies at much smaller scales. Storyblocks, for example, runs 150 to 400 AWS EC2 instances at any given point in time. It would be challenging to provide that entire compute power via vertical scaling.Ok, back to load balancers. They&#39;re the magic sauce that makes scaling horizontally possible. They route incoming requests to one of many application servers that are typically clones / mirror images of each other and send the response from the app server back to the client. Any one of them should process the request the same way so it&#39;s just a matter of distributing the requests across the set of servers so none of them are overloaded.That&#39;s it. Conceptually load balancers are fairly straight forward. Under the hood there are certainly complications but no need to dive in for our 101 version.Web Application ServersAt a high level web application servers are relatively simple to describe. They execute the core business logic that handles a user&#39;s request and sends back HTML to the user&#39;s browser. To do their job, they typically communicate with a variety of backend infrastructure such as databases, caching layers, job queues, search services, other microservices, data/logging queues, and more. As mentioned above, you typically have at least two and often times many more, plugged into a load balancer in order to process user requests.You should know that app server implementations require choosing a specific language (Node.js, Ruby, PHP, Scala, Java, C# .NET, etc.) and a web MVC framework for that language (Express for Node.js, Ruby on Rails, Play for Scala, Laravel for PHP, etc.). However, diving into the details of these languages and frameworks is beyond the scope of this article.Database ServersEvery modern web application leverages one or more databases to store information. Databases provide ways of defining your data structures, inserting new data, finding existing data, updating or deleting existing data, performing computations across the data, and more. In most cases the web app servers talk directly to one, as will the job servers. Additionally, each backend service may have it&#39;s own database that&#39;s isolated from the rest of the application.While I&#39;m avoiding a deep dive on particular technologies for each architecture component, I&#39;d be doing you a disservice not to mention the next level of detail for databases: SQL and NoSQL.SQL stands for “Structured Query Language” and was invented in the 1970s to provide a standard way of querying relational data sets that was accessible to a wide audience. SQL databases store data in tables that are linked together via common IDs, typically integers. Let&#39;s walk through a simple example of storing historical address information for users. You might have two tables, users and user_addresses, linked together by the user&#39;s id. See the image below for a simplistic version. The tables are linked because the user_id column in user_addresses is a “foreign key” to the id column in the users table.If you don&#39;t know much about SQL, I highly recommend walking through a tutorial like you can find on Khan Academy here. It&#39;s ubiquitous in web development so you&#39;ll at least want to know the basics in order to properly architect an application.NoSQL, which stands for “Non-SQL”, is a newer set of database technologies that has emerged to handle the massive amounts of data that can be produced by large scale web applications (most variants of SQL don&#39;t scale horizontally very well and can only scale vertically to a certain point). If you don&#39;t know anything about NoSQL, I recommend starting with some high level introductions like these:  https://www.w3resource.com/mongodb/nosql.php  http://www.kdnuggets.com/2016/07/seven-steps-understanding-nosql-databases.html  https://resources.mongodb.com/getting-started-with-mongodb/back-to-basics-1-introduction-to-nosqlI would also keep in mind that, by and large, the industry is aligning on SQL as an interface even for NoSQL databases so you really should learn SQL if you don&#39;t know it. There&#39;s almost no way to avoid it these days.Caching ServiceA caching service provides a simple key/value data store that makes it possible to save and lookup information in close to O(1) time. Applications typically leverage caching services to save the results of expensive computations so that it&#39;s possible to retrieve the results from the cache instead of recomputing them the next time they&#39;re needed. An application might cache results from a database query, calls to external services, HTML for a given URL, and many more. Here are some examples from real world applications:  Google caches search results for common search queries like “dog” or “Taylor Swift” rather than re-computing them each time  Facebook caches much of the data you see when you log in, such as post data, friends, etc. Read a detailed article on Facebook’s caching tech here  Storyblocks caches the HTML output from server-side React rendering, search results, typeahead results, and more.The two most widespread caching server technologies are Redis and Memcache. I’ll go into more detail here in another post.Job Queue &amp;amp; ServersMost web applications need to do some work asynchronously behind the scenes that&#39;s not directly associated with responding to a user&#39;s request. For instance, Google needs to crawl and index the entire internet in order to return search results. It does not do this every time you search. Instead, it crawls the web asynchronously, updating the search indexes along the way.While there are different architectures that enable asynchronous work to be done, the most ubiquitous is what I&#39;ll call the “job queue” architecture. It consists of two components: a queue of “jobs” that need to be run and one or more job servers (often called “workers”) that run the jobs in the queue.Job queues store a list of jobs that need to be run asynchronously. The simplest are first-in-first-out (FIFO) queues though most applications end up needing some sort of priority queuing system. Whenever the app needs a job to be run, either on some sort of regular schedule or as determined by user actions, it simply adds the appropriate job to the queue.Storyblocks, for instance, leverages a job queue to power a lot of the behind-the-scenes work required to support our marketplaces. We run jobs to encode videos and photos, process CSVs for metadata tagging, aggregate user statistics, send password reset emails, and more. We started with a simple FIFO queue though we upgraded to a priority queue to ensure that time-sensitive operations like sending password reset emails were completed ASAP.Job servers process jobs. They poll the job queue to determine if there&#39;s work to do and if there is, they pop a job off the queue and execute it. The underlying languages and frameworks choices are as numerous as for web servers so I won&#39;t dive into detail in this article.Full-text Search ServiceMany if not most web apps support some sort of search feature where a user provides a text input (often called a “query”) and the app returns the most “relevant” results. The technology powering this functionality is typically referred to as “full-text search”, which leverages an inverted index to quickly look up documents that contain the query keywords.While it&#39;s possible to do full-text search directly from some databases (e.g., MySQL supports full-text search), it&#39;s typical to run a separate “search service” that computes and stores the inverted index and provides a query interface. The most popular full-text search platform today is Elasticsearch though there are other options such as Sphinx or Apache Solr.ServicesOnce an app reaches a certain scale, there will likely be certain “services” that are carved out to run as separate applications. They&#39;re not exposed to the external world but the app and other services interact with them. Storyblocks, for example, has several operational and planned services:  Account service：stores user data across all our sites, which allows us to easily offer cross-sell opportunities and create a more unified user experience  Content service：stores metadata for all of our video, audio, and image content. It also provides interfaces for downloading the content and viewing download history  Payment service：provides an interface for billing customer credit cards  HTML → PDF service：provides a simple interface that accepts HTML and returns a corresponding PDF documentDataToday, companies live and die based on how well they harness data. Almost every app these days, once it reaches a certain scale, leverages a data pipeline to ensure that data can be collected, stored, and analyzed. A typical pipeline has three main stages:      The app sends data, typically events about user interactions, to the data “firehose” which provides a streaming interface to ingest and process the data. Often times the raw data is transformed or augmented and passed to another firehose. AWS Kinesis and Kafka are the two most common technologies for this purpose.        The raw data as well as the final transformed/augmented data are saved to cloud storage. AWS Kinesis provides a setting called “firehose” that makes saving the raw data to it’s cloud storage (S3) extremely easy to configure.        The transformed/augmented data is often loaded into a data warehouse for analysis. We use AWS Redshift, as does a large and growing portion of the startup world, though larger companies will often use Oracle or other proprietary warehouse technologies. If the data sets are large enough, a Hadoop-like NoSQL MapReduce technology may be required for analysis.  Another step that&#39;s not pictured in the architecture diagram: loading data from the app and services operational databases into the data warehouse. For example at Storyblocks we load our VideoBlocks, AudioBlocks, Storyblocks, account service, and contributor portal databases into Redshift every night. This provides our analysts a holistic dataset by co-locating the core business data alongside our user interaction event data.Cloud storage“Cloud storage is a simple and scalable way to store, access, and share data over the Internet” according to AWS. You can use it to store and access more or less anything you&#39;d store on a local file system with the benefits of being able to interact with it via a RESTful API over HTTP. Amazon&#39;s S3 offering is by far the most popular cloud storage available today and the one we rely on extensively here at Storyblocks to store our video, photo, and audio assets, our CSS and Javascript, our user event data and much more.CDNCDN stands for “Content Delivery Network” and the technology provides a way of serving assets such as static HTML, CSS, Javascript, and images over the web much faster than serving them from a single origin server. It works by distributing the content across many “edge” servers around the world so that users end up downloading assets from the “edge” servers instead of the origin server. For instance in the image below, a user in Spain requests a web page from a site with origin servers in NYC, but the static assets for the page are loaded from a CDN “edge” server in England, preventing many slow cross-Atlantic HTTP requests.Check out this article for a more thorough introduction. In general a web app should always use a CDN to serve CSS, Javascript, images, videos and any other assets. Some apps might also be able to leverage a CDN to serve static HTML pages.参考资料Web Architecture 101storyblocks"
  },
  
  {
    "title": "opcache的使用",
    "url": "/posts/opcache/",
    "categories": "",
    "tags": "php",
    "date": "2018-09-25 20:50:00 +0800",
    





    "snippet": "  介绍使用opcache来提升php的性能前言php作为脚本语言，在脚本执行结束后不会保留任何状态，所以每次执行都需要重新解析脚本，增加了内存与cpu的开销。通过使用opcache可以避免每次都对脚本文件进行解析，从而提高性能。php运行周期php5关闭opcache开启opcache步骤说明：  Scanning(Lexing)：词法分析，将php代码转换为语言片段(tokens)  Parsing：语法分析，将tokens转换成简单而有意义的表达式(op arrays)  Compilation：将表达式编译成opcodes  Execution：顺次执行opcodes，每次一条，从而实现PHP脚本的功能php7相对于php5的解析过程，php7在parsing阶段将不直接生成op arrays而是生成ast(抽象语法树)，在Compilation时先从ast生成op arrays再编译为Opcodes。让解释器与编译器进行了解耦，增加了内存的使用，但降低了执行时间。关闭opcache开启opcache步骤说明：  Scanning(Lexing)：词法分析，将PHP代码转换为语言片段(tokens)  Parsing：语法分析，将tokens转换成抽象语法树(ast)  AST：抽象语法树，解耦parsing与compilation  Compilation：从ast生成op arrays，再编译成Opcodes  Execution：顺次执行Opcodes，每次一条，从而实现PHP脚本的功能opcache原理OPcache 通过将 PHP 脚本预编译的字节码存储到共享内存中来提升 PHP 的性能，存储预编译字节码的好处就是 省去了每次加载和解析 PHP 脚本的开销。opcache使用开启opcache在php5.5.0及之后的版本，会自带opcache扩展，位置一般在extension_dir所指向的文件夹。php默认是不开启opcache的，如果需要使用可通过如下方式开启：#php.inizend_extension=opcache.soopcache.enable=1推荐配置#OPcache的共享内存大小，以兆字节(m)为单位opcache.memory_consumption=128#用来存储临时字符串的内存大小，以兆字节为单位opcache.interned_strings_buffer=8#OPcache哈希表中可存储的脚本文件数量上限，真实的取值是在质数集合 { 223, 463, 983, 1979, 3907, 7963, 16229, 32531, 65407, 130987 } 中找到的第一个大于等于设置值的质数opcache.max_accelerated_files=4000#检查脚本时间戳是否有更新的周期，以秒为单位。 设置为 0 会导致针对每个请求， OPcache 都会检查脚本更新。#如果opcache.validate_timestamps 配置指令设置为禁用，那么此设置项将会被忽略opcache.revalidate_freq=60#如果启用，则会使用快速停止续发事件。 #所谓快速停止续发事件是指依赖 Zend 引擎的内存管理模块 一次释放全部请求变量的内存，而不是依次释放每一个已分配的内存块opcache.fast_shutdown=1#仅针对 CLI 版本的 PHP 启用操作码缓存。 通常被用来测试和调试。opcache.enable_cli=1也可以修改如下2个配置。在生产环境中使用下面配置之前，必须经过严格测试。因为上述配置存在一个已知问题，它会引发一些框架和应用的异常， 尤其是在存在文档使用了备注注解的时候。 #如果禁用，脚本文件中的注释内容将不会被包含到操作码缓存文件， 这样可以有效减小优化后的文件体积。 #禁用此配置指令可能会导致一些依赖注释或注解的 应用或框架无法正常工作， 比如： Doctrine， Zend Framework 2 以及 PHPUnitopcache.save_comments=0#如果启用，则在调用函数 file_exists()， is_file() 以及 is_readable() 的时候， 都会检查操作码缓存，无论文件是否已经被缓存。 #如果应用中包含检查 PHP 脚本存在性和可读性的功能，这样可以提升性能。 但是如果禁用了 opcache.validate_timestamps 选项， 可能存在返回过时数据的风险opcache.enable_file_override=1strace跟踪分析通过strace的跟踪日志来看opcache开启前后的php执行信息开启opcache第一次执行，需要打开关闭执行的文件并对文件进行分配回收内存等一系列操作11:09:17.993927 chdir(&quot;/www/htdocs/Interview/Web/singlepage&quot;) = 0 &amp;lt;0.000716&amp;gt;11:09:17.995499 setitimer(ITIMER_PROF, {it_interval={0, 0}, it_value={30, 0}}, NULL) = 0 &amp;lt;0.000076&amp;gt;11:09:17.996063 fcntl(25, F_SETLK, {type=F_RDLCK, whence=SEEK_SET, start=1, len=1}) = 0 &amp;lt;0.000047&amp;gt;11:09:17.996979 lstat(&quot;/www/htdocs/Interview/Web/singlepage/test.php&quot;, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000727&amp;gt;11:09:17.999070 lstat(&quot;/www/htdocs/Interview/Web/singlepage&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000533&amp;gt;11:09:17.999880 lstat(&quot;/www/htdocs/Interview/Web&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000202&amp;gt;11:09:18.000208 lstat(&quot;/www/htdocs/Interview&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000150&amp;gt;11:09:18.000481 lstat(&quot;/www/htdocs&quot;, {st_mode=S_IFLNK|0777, st_size=16, ...}) = 0 &amp;lt;0.000010&amp;gt;11:09:18.000615 readlink(&quot;/www/htdocs&quot;, &quot;/vagrant/htdocs/&quot;, 4096) = 16 &amp;lt;0.000011&amp;gt;11:09:18.000746 lstat(&quot;/vagrant/htdocs&quot;, {st_mode=S_IFDIR|0777, st_size=12288, ...}) = 0 &amp;lt;0.000110&amp;gt;11:09:18.000988 lstat(&quot;/vagrant&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000064&amp;gt;#打开test.php文件11:09:18.001210 open(&quot;/vagrant/htdocs/Interview/Web/singlepage/test.php&quot;, O_RDONLY) = 21 &amp;lt;0.000523&amp;gt;#根据文件描述符获取文件状态11:09:18.001871 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000069&amp;gt;11:09:18.002075 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000061&amp;gt;11:09:18.002268 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000057&amp;gt;#建立内存映射11:09:18.002440 mmap(NULL, 42875, PROT_READ, MAP_SHARED, 21, 0) = 0x7f9cf614a000 &amp;lt;0.000014&amp;gt;#根据文件路径获取文件状态11:09:18.002580 stat(&quot;/vagrant/htdocs/Interview/Web/singlepage/test.php&quot;, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000417&amp;gt;11:09:18.003577 brk(0x10fd000)          = 0x10fd000 &amp;lt;0.000011&amp;gt;11:09:18.005148 brk(0x113d000)          = 0x113d000 &amp;lt;0.000011&amp;gt;11:09:18.006018 fcntl(25, F_SETLKW, {type=F_WRLCK, whence=SEEK_SET, start=0, len=1}) = 0 &amp;lt;0.000013&amp;gt;11:09:18.006535 fcntl(25, F_SETLK, {type=F_UNLCK, whence=SEEK_SET, start=0, len=1}) = 0 &amp;lt;0.000012&amp;gt;#解除内存映射11:09:18.006782 munmap(0x7f9cf614a000, 42875) = 0 &amp;lt;0.000019&amp;gt;#关闭文件11:09:18.006925 close(21)               = 0 &amp;lt;0.000158&amp;gt;11:09:18.007428 uname({sys=&quot;Linux&quot;, node=&quot;vagrant.localhost&quot;, ...}) = 0 &amp;lt;0.000009&amp;gt;11:09:18.010017 brk(0x1160000)          = 0x1160000 &amp;lt;0.000012&amp;gt;11:09:18.010200 brk(0x11a0000)          = 0x11a0000 &amp;lt;0.000009&amp;gt;11:09:18.012429 chdir(&quot;/&quot;)              = 0 &amp;lt;0.000014&amp;gt;第二次及以后的执行，因为opcache中已有缓存，不需要再解析文件，所以减少了很多操作11:09:52.324217 chdir(&quot;/www/htdocs/Interview/Web/singlepage&quot;) = 0 &amp;lt;0.000319&amp;gt;11:09:52.324707 setitimer(ITIMER_PROF, {it_interval={0, 0}, it_value={30, 0}}, NULL) = 0 &amp;lt;0.000011&amp;gt;11:09:52.324878 fcntl(25, F_SETLK, {type=F_RDLCK, whence=SEEK_SET, start=1, len=1}) = 0 &amp;lt;0.000018&amp;gt;11:09:52.325063 stat(&quot;/vagrant/htdocs/Interview/Web/singlepage/test.php&quot;, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000608&amp;gt;11:09:52.325957 uname({sys=&quot;Linux&quot;, node=&quot;vagrant.localhost&quot;, ...}) = 0 &amp;lt;0.000012&amp;gt;11:09:52.332211 chdir(&quot;/&quot;)              = 0 &amp;lt;0.000120&amp;gt;关闭opcache每次执行，需要打开关闭执行的文件并对文件进行分配回收内存等一系列操作#第一次3570  14:24:34.125873 chdir(&quot;/www/htdocs/Interview/Web/singlepage&quot;) = 0 &amp;lt;0.000450&amp;gt;3570  14:24:34.126573 setitimer(ITIMER_PROF, {it_interval={0, 0}, it_value={30, 0}}, NULL) = 0 &amp;lt;0.000014&amp;gt;3570  14:24:34.126930 lstat(&quot;/www/htdocs/Interview/Web/singlepage/test.php&quot;, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000874&amp;gt;3570  14:24:34.128097 lstat(&quot;/www/htdocs/Interview/Web/singlepage&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000644&amp;gt;3570  14:24:34.128981 lstat(&quot;/www/htdocs/Interview/Web&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000397&amp;gt;3570  14:24:34.129558 lstat(&quot;/www/htdocs/Interview&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000337&amp;gt;3570  14:24:34.130117 lstat(&quot;/www/htdocs&quot;, {st_mode=S_IFLNK|0777, st_size=16, ...}) = 0 &amp;lt;0.000010&amp;gt;3570  14:24:34.130271 readlink(&quot;/www/htdocs&quot;, &quot;/vagrant/htdocs/&quot;, 4096) = 16 &amp;lt;0.000010&amp;gt;3570  14:24:34.130402 lstat(&quot;/vagrant/htdocs&quot;, {st_mode=S_IFDIR|0777, st_size=12288, ...}) = 0 &amp;lt;0.000146&amp;gt;3570  14:24:34.130737 lstat(&quot;/vagrant&quot;, {st_mode=S_IFDIR|0777, st_size=4096, ...}) = 0 &amp;lt;0.000096&amp;gt;3570  14:24:34.131021 open(&quot;/vagrant/htdocs/Interview/Web/singlepage/test.php&quot;, O_RDONLY) = 21 &amp;lt;0.020507&amp;gt;3570  14:24:34.151795 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000059&amp;gt;3570  14:24:34.152002 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000056&amp;gt;3570  14:24:34.152182 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000064&amp;gt;3570  14:24:34.152362 mmap(NULL, 42875, PROT_READ, MAP_SHARED, 21, 0) = 0x7f9cf614a000 &amp;lt;0.000013&amp;gt;3570  14:24:34.154280 munmap(0x7f9cf614a000, 42875) = 0 &amp;lt;0.000019&amp;gt;3570  14:24:34.154437 close(21)         = 0 &amp;lt;0.000116&amp;gt;3570  14:24:34.154721 uname({sys=&quot;Linux&quot;, node=&quot;vagrant.localhost&quot;, ...}) = 0 &amp;lt;0.000008&amp;gt;3570  14:24:34.158334 chdir(&quot;/&quot;)        = 0 &amp;lt;0.000000&amp;gt;#第二次及以后3570  14:24:34.842757 chdir(&quot;/www/htdocs/Interview/Web/singlepage&quot;) = 0 &amp;lt;0.000752&amp;gt;3570  14:24:34.843855 setitimer(ITIMER_PROF, {it_interval={0, 0}, it_value={30, 0}}, NULL) = 0 &amp;lt;0.000021&amp;gt;3570  14:24:34.844160 open(&quot;/vagrant/htdocs/Interview/Web/singlepage/test.php&quot;, O_RDONLY) = 21 &amp;lt;0.001091&amp;gt;3570  14:24:34.845657 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000242&amp;gt;3570  14:24:34.846246 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000195&amp;gt;3570  14:24:34.846808 fstat(21, {st_mode=S_IFREG|0777, st_size=42875, ...}) = 0 &amp;lt;0.000166&amp;gt;3570  14:24:34.847286 mmap(NULL, 42875, PROT_READ, MAP_SHARED, 21, 0) = 0x7f9cf614a000 &amp;lt;0.000027&amp;gt;3570  14:24:34.850917 munmap(0x7f9cf614a000, 42875) = 0 &amp;lt;0.000044&amp;gt;3570  14:24:34.851078 close(21)         = 0 &amp;lt;0.000159&amp;gt;3570  14:24:34.851457 uname({sys=&quot;Linux&quot;, node=&quot;vagrant.localhost&quot;, ...}) = 0 &amp;lt;0.000011&amp;gt;3570  14:24:34.856732 chdir(&quot;/&quot;)        = 0 &amp;lt;0.000025&amp;gt;opcache缓存更新当修改了业务代码更新到线上环境后，如果不更新缓存那么实际执行的代码还是旧的，可通过如下方式进行更新。全部更新1.重启apache或php-fpm重启web服务可清除掉所有缓存的opcode信息，之后处理web请求时会重新更新缓存，是最简单也是最保险的做法2.在代码中执行opcache_reset在不方便重启web服务的情况下，可在项目文件中嵌入一个操作opcache的脚本，在需要的时候进行调用局部更新1.自动清理借助如下2个配置，让opcache定期检查脚本是否有变化，从而自动更新缓存opcache.validate_timestamps=1opcache.revalidate_freq=602.手动清理如果知道更新的文件列表，可以使用opcache_invalidate来局部更新，避免影响在此服务器上的所有业务。opcache操作脚本参考资料深入理解PHP原理之OpcodesPHP加速器之opcache配置详解运行时配置PHP7新特性中抽象语法树(AST)的一些介绍"
  },
  
  {
    "title": "redis的安装",
    "url": "/posts/redis-install/",
    "categories": "",
    "tags": "redis",
    "date": "2018-09-24 10:50:00 +0800",
    





    "snippet": "  介绍redis的安装及相关配置说明前言为了可以使用redis来做缓存服务器，首先需要进行服务的安装并启动服务，这里主要介绍的是单机单实例的安装安装与启动1.安装可在官网查看redis的可用版本，一般选择最新的可用版，这里使用的是4.0.11[root@vagrant bmsource]# wget http://download.redis.io/releases/redis-4.0.11.tar.gz[root@vagrant bmsource]# tar zxvf redis-4.0.11.tar.gz[root@vagrant bmsource]# cd redis-4.0.11[root@vagrant redis-4.0.11]# make如果在make后执行make install则redis的相关可执行文件会复制到/usr/local/bin中。此处不使用这种方式，而是手动将可执行文件与配置文件复制到/usr/local/redis中[root@vagrant redis-4.0.11]# cd /usr/local/[root@vagrant local]# mkdir redis[root@vagrant local]# cp /bmsource/redis-4.0.11/src/redis-cli /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/src/redis-check-aof /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/src/redis-check-rdb /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/src/redis-benchmark  /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/src/redis-server /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/src/redis-sentinel /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/redis.conf /usr/local/redis/[root@vagrant local]# cp /bmsource/redis-4.0.11/sentinel.conf /usr/local/redis/可执行文件说明  redis-server：启动redis服务  redis-cli：redis命令行客户端  redis-benchmark：redis基准测试工具  redis-check-aof：Redis AOF持久化文件检测和修复工具  redis-check-dump：Redis RDB持久化文件检测和修复工具  redis-sentinel：启动redis sentinel服务为了以后可以方便使用，将redis路径配置到环境变量中#编辑文件[root@vagrant local]# vim /etc/profile#增加配置export REDIS=/usr/local/redis/export PATH=$PATH:$REDIS#生效配置[root@vagrant local]# source /etc/profile2.启动redis的实际运行需要设置相关配置项，所以启动都是通过配置文件启动，且都是以守护进程模式运行#编辑配置文件[root@vagrant local]# vim /usr/local/redis/redis.conf#设置为守护模式daemonize yes#启动[root@vagrant local]# redis-server /usr/local/redis/redis.conf #客户端查看28191:C 24 Sep 06:25:41.019 # Configuration loaded[root@vagrant local]# redis-cli 127.0.0.1:6379&amp;gt; info server# Serverredis_version:4.0.11redis_git_sha1:00000000redis_git_dirty:0redis_build_id:90349ad45b8aa06aredis_mode:standaloneos:Linux 2.6.32-573.el6.x86_64 x86_64arch_bits:64multiplexing_api:epollatomicvar_api:sync-builtingcc_version:4.4.7process_id:28192run_id:86fc3f7746c55aa156f0af86289422d0aeeb733ftcp_port:6379uptime_in_seconds:76uptime_in_days:0hz:10lru_clock:11043761executable:/usr/local/redis-serverconfig_file:/usr/local/redis/redis.conf127.0.0.1:6379&amp;gt; 3.单机多实例资源不够，使用服务器的多进程与多线程，最大内存配置，错时持久化。配置文件此配置文件redis.conf对应的是redis-server，为单服务的配置基本配置						基本配置							名称			说明			默认值			可选值			支持热配置							daemonize			守护进程			no			yes|no			no							port			端口号			6379			整数			no							loglevel			日志级别			notice			debug|verbose|notice|warning			yes							logfile			日志文件			空			可按端口号区别			no							databases			数据库数量			16			整数			no							unixsocket			unix套接字			空(不监听)			套接字文件			no							unixsocketperm			unix套接字权限			0			linux三位数权限			no							pidfile			进程文件			/var/run/redis.pid			/var/run/redis_{port}.pid			no							lua-time-limit			lua脚本超时时间			单位：毫秒			5000			整数，超时还会执行			script kill 或 shutdown			yes							tcp-backlog			tcp-backlog			511			整数			no							watchdog-period			检查redis延迟问题			的周期			0			整数			yes							activerehashing			重置hash			yes			yes：延迟要求不高，可尽快释放内存			no：延迟要求很高			yes							dir			工作目录			./(当前目录)			自定义目录			yes			最大内存配置内存淘汰算法：  lru（Least recently used）：最近最少使用  lfu（Least Frequently Used）：最不经常使用						最大内存							名称			说明			默认值			可选值			支持热配置							maxmemory			最大可用内存(字节)			0(不限制)			整数			yes							maxmemory-policy			内存淘汰策略			如果设置了最大内存			noeviction			volatile-lru：可过期键，lru算法			allkeys-lru：所有键，lru算法			volatile-lfu：可过期键，lfu算法			allkeys-lfu：所有键，lru算法			volatile-random：可过期键，随机			allkeys-random：所有键，随机			volatile-ttl：可过期键，最近要过期键			noeviction：不淘汰，执行写命名返回错误			yes							maxmemory-samples			lru,lfu,ttl采样数			5			整数			yes			AOF配置						AOF							名称			说明			默认值			可选值			支持热配置							appendonly			开启aof持久化			no			yes|no			yes							appendfsync			同步磁盘频率			everysec			no|always|everysec			yes							appendfilename			aof文件名			appendonly.aof			appendonly_{port}.aof			no							aof-load-truncated			加载aof文件，是否忽略			aof不完整的情况			yes			yes|no			yes							no-appendfsync-on-rewrite			rewrite期间对新的写入			是否不执行fsync			no			yes|no			yes							auto-aof-rewrite-min-size			触发自动重写的aof文件			的最小阀值(兆)			(即使不配置同步频率？)			64M			整数			yes							auto-append-rewrite-percentage			触发自动重写的aof文件			的增长比例条件			(即使不配置同步频率？)			100			整数			yes							aof-rewrite-incremental-fsync			重写过程中，是否采取			增量文件同步策略，每			32M同步磁盘			yes			yes|no			yes			RDB配置						RDB							名称			说明			默认值			可选值			支持热配置							save			保存条件			save 900 1			save 300 10			save 60 10000			不设置，表示不使用			rdb策略			yes							dbfilename			文件名			dump.rdb			dump_{prot}.rdb			yes							rdbcompression			文件是否压缩			yes			yes|no			yes							rdbchecksum			文件是否校验和			yes			yes|no			yes							stop-writes-on-bgsave-error			当前bgsave执行错误，是否拒绝			redis服务的写请求			下次触发bgsave时会恢复写请求			yes			yes|no			yes			慢查询配置						慢查询							名称			说明			默认值			可选值			支持热配置							slowlog-log-slower-than			慢日志被记录阀值(微秒)			10000			整数			yes							slowlog-max-len			慢日志队列长度			128			整数			yes		 					latency-monitor-threshold			开启redis服务内存延迟监控			高负载的情况下，对性能可能会有影响			0(关闭)			整数			yes			数据结构优化配置						数据结构优化							名称			说明			默认值			可选值			支持热配置							hash-max-ziplist-entries			hash数据结构优化参数			512			整数			yes							hash-max-ziplist-value			hash数据结构优化参数			64			整数			yes							list-max-ziplist-size			list数据结构优化参数			-2			[-5,-1]			&amp;gt;=0			yes							list-compress-depth			list数据结构优化参数			0			&amp;gt;=0			yes							set-max-intset-entries			set数据结构优化参数			512			整数			yes							zset-max-ziplist-entries			zset数据结构优化参数			128			整数			yes							zset-max-ziplist-value			zset数据结构优化参数			64			整数			yes							hll-sparse-max-bytes			HyperLogLog数据结构优化参数			3000			整数			yes			主从复制配置						主从复制							名称			说明			默认值			可选值			支持热配置							slaveof			从节点属于哪个主节点			空			ip+port			no			可使用slaveof配置							repl-ping-slave-period			从节点向主节点发送ping命令的周期(s)			10			整数			yes							repl-timeout			主从复制超时时间(s)			(需&amp;gt;repl-ping-slave-period)			60			整数			yes							repl-backlog-size			复制积压缓冲区大小			保存从机断开连接期间的数据			1M			整数			yes							repl-backlog-ttl			积压缓冲区释放时间(s)			从节点缓冲区不能被释放，因为可能被提升为主节点			3600			整数			yes							slave-priority			从节点优先级			越低的会优先被sentinel提升为master			0代表从永远不能变为master			100			[0-100]			yes							min-slaves-to-write			当从节点数&amp;lt;min-slaves-to-write且延迟&amp;lt;=min-slaves-max-lag时，master不接受写入请求。			防止有较多的从机不可用			0			整数			yes							min-slaves-max-lag			10			整数			yes							slave-serve-stale-data			当从节点与主节点断开连接时，从节点是否可以继续提供服务			yes			yes|no			yes							slave-read-only			从节点是否只读			集群模式，从节点读写都不可用，需要使用readonly手动开启			yes			yes|no			yes							repl-disable-tcp-nodelay			是否开启主从复制TCP_NODELAY			yes：合并tcp包，降低带宽，会有延迟			no：立即同步，没有延迟			no			yes|no			yes							repl-diskless-sync			是否开启无盘复制			yes：直接将rdb文件发送到从机			no：先保存rdb文件，逐步将文件发送给从机			no			yes|no			yes							repl-diskless-sync-delay			无盘复制时，开始传送rdb文件的等待时间			用于等待多个从机加入进来，可一起传送			5			&amp;nbsp;			yes			客户端配置						客户端							名称			说明			默认值			可选值			支持热配置							maxclients			最大客户端连接数			10000			整数			yes							client-output-buffer-limit			客户端输出缓冲区限制			normal 0 0 0			slave 256mb 64mb 60			pubsub 32mb 8mb 60			整数			yes							timeout			客户端闲置多久自动关闭连接(s)			0			整数			yes							tcp-keepalive			检查tcp连接活性的周期(s)			300			整数			yes			安全配置						安全							名称			说明			默认值			可选值			支持热配置							requirepass			密码			空			自定义			yes							bind			绑定ip			空			自定义			no							masterauth			从节点配置主节点的密码			127.0.0.1			主节点的密码			yes			参考资料官网redis.confredis开发与运维"
  },
  
  {
    "title": "xhprof使用",
    "url": "/posts/xhprof/",
    "categories": "",
    "tags": "php",
    "date": "2018-09-20 20:50:00 +0800",
    





    "snippet": "  介绍使用xhprof来分析php的性能前言XHProf是一个轻量级的分层性能测量分析器。在数据收集阶段，它跟踪调用次数与测量数据，展示程序动态调用的弧线图。 它在报告、后期处理阶段计算了独占的性能度量，例如运行经过的时间、CPU计算时间和内存开销。 函数性能报告可以由调用者和被调用者终止。在数据搜集阶段XHProf通过调用图的循环来检测递归函数，通过赋予唯一的深度名称来避免递归调用的循环。扩展安装[root@vagrant bmsource]# wget  http://pecl.php.net/get/xhprof-0.9.4.tgz[root@vagrant bmsource]# tar -zxvf xhprof-0.9.4.tgz[root@vagrant bmsource]# cd xhprof-0.9.4[root@vagrant bmsource]# cd extension/[root@vagrant bmsource]# phpize [root@vagrant bmsource]# ./configure[root@vagrant bmsource]# make &amp;amp;&amp;amp; make install[root@vagrant bmsource]# cd /usr/local/php/lib/php/extensions/no-debug-non-zts-20131226/[root@vagrant bmsource]# cp xhprof.so /usr/local/php/lib/php/extensions/xhprof.so扩展使用php.ini为了可以在php中收集性能数据，php.ini需要增加如下配置[xhprof]#扩展文件extension=xhprof.so#收集数据存储的位置#可以直接放到性能分析web下，便于之后的分析使用xhprof.output_dir=/www/htdocs/xhprof/log数据收集在需要进行性能分析的业务代码前后，增加如下代码//开始分析//XHPROF_FLAGS_NO_BUILTINS这个不加导致程序奔溃xhprof_enable(XHPROF_FLAGS_NO_BUILTINS | XHPROF_FLAGS_MEMORY);//业务代码phpinfo();//结束分析$xhprofData = xhprof_disable();//将分析结果保存到xhprof.output_dir定义的位置require &#39;/www/htdocs/xhprof/xhprof_lib/utils/xhprof_lib.php&#39;;require &#39;/www/htdocs/xhprof/xhprof_lib/utils/xhprof_runs.php&#39;;$xhprofRuns = new XHProfRuns_Default();$runId = $xhprofRuns-&amp;gt;save_run($xhprofData, &#39;xhprof_test&#39;);性能查看xhprof自带一个web的可视化性能查看工具，需要配置一个虚拟目录，用来运行webweb目录[root@vagrant bmsource]# cd /www/htdocs/[root@vagrant htdocs]# mkdir xhprof[root@vagrant htdocs]# cd xhprof/[root@vagrant htdocs]# mkdir log#使用xhprof提供的文件[root@vagrant htdocs]# cp -R /bmsource/xhprof-0.9.4/xhprof_html/ xhprof/xhprof_html/[root@vagrant htdocs]# cp -R /bmsource/xhprof-0.9.4/xhprof_lib/ xhprof/xhprof_lib/虚拟目录#httpd-vhosts.conf&amp;lt;VirtualHost *:80&amp;gt;    DocumentRoot &quot;/www/htdocs/xhprof/xhprof_html&quot;    ServerName xhprof.**.com&amp;lt;Directory &quot;/www/htdocs/xhprof/xhprof_html&quot;&amp;gt;    Options FollowSymLinks    AllowOverride None    Require all granted&amp;lt;/Directory&amp;gt;&amp;lt;IfModule dir_module&amp;gt;    DirectoryIndex index.php &amp;lt;/IfModule&amp;gt;&amp;lt;/VirtualHost&amp;gt;网站访问安装图形组件[root@vagrant xhprof]# yum install graphviz配置本地hostsxhprof.**.com 10.100.255.115访问网站，可看到方法调用的统计信息  funciton name：函数名  calls：调用次数  calls：调用次数（占比）  Incl. Wall Time (microsec)：函数运行时间（包括子函数）  IWall%：函数运行时间（占比）  Excl. Wall Time(microsec)：函数运行时间（不包括子函数）  EWall%：函数运行时间（占比）点击[View Full Callgraph]可看到图形分析参考资料层次式性能分析器xhprof"
  },
  
  {
    "title": "redis的内存",
    "url": "/posts/redis-memory/",
    "categories": "",
    "tags": "redis",
    "date": "2018-09-12 10:50:00 +0800",
    





    "snippet": "  介绍redis的内存相关优化。内存消耗1.内存使用统计通过如下命令可获取redis实例的内存使用情况127.0.0.1:6379&amp;gt; info memory						属性说明							used_memory:12597672			redis的当前内存							used_memory_human:12.01M							used_memory_rss:17149952			系统显示的redis进程内存							used_memory_rss_human:16.36M							used_memory_peak:14492352			redis的最大内存							used_memory_peak_human:13.82M							used_memory_peak_perc:86.93%							total_system_memory:4018454528			系统内存							total_system_memory_human:3.74G							used_memory_lua:37888			lua引擎内存							used_memory_lua_human:37.00K							maxmemory:1073741824			最大可用内存							maxmemory_human:1.00G							maxmemory_policy:noeviction							mem_fragmentation_ratio:1.36			内存碎片率			used_memory_rss/used_memory							mem_allocator:jemalloc-4.0.3			内存分配器			需要特别注意内存碎片率：  mem_fragmentation_ratio&amp;gt;1：说明存在内存碎片，如果比值很大则碎片率较严重，可重启实例解决  mem_fragmentation_ratio&amp;lt;1：说明redis内存已超过系统内存，产生了磁盘交换，会导致redis的性能大幅下降2.内存使用划分redis的内存使用主要包括：自身内存，对象内存，缓冲内存，内存碎片自身内存(used_memory)一个空的redis，used_memory为800k左右，used_memory_rss在2M左右，也就是说redis自身占用的内存很小对象内存(used_memory)用于存储所有的数据，包括key与value，是占用内存最大的缓冲内存(used_memory)缓存内存包括：客户端缓冲、复制积压缓冲区、AOF缓冲区内存碎片(used_memory_rss-used_memory)redis默认使用的是jemalloc内存分配器，在64位系统下，会按照如下规则进行分配内存：  小：[8byte]，[16byte，32byte，48byte，…，128byte]，[192byte，256byte，…，512byte]，[768byte，1024byte，…，3840byte]  大：[4KB，8KB，12KB，…，4072KB]  巨大：[4MB，8MB，12MB，…]当为了存储5KB的对象时，会采用8KB的块存储，剩下的3KB就会变成碎片，而不能分配给其他对象使用。下面的情况可能会出现较多的内存碎片：  频繁的更新操作，对已存在的键做append，setrange等更新操作  大量的键在过期后删除，释放的空间不能充分利用可通过如下方式尝试解决：  数据对齐：在条件允许的情况做数据对齐，比如尽量采用数字类型或固定长度的字符串  安全重启：如果redis做了高可用，可重启碎片率较高的节点，注意保证服务的可用性3.子进程内存消耗子进程内存消耗主要是执行AOF/RDB重写时Redis创建的子进程内存消耗，理论上需要1倍的父进程内存来完成重写，但是因为Linux的写时复制技术（copy-on-write），子进程并不需要消耗1倍的父进程内存，但最好还是预留出一些内存（父进程内存的[0%-100%]）用于子进程的重写操作，防止内存溢出。如下设置可用于避免一些内存问题：1.允许内核可以分配所有的物理内存，防止Redis进程执行fork时因系统剩余内存不足而失败[root@DEV-HROEx64 mm]# sysctl vm.overcommit_memory=1[root@DEV-HROEx64 redis]# vim /etc/sysctl.conf2.关闭Linux的THP（Transparent Huge Pages）机制，此机制会导致copy-on-write期间复制内存页的单位从4KB变为2MB，如果父进程有大量写命令，会加重内存拷贝量，从而造成过度内存消耗[root@DEV-HROEx64 mm]# echo never &amp;gt; /sys/kernel/mm/redhat_transparent_hugepage/enabled[root@DEV-HROEx64 mm]# vim /sys/kernel/mm/redhat_transparent_hugepage内存管理1.服务器内存一台单纯的redis服务器，内存使用主要包括如下几个部分：  linux系统本身（1G）  其它一些服务进程（1G）  redis主进程，可能有多个实例（剩余内存/实例个数+0.5）  redis子进程（子进程执行过程中写入命令量，可粗略为单实例的50%）上述数值只作为参考使用，具体配置需要结合实际情况。Tips：如果单机部署多个实例，且实例都有持久化需求，需要避免多实例在同一时间进行持久化操作，防止内存溢出2.内存上限设置maxmemory的作用：  当缓存使用的内存超过maxmemory时，触发内存回收策略释放空间  防止内存超过物理内存，而产生磁盘交换，大幅降低redis的性能根据1中的计算，可以得出可设置的maxmemory。Tips：因为内存碎片的原因，此处的maxmemory=used_memory，而非used_memory_rss，所以要注意这部分是否会导致内存溢出3.动态调整内存上限使用如下命令，可用来为正在运行中的redis进程动态修改最大内存，以满足需求127.0.0.1:6379&amp;gt; CONFIG set maxmemory 1G4.内存回收策略1.过期键删除  惰性删除：当客户端读取带超时属性的键时，如果键已过期则进行删除并返回空  定时任务删除：定时任务，默认每秒运行10次（config hz），回收过期键算法如下慢模式与快模式的内部执行逻辑相同，只是执行超时时间不同，慢模式为25ms超时，快模式为1ms且2秒内只能运行一次。2.内存溢出控制策略  noeviction：默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作  allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止  allkeys-random：随机删除所有键，直到腾出足够空间为止  volatile-lru：根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止。如果没有可删除的键对象，回退到noeviction策略  volatile-random：随机删除过期键，直到腾出足够空间为止  volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略redis每次执行命令时都会尝试回收内存的操作，如果redis一直运行在（used_memory&amp;gt;maxmemory）且回收策略非（noeviction）的情况时，会频繁触发回收内存的操作，从而影响性能。Tips：为了避免频繁回收内存产生的开销，redis最好工作在maxmemory&amp;gt;used_memory状态下内存优化1.redisObject对象redis存储的数据都是使用redisObject对象进行封装的，包含如下属性：						type			unsigned 4			0.5B			对象的数据类型			string、hash、list、set、zset							encoding			unsigned 4			0.5B			对象的编码类型			对象在内部使用哪种数据结构							lru			unsigned LRU_BITS(24)			3B			LRU计时时钟			对象最后一次被访问的时间							refcount			int			4B			引用计数器			对象被引用的次数，当为0时，可以安全回收当前对象空间							*ptr			void(64位系统)			8B			数据指针			整数：直接存储数据			其它：指向数据的指针			Tips：当存储的值为字符串类型且长度&amp;lt;=44字节时，内部编码会使用embstr类型，字符串sds和redisObject一起分配，从而只要一次内存操作即可，在高并发常见如果能控制字符串长度可以提高性能2.缩减键值对象keyredis的key是使用string存储，需要占用存储空间，所以设计键时，在满足业务区分的情况下，尽量越短越好value  精简业务信息，去除不必要存储的数据  将字符串进行压缩后存储Tips：选用压缩工具时，需要综合考虑压缩速度和计算开销成本3.共享对象池redis内部维护了[0-9999]的整数对象池，当创建整数值对象或list、hash、set、zset的内部元素为整数值时可以直接使用对象池的整数对象，从而节约内存。Tips：当设置maxmemory并启用LRU相关淘汰策略如：volatile-lru，allkeys-lru时，Redis禁止使用共享对象池；对于ziplist编码的值对象，也是不能使用共享对象池，因为ziplist使用压缩且内存连续，对象判断成本过高为何只有整数对象池：  复用几率大  比较算法的时间复杂度为o(1)，字符串为o(n)，其他复杂数据结构如hash,list等需要o(n*n)4.字符串优化redis中所有键都是字符串类型，值对象除了整数都使用字符串存储。字符串结构redis的字符串结构为简单动态字符串（simple dynamic string），结构如下：  len[int]:已用字节长度  free[int]:未用字节长度  buf[][char]:字节数组sds字符串结构有如下特点：  o(1)时间复杂度获取：字符串长度，已用长度，未用长度  保存字节数组，支持安全的二进制数据存储  内部实现空间预分配机制，降低内存再分配的频率  惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留预分配机制当对字符串进行append，setrange等修改操作时，会触发预分配机制，避免不断的重分配内存和字节数据复制，但同时会造成内存的浪费。空间预分配规则如下：  第一次创建len属性等于数据实际大小，free等于0，不做预分配  修改后如果已有free空间不够且数据小于1M，每次预分配一倍容量。如原有len=60byte，free=0，再追加60byte，预分配120byte，总占用空间：60byte+60byte+120byte+1byte  修改后如果已有free空间不够且数据大于1MB，每次预分配1MB数据。如原有len=10MB，free=0，当再追加100byte，预分配1MB，总占用空间：10MB+100byte+1MB+1byteTips：减少字符串的部分修改操作（append，setrange等），直接使用set来修改整个字符串，降低预分配带来的内存浪费与内存碎片率字符串重构不一定把每份数据作为字符串整体存储，像json这样的数据可以使用hash结构，使用二级结构存储也能帮我们节省内存。同时可以使用hmget、hmset命令支持字段的部分读取修改，而不用每次整体存取5.编码优化redis中类型与编码的对应关系如下：						类型			编码			数据结构			条件							string			int			整数编码			8个字节的长整型							embstr			优化内存分配的字符串编码			小于等于44个字节的字符串							raw			动态字符串编码			大于44个字节的字符串							hash			ziplist			压缩列表编码			field个数&amp;lt;=hash-max-ziplist-entries(默认512)			value最大空间(字节)&amp;lt;=hash-max-ziplist-value配置(默认64)							hashtable			散列表编码			不满足ziplist条件							list			quicklist			快速列表编码			ziplist组成的双向链表			list-max-ziplist-size(正数)：节点ziplist最多包含的entry个数			list-max-ziplist-size(负数[-5 -1])：节点ziplist的字节大小			list-compress-depth：压缩深度(默认0，不压缩)							set			intset			整数集合编码			元素都是整数			集合长度&amp;lt;=set-max-intset-entries(默认512)							hashtable			散列表编码			不满足intset条件							zset			ziplist			压缩列表编码			field个数&amp;lt;=zset-max-ziplist-entries(默认128)			value最大空间(字节)&amp;lt;=zset-max-ziplist-value配置(默认64)							skiplist			跳跃表编码			不满足ziplist条件时			在了解了内部编码后，就可以通过调节条件参数来让redis使用对应的编码，从而减少内存，不过调整也不是随意的，需要慎重考虑。Tips：编码类型的转换是写入redis数据时自动进行的，且转换只能从小内存编码往大内存编码进行。6.控制键的数量当redis中存在大量的键时，也会消耗内存，可以根据业务情况，利用redis中hash等数据结构，进行二级存储，降低外层键数量，从而节省内存。在进行此类优化时，需要注意如下情况：  hash编码必须调整为使用ziplist，ziplist长度控制在1000内，存储的对象需要为小对象，预估键规模设计hash的分组规模  hash重构后键不能使用超时(expire)与淘汰(lru)机制自动删除，需要手动维护参考资料redis开发与运维linux写时复制lru算法redisObjectc语言指针占几个字节quicklistredis info信息"
  },
  
  {
    "title": "mysql连接池",
    "url": "/posts/mysql-connection-pool/",
    "categories": "",
    "tags": "mysql, php",
    "date": "2018-08-30 10:00:00 +0800",
    





    "snippet": "  介绍在php中怎么实现连接池。前言php作为脚本语言在每次运行结束后会销毁所有状态，不能将状态常驻在内存中，从而就不能像java等常驻内存的语言一样，可以实现全功能的连接池。这里利用swoole这种可以常驻内存的扩展来实现php的连接池。处理流程实现1.服务端创建常驻内存运行的swoole服务，用于接收客户端的请求来执行数据操作。  worker_num：接受外部数据操作请求的并发数  task_worker_num：连接池中的可用连接数/** * 准备服务 */protected function prepare() {    //实例化对象    //swoole_get_local_ip()获取本机ip    $this-&amp;gt;objServer = new swoole_server(Config::get(&#39;database.devmanager.connect_pool.host&#39;), Config::get(&#39;database.devmanager.connect_pool.port&#39;));    //设置运行参数    $this-&amp;gt;objServer-&amp;gt;set(array(        &#39;daemonize&#39; =&amp;gt; 1, //以守护进程执行        &#39;max_request&#39; =&amp;gt; 10000, //worker进程在处理完n次请求后结束运行        &#39;worker_num&#39; =&amp;gt; Config::get(&#39;database.devmanager.connect_pool.worker_num&#39;),        &#39;task_worker_num&#39; =&amp;gt; Config::get(&#39;database.devmanager.connect_pool.task_num&#39;),        &quot;task_ipc_mode &quot; =&amp;gt; 3, //使用消息队列通信，并设置为争抢模式,        &#39;heartbeat_check_interval&#39; =&amp;gt; 5, //每隔多少秒检测一次，单位秒，Swoole会轮询所有TCP连接，将超过心跳时间的连接关闭掉        &#39;heartbeat_idle_time&#39; =&amp;gt; 10, //TCP连接的最大闲置时间，单位s , 如果某fd最后一次发包距离现在的时间超过则关闭        &#39;open_eof_split&#39; =&amp;gt; true,        &#39;package_eof&#39; =&amp;gt; &quot;\\r\\n&quot;,        &quot;log_file&quot; =&amp;gt; $this-&amp;gt;objApp-&amp;gt;make(&#39;path.storage&#39;) . &quot;\\log\\\\&quot; . Config::get(&#39;database.devmanager.connect_pool.log_file&#39;)    ));    //设置事件回调    $this-&amp;gt;objServer-&amp;gt;on(&#39;Connect&#39;, array($this, &#39;onConnect&#39;));    $this-&amp;gt;objServer-&amp;gt;on(&#39;Receive&#39;, array($this, &#39;onReceive&#39;));    $this-&amp;gt;objServer-&amp;gt;on(&#39;Finish&#39;, array($this, &#39;onFinish&#39;));    $this-&amp;gt;objServer-&amp;gt;on(&#39;Task&#39;, array($this, &#39;onTask&#39;));    $this-&amp;gt;objServer-&amp;gt;on(&#39;WorkerStart&#39;, array($this, &#39;onWorkerStart&#39;));}/** * 接收到数据时 */public function onReceive($objServer, $fd, $reactor_id, $strData) {    //1.接受到业务数据操作，分配给空闲连接执行    $mixResult = $objServer-&amp;gt;taskwait($strData, 3);    if ($mixResult === false) {        $mixResult = json_encode([&#39;success&#39; =&amp;gt; 0, &#39;result&#39; =&amp;gt; [], &#39;err_msg&#39; =&amp;gt; &#39;task timeout&#39;]);    }    $blnFlag = $objServer-&amp;gt;send($fd, $mixResult);    if (!$blnFlag) {        //记录日志    }}/** * 处理投递的任务 */public function onTask($objServer, $task_id, $src_worker_id, $strData) {    //1.参数解析    $strData = preg_replace(&#39;/\\r\\n/&#39;, &#39;&#39;, $strData);    $arrData = json_decode($strData, true);    //2.执行数据操作    $arrReturn = [];    switch ($arrData[&#39;type&#39;]) {        case &#39;select&#39;:            $this-&amp;gt;objDB-&amp;gt;setMainTable($arrData[&#39;main_table&#39;]);            $blnException = false;            $arrTmp = $this-&amp;gt;objDB-&amp;gt;select($arrData[&#39;sql&#39;], $arrData[&#39;param&#39;], $arrData[&#39;sql&#39;], $blnException);            $arrReturn = [&#39;success&#39; =&amp;gt; $blnException ? 0 : 1, &#39;result&#39; =&amp;gt; $arrTmp, &#39;err_msg&#39; =&amp;gt; &#39;&#39;];            break;        default:            $arrReturn = [&#39;success&#39; =&amp;gt; 0, &#39;result&#39; =&amp;gt; [], &#39;err_msg&#39; =&amp;gt; &#39;type类型错误&#39;];            break;    }    //数据返回    return json_encode($arrReturn) . &quot;\\r\\n&quot;;}2.客户端连接swoole服务进行数据操作的请求。$objClient = new swoole_client(SWOOLE_SOCK_TCP | SWOOLE_KEEP);//设置eof检测$objClient-&amp;gt;set([    &#39;open_eof_check&#39; =&amp;gt; true,    &#39;package_eof&#39; =&amp;gt; &quot;\\r\\n&quot;]);if ($objClient-&amp;gt;connect(&#39;127.0.0.1&#39;, 9602) !== false) {    $strtmp = json_encode([&#39;main_table&#39; =&amp;gt; &#39;test&#39;, &#39;type&#39; =&amp;gt; &#39;select&#39;, &#39;sql&#39; =&amp;gt; &quot;select * from test where 1=1&quot;, &#39;param&#39; =&amp;gt; []]);    $arrTmp = $objClient-&amp;gt;send($strtmp . &quot;\\r\\n&quot;);    var_dump(json_decode($objClient-&amp;gt;recv(), true));}3.结果数据库进程此类中开启的连接池个数为2，所以可以看到进程始终保持在2个。mysql&amp;gt; show full processlist;+-----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id  | User            | Host            | db         | Command | Time   | State                  | Info                  |+-----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|   4 | event_scheduler | localhost       | NULL       | Daemon  | 529101 | Waiting on empty queue | NULL                  ||  83 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 309 | test            | 127.0.0.1:45384 | devmanager | Sleep   |     71 |                        | NULL                  || 310 | test            | 127.0.0.1:45386 | devmanager | Sleep   |     71 |                        | NULL                  |+-----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+4 rows in set (0.00 sec)又执行了几次web请求，都是复用的现有连接。mysql&amp;gt; show full processlist;+-----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id  | User            | Host            | db         | Command | Time   | State                  | Info                  |+-----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|   4 | event_scheduler | localhost       | NULL       | Daemon  | 529128 | Waiting on empty queue | NULL                  ||  83 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 309 | test            | 127.0.0.1:45384 | devmanager | Sleep   |      3 |                        | NULL                  || 310 | test            | 127.0.0.1:45386 | devmanager | Sleep   |      3 |                        | NULL                  |+-----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+4 rows in set (0.00 sec)sql日志当连接池中连接还没建立时，第一次建立连接，所花的时间为10几毫秒Date:[2018-08-30 18:22:28]ClientIP:[10.0.2.15]ServerIP:[10.0.2.15]Url:[mysql_connect_pool]UserID:[]Memo:[ sql:select * from test where 1=1  param:[]  startdate:2018-08-30 18:22:28.089  enddate:2018-08-30 18:22:28.139 ]当连接池中连接已经建立后，之后的sql操作可以直接使用连接，而不需要重新建立连接，所花的时间为几毫秒----------------------------------------------------------------------Date:[2018-08-30 18:24:22]ClientIP:[10.0.2.15]ServerIP:[10.0.2.15]Url:[mysql_connect_pool]UserID:[]Memo:[ sql:select * from test where 1=1  param:[]  startdate:2018-08-30 18:24:22.268  enddate:2018-08-30 18:24:22.268 ]----------------------------------------------------------------------Date:[2018-08-30 18:25:14]ClientIP:[10.0.2.15]ServerIP:[10.0.2.15]Url:[mysql_connect_pool]UserID:[]Memo:[ sql:select * from test where 1=1  param:[]  startdate:2018-08-30 18:25:14.338  enddate:2018-08-30 18:25:14.339 ]结语数据库的连接池在网站并发量超级大的时候（连接数万级以上），此时数据库就会有压力，可以考虑使用，少于这个量级一般长连接或者单例就可以满足业务需求了。从直连数据库转变为通过swoole连接数据库，由于与swoole之间的通信也需要时间，所以总时间上可能会比直连消耗的多。参考资料基于swoole扩展实现PHP数据库连接池Swoole文档"
  },
  
  {
    "title": "mysql持久化连接",
    "url": "/posts/mysql-persistent/",
    "categories": "",
    "tags": "mysql, php",
    "date": "2018-08-28 16:20:00 +0800",
    





    "snippet": "  介绍在持久化连接的特性。概述短连接：每次web请求需要与数据库进行交互时，都重新建立数据库连接，从而需要进行3次握手，请求结束关闭连接时也会3/4次的网络通信。可能会增加一定的延时与额外的IO消耗。长连接：每次web请求需要与数据库进行交互时，如果进程可以复用已存在的连接则直接使用，避免重新建立新的连接，节省IO的消耗。实现与使用1.实现方式php的长连接是搭载在apache这样的带有mpm模块的webserver，linux下apache会维护一个进程池，开启了apache mpm功能之后，apache会默认维持一个进程池，mysql长连接之后的连接，并没有作为socet连接关闭，而是作为一个不释放的东西，放进了进程池/线程池里面去，等需要连接的时，apache从它维护的进程池/线程池里面取出mysql  socket connnection, 然后就可以复用此连接了。2.适用场景不适用：  cli：脚本执行完，连接就会直接释放  apache+mpm（不开启）：请求结束，连接就会直接释放  nginx+php-fpm：大部分情况不支持（没测试过）适用：  apache+mpm（开启）：请求结束，连接不会直接释放，除非到超时时间  常驻内存进程（如swoole）：因为是常驻服务，只要建立连接就会存在（除非超时被关闭），变相的实现了长连接web请求测试1.测试准备为了在测试时可以比较方便的观察连接，将apache的并发处理数调整为1。httpd.conf#启用httpd-mpm模块Include conf/extra/httpd-mpm.confhttpd-mpm.conf&amp;lt;IfModule mpm_prefork_module&amp;gt;    StartServers             1    MinSpareServers          1    MaxSpareServers         1    MaxRequestWorkers      1    MaxConnectionsPerChild   0&amp;lt;/IfModule&amp;gt;2.长连接连接代码$this-&amp;gt;objPdoRead = new PDO($strDsn, &#39;username&#39;, &#39;password&#39;, [PDO::ATTR_TIMEOUT =&amp;gt; 3, PDO::ATTR_PERSISTENT =&amp;gt; true]);端口查看[root@vagrant ~]# netstat -anp|grep 3306当执行多次web请求时，端口始终为一个。[root@vagrant ~]# netstat -anp|grep 3306tcp        1      0 127.0.0.1:40840             127.0.0.1:3306              CLOSE_WAIT  5539/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         [root@vagrant ~]# netstat -anp|grep 3306tcp        0      0 127.0.0.1:40844             127.0.0.1:3306              ESTABLISHED 5539/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40844      ESTABLISHED 2714/mysqld         [root@vagrant ~]# netstat -anp|grep 3306tcp        0      0 127.0.0.1:40844             127.0.0.1:3306              ESTABLISHED 5539/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40844      ESTABLISHED 2714/mysqld         [root@vagrant ~]# netstat -anp|grep 3306tcp        0      0 127.0.0.1:40844             127.0.0.1:3306              ESTABLISHED 5539/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40844      ESTABLISHED 2714/mysqld    进程查看当执行多次web请求时，连接进程为同一个，进程空闲时间会进行刷新。mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 354374 | Waiting on empty queue | NULL                  || 41 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 57 | test            | 127.0.0.1:40844 | devmanager | Sleep   |      4 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 354384 | Waiting on empty queue | NULL                  || 41 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 57 | test            | 127.0.0.1:40844 | devmanager | Sleep   |      2 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 354388 | Waiting on empty queue | NULL                  || 41 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 57 | test            | 127.0.0.1:40844 | devmanager | Sleep   |      1 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)tcp包查看[root@vagrant ~]# tcpdump -s 0 -l -w - dst 127.0.0.1 and port 3306 -i any -w /www/htdocs/Interview/logs/mysql.cap当执行多次web请求时，只有第一次进行了3次tcp握手，之后不需要。长连接.cap3.短连接连接代码$this-&amp;gt;objPdoRead = new PDO($strDsn, &#39;username&#39;, &#39;password&#39;, [PDO::ATTR_TIMEOUT =&amp;gt; 3]);端口查看[root@vagrant ~]# netstat -anp|grep 3306当执行多次web请求时，端口每次都是不同的。[root@vagrant ~]# netstat -anp|grep 3306tcp        0      0 127.0.0.1:40858             127.0.0.1:3306              ESTABLISHED 5833/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40858      ESTABLISHED 2714/mysqld         [root@vagrant ~]# netstat -anp|grep 3306tcp        0      0 127.0.0.1:40859             127.0.0.1:3306              ESTABLISHED 5833/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40858      TIME_WAIT   -                   tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40859      ESTABLISHED 2714/mysqld         [root@vagrant ~]# netstat -anp|grep 3306tcp        0      0 127.0.0.1:40860             127.0.0.1:3306              ESTABLISHED 5833/httpd          tcp        0      0 :::33060                    :::*                        LISTEN      2714/mysqld         tcp        0      0 :::3306                     :::*                        LISTEN      2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40860      ESTABLISHED 2714/mysqld         tcp        0      0 ::ffff:127.0.0.1:3306       ::ffff:127.0.0.1:40859      TIME_WAIT   -                   [root@vagrant ~]# 进程查看当执行多次web请求时，连接进程每次都不相同。mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 412839 | Waiting on empty queue | NULL                  || 58 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 62 | test            | 127.0.0.1:40855 | devmanager | Sleep   |      3 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 412856 | Waiting on empty queue | NULL                  || 58 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 63 | test            | 127.0.0.1:40856 | devmanager | Sleep   |      1 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 412876 | Waiting on empty queue | NULL                  || 58 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 64 | test            | 127.0.0.1:40857 | devmanager | Sleep   |      2 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)tcp包查看[root@vagrant ~]# tcpdump -s 0 -l -w - dst 127.0.0.1 and port 3306 -i any -w /www/htdocs/Interview/logs/mysql.cap当执行多次web请求时，每次都进行了3次tcp握手。短连接.cap4.长连接与短连接混用1.使用长连接连接一次，查看进程状态，id=68为长连接。mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 413692 | Waiting on empty queue | NULL                  || 58 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 68 | test            | 127.0.0.1:40861 | devmanager | Sleep   |     27 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)2.使用短连接连接一次，查看进程状态，id=69为短连接，没有能够复用长连接。mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 413701 | Waiting on empty queue | NULL                  || 58 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 68 | test            | 127.0.0.1:40861 | devmanager | Sleep   |     36 |                        | NULL                  || 69 | test            | 127.0.0.1:40862 | devmanager | Sleep   |      7 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+4 rows in set (0.00 sec)3.使用长连接连接一次，查看进程状态，id=68为短连接，复用了长连接。mysql&amp;gt; show full processlist;+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+| Id | User            | Host            | db         | Command | Time   | State                  | Info                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+|  4 | event_scheduler | localhost       | NULL       | Daemon  | 413720 | Waiting on empty queue | NULL                  || 58 | root            | localhost       | NULL       | Query   |      0 | starting               | show full processlist || 68 | test            | 127.0.0.1:40861 | devmanager | Sleep   |      5 |                        | NULL                  |+----+-----------------+-----------------+------------+---------+--------+------------------------+-----------------------+3 rows in set (0.00 sec)综上，如果项目中长连接与短连接混合用，短连接不能复用长连接建立的连接，而长连接可以。总结长连接的优缺点：  优点：  1.复用连接，减少了连接阶段的IO消耗  2.减少了TIME_WAIT数量  缺点：  1.当长连接占满服务器的最大连接时，会导致新连接连接不上  2.长连接的维护需要依赖web服务器，在使用前需要确保环境支持短连接的优缺点：  优点：  1.每次连接使用后会关闭连接，不会一直占用  2.使用场景不依赖于服务器环境  缺点：  1.每次都是新建连接，额外消耗一些IO与时间  2.频繁的连接会产生较多的TIME_WAITTips：以下只是参考情况，实际应用需要综合多方面的考虑。一般应用（日pv=百万级，连接数不多）：短连接+数据库单例中型应用（日pv=千万级，连接数较多）：长连接+数据库单例超大应用（日pv&amp;gt;千万级，连接数超多）：连接池+数据库单例参考资料连接与连接管理MySQL的连接池、异步、断线重连mysql 关于php mysql长连接、连接池的一些探索"
  },
  
  {
    "title": "redis的api使用",
    "url": "/posts/redis-api/",
    "categories": "",
    "tags": "php, redis",
    "date": "2018-08-21 15:00:00 +0800",
    





    "snippet": "  介绍redis中数据结构及api的使用。前言1.数据结构与内部编码redis主要包含5种数据结构，每种数据结构的内部编码可能有多个，redis会根据实际使用情况选择合适的编码，来优化内存与性能。#数据结构127.0.0.1:6379[1]&amp;gt; type k_stringstring#内部编码127.0.0.1:6379[1]&amp;gt; OBJECT encoding k_string&quot;int&quot;数据结构与内部编码对应关系。Tips：内部编码的限定条件，可能会根据redis的不同版本有所调整或者增加新的内部编码，这里的版本为3.0.7。redis里中文占3个字节。						数据结构			内部编码			备注			优点			缺点							string			int			8个字节的长整型													embstr			小于等于39个字节的字符串													raw			大于39个字节的字符串													hash			ziplist(压缩列表)						元素个数小于hash-max-ziplist-entries配置(默认512个)，同时所有值都小于hash-max-ziplist-value配置(默认64字节)						节省内存			读写效率不足							hashtable(哈希表)			不满足ziplist条件时						读写为o(1)							list			ziplist(压缩列表)						元素个数小于list-max-ziplist-entries配置(默认512个)，同时所有值都小于list-max-ziplist-value配置(默认64字节)						节省内存										linkedlist(链表)			不满足ziplist条件时													set			intset整数集合			元素都是整数且元素个数小于set-maxintset-entries配置(默认512个)			节省内存										hashtable(哈希表)			不满足intset条件时													zset			ziplist			元素个数小于zset-max-ziplist-entries配置(默认128个)，同时每个元素的值都小于zset-max-ziplist-value配置(默认64字节)			节省内存										skiplist			不满足ziplist条件时									2.单线程redis使用的是单线程与I/O多路复用模式，所有到服务器的命令都会进行排队然后逐个执行，所以需要特别注意每个命令的执行时间，因为可能会阻塞其它命令的执行。redis高性能因素：  纯内存访问，内存响应时间100纳秒左右  非阻塞I/O，使用epoll作为I/O多路复用技术的实现，再加上redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间  避免线程切换与竞态产生的消耗字符串字符串是最基础的数据结构，字符串的值可以是字符串（简单的字符串、复杂的字符串（例如JSON、XML））、数字（整数、浮点数），甚至是二进制（图片、音频、视频），但是值最大不能超过512MB。1.常用命令						命令类型			命令格式			备注			复杂度			官方说明							增/改			set key value [EX seconds] [PX milliseconds] [NX|XX]			设置键的值			o(1)			link							getset key value			设置键的值，返回原值			o(1)			link							mset key value [key value ...]			设置多个键值对			o(n)			link							setrange key offset value			替换键的值			o(1)/o(m)			link							append key value			追加键的值			o(1)			link							删			del key [key ...]			删除键，阻塞			o(n)			link							unlink key [key ...]			删除键，非阻塞			o(n)			link							查			get key			获取键的值			o(1)			link							mget key [key ...]			获取多个键的值			o(n)			link							其它			incr key			键的值加1			o(1)			link							incrby key increment			键的值加给定值，整数			o(1)			link							incrbyfloat key increment			键的值加给定值，浮点数			o(1)			link							decr key			键的值减1			o(1)			link							decrby key			键的值减给定值			o(1)			link							strlen key			获取键的值长度			o(1)			link			2.使用场景数据缓存将redis作为缓存层，mysql作为存储层，可以加速读写，降低数据库的压力。一般思路，如果缓存有读缓存，缓存没有从库里读取后返回数据，同时将数据放入缓存+过期时间，等待下次的数据访问。计数可用于记录商品被查看的次数、视频观看次数等，异步将统计数据同步到存储层。session共享目前大多数的web网站都会使用负载均衡来提高网站的可用性与并发量，如果session存储在各自服务器上的话，可能就会导致用户在A服务器存的session，当用户访问到B服务器时找不到session的情况。可将用户的session信息存储到redis中，在redis是高可用的情况下，无论用户访问的是哪台服务器，都可以获取到session信息。token共享对于像微信token这种每天有获取上限的token，需要将token记录到涉及web应用都可以访问到的地方，使用redis记录是一个不错的选择。限流为了防止接口被恶意调用，或者对于某些接口在一定时间范围内有调用限制，可使用redis的带过期时间的数值key来处理。哈希哈希结构也可以叫做字典、关联数组等，键的值是(field-value)的映射关系。1.常用命令						命令类型			命令格式			备注			复杂度			官方说明							增/改			hset key field value			设置键的field-value，单个			o(1)			link							hmset key field value [field value ...]			设置键的field-value，多个			o(n)			link							hsetnx key field value			设置键的field-value，当field不存在时			o(1)			link							删			hdel key field [field ...]			删除键的field			o(n)			link							查			hget key field			获取键的field-value，单个field			o(1)			link							hmget key field [field ...]			获取键的field-value，多个field			o(n)			link							hgetall key			获取键的field-value，所有field此命名为重命令，控制获取元素个数			o(n)			link							hkeys key			获取键的所有field			o(n)			link							hvals key			获取键的所有field对应的value			o(n)			link							其它			hexists key field			判断键是否存在field			o(1)			link							hincrby key field increment			键的field对应value加给定值，整数			o(1)			link							hincrbyfloat key field increment			键的field对应value加给定值，浮点数			o(1)			link							hlen key			获取键中field数			o(1)			link							hstrlen key field			获取键的field对应value的长度			o(1)			link							hscan key cursor [MATCH pattern] [COUNT count]			递归获取键的field-value			o(1)/o(n)			link			2.使用场景商品/用户信息一般商品/用户信息会有多个属性，如果只许调整某些属性值，可以比较方便。列表列表用来存储有序的可重复的字符串，根据使用方式可实现栈或队列的功能。1.常用命令						命令类型			命令格式			备注			复杂度			官方说明							增/改			lpush key value [value ...]			向队列的左边插入元素			o(n)			link							lpushx key value			向队列的左边插入元素，当队列不存在			o(1)			link							rpush key value [value ...]			向队列的右边插入元素			o(n)			link							rpushx key value			向队列的右边插入元素，当队列不存在			o(1)			link							lset key index value			设置队列某个位置的元素			o(1)/o(n)			link							linsert key BEFORE|AFTER pivot value			在队列某个元素的前面或后面插入元素			o(1)/o(n)			link							删			lpop key			从队列左边弹出一个元素			o(1)			link							rpop key			从队列右边弹出一个元素			o(1)			link							lrem key count value			从队列的左边或右边删除指定个数的给定元素			o(n)			link							ltrim key start stop			按索引范围裁剪队列			o(n)			link							查			lindex key index			获取索引位置的元素			o(n)			link							lrange key start stop			获取索引范围的元素此命名为重命令，控制获取元素个数			o(n)			link							其它			llen key			队列中元素的个数			o(1)			link			2.使用场景栈lpush+lpop，向列表的一端插入数据，再从同样一端获取数据。队列lpush+rpop，向列表的一端插入数据，再从另外一端获取数据。有限集合lpush+ltrim，向列表的一端插入数据，获取当前列表中的记录数，当记录数超过限定值时，截断列表。消息队列lpush+brpop，向列表的一端插入数据，再从另外一端阻塞获取数据。集合集合用来存储无序的不可重复的字符串，多个集合可取交集、并集、差集。1.常用命令						命令类型			命令格式			备注			复杂度			官方说明							增/改			sadd key member [member ...]			向集合插入元素			o(n)			link							删			srem key member [member ...]			从集合删除元素			o(n)			link							spop key [count]			从集合弹出一个元素			o(1)			link							smove source destination member			将元素从一个集合转移到另一个集合			o(1)			link							查			srandmember key [count]			从集合中返回随机元素			o(1)/o(n)			link							smembers key			从集合中返回所有元素			此命名为重命令，控制获取元素个数			o(n)			link							其它			scard key			集合中元素的个数			o(1)			link							sismember key member			集合中是否存在某个元素			o(1)			link							sscan key cursor [MATCH pattern] [COUNT count]			递归获取集合的元素			o(1)/o(n)			link							集合			sinter key [key ...]			获取集合的交集			o(1)			link							sinterstore destination key [key ...]			获取集合的交集，并保存			o(n*m)			link							sunion key [key ...]			获取集合的并集			o(n)			link							sunionstore destination key [key ...]			获取集合的并集，并保存			o(n)			link							sdiff key [key ...]			获取集合的差集			o(n)			link							sdiffstore destination key [key ...]			获取集合的差集，并保存			o(n)			link			2.使用场景用户标签sadd，记录用户喜欢的标签，标签被哪些用户喜欢。抽奖sadd+spop/srandmember，从所有id中获取随机值。社交sadd+sinter，获取不同用户相同的标签。有序集合有序集合用来存储有序的不可重复的字符串，使用score来进行排序。1.常用命令						命令类型			命令格式			备注			复杂度			官方说明							增/改			zadd key [NX|XX] [CH] [INCR] score member [score member ...]			向集合插入元素			o(log(n))			link							删			zrem key member [member ...]			从集合删除元素			o(m*log(n))			link							zremrangebyrank key start stop			从集合删除指定排序范围的元素			o(m*log(n))			link							zremrangebyscore key min max			从集合删除指定分数范围的元素			o(m*log(n))			link							zremrangebylex key min max			从集合删除指定元素秩范围的元素			o(m*log(n))			link							查			zrange key start stop [WITHSCORES]			返回指定排序范围的元素（由低到高）			o(log(n)+m)			link							zrangebyscore key min max [WITHSCORES] [LIMIT offset count]			返回指定分数范围的元素（由低到高）			o(log(n)+m)			link							zrangebylex key min max [LIMIT offset count]			返回指定元素秩范围的元素个数（由低到高）			o(log(n)+m)			link							zrevrange key start stop [WITHSCORES]			返回指定排序范围的元素（由高到低）			o(log(n)+m)			link							zrevrangebyscore key max min [WITHSCORES] [LIMIT offset count]			返回指定分数范围的元素（由高到低）			o(log(n)+m)			link							zrevrangebylex key max min [LIMIT offset count]			返回指定元素秩范围的元素个数（由高到低）			o(log(n)+m)			link							其它			zcard key			集合中元素的个数			o(1)			link							zcount key min max			返回指定分数范围的元素个数			o(log(n))			link							zincrby key increment member			增加集合中元素的分值			o(log(n))			link							zlexcount key min max			返回分数范围内的元素个数			o(log(n))			link							zrank key member			返回元素的排名（由低到高）			o(log(n))			link							zrevrank key member			返回元素的排名（由低到高）			o(log(n))			link							zscan key cursor [MATCH pattern] [COUNT count]			递归获取集合中的元素			o(1)/o(n)			link							集合			zinterstore destination numkeys key [key ...]			[WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]			获取集合的交集			o(n*k)+o(m*log(n))&amp;nbsp;			link							zunionstore destination numkeys key [key ...]			[WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]			获取集合的并集			o(n*k)+o(m*log(n))&amp;nbsp;			link			2.使用场景排行榜如游戏中可以按照各种维度提供排行的功能。键redis中不管值是什么数据结构，它们的键一样都是字符串，对于键的管理也有相关方法。1.常用命令						命令格式			备注			复杂度			官方说明							del key [key ...]			删除键值对，阻塞			o(n)			link							unlink key arg ...options...			删除键值对，非阻塞			o(n)			link							exists key [key ...]			键是否存在			on)			link							expire key seconds			设置键的过期时间，秒			o(1)			link							pexpire key milliseconds			设置键的过期时间，毫秒			o(1)			link							expireat key timestamp			设置键在何时过期，秒			o(1)			link							pexpireat key milliseconds-timestamp			设置键在何时过期，毫秒			o(1)			link							persist key			移除键的过期时间			o(1)			link							ttl key			获取键的过期时间，秒			o(1)			link							pttl key			获取键的过期时间，毫秒			o(1)			link							rename key newkey			重命名键			o(1)			link							renamenx key newkey			重命名键，newkey不存在			o(1)			link							type key			键的数据结构			o(1)			link							object encoding [arguments [arguments ...]]			键的内部编码			o(1)			link							keys pattern			模糊匹配键，阻塞			o(n)			link							scan cursor [MATCH pattern] [COUNT count]			模糊匹配键，不阻塞，渐进式			o(1)/o(n)			link			参考资料redis commandredisphpredisredis开发与运维"
  },
  
  {
    "title": "php中异常与错误处理",
    "url": "/posts/php-error-exception/",
    "categories": "",
    "tags": "php",
    "date": "2018-08-16 20:50:00 +0800",
    





    "snippet": "  介绍php中的异常与错误处理。前言在使用php时，总会遇到意想不到的异常与错误，为了在知道错误后可以对代码进行调整，需要将异常与错误进行收集，那么一般可以怎么做呢。web服务器处理此方式是借助于web服务器来进行捕捉异常与错误信息。1.php.ini通过修改如下配置，即可记录到错误日志。tips:确保error_log配置的文件，apache用户（如nobody）有读写权限#设置报错级别error_reporting = E_ALL#不向页面输出错误display_errors = off#将错误记录到日志log_errors = On#错误日志文件error_log=/www/htdocs/error_log#每条日志的长度，会影响日志的完整度log_errors_max_len = 10242.虚拟目录根据上面的配置，部署在此服务器的所有web站点日志都会记录在一个文件中，不方便对不同的站点进行监控。可在网站的虚拟目录配置文件httpd-vhosts.conf或httpd-ssl.conf中，配置各个站点记录错误日志的位置。tips:需要将php.ini的中error_log注释或将其置为空，否则优先会使用此处的配置。ErrorLog &quot;/www/htdocs/project_name/storage/log/error_log&quot;程序代码处理此方式是大多数框架的处理方式，在index.php的入口文件中，会引入一个文件来定义php的报错级别（error_reporting），异常处理（set_exception_handler），错误处理（set_error_handler），脚本终止处理（register_shutdown_function）。1.error_reporting设置哪些php错误需要报告出来，这里设置所有的错误。error_reporting(E_ALL);php错误分类如下：            Fatal 致命错误(脚本终止运行)                E_ERROR        致命的运行时错误。这类错误一般是不可恢复的情况，例如内存分配导致的问题。后果是导致脚本终止不再继续运行                E_CORE_ERROR        在PHP初始化启动过程中发生的致命错误。该错误类似 E_ERROR，但是是由PHP引擎核心产生的                E_COMPILE_ERROR        致命编译时错误。类似E_ERROR, 但是是由Zend脚本引擎产生的                E_USER_ERROR        用户产生的错误信息。类似 E_ERROR, 但是是由用户自己在代码中使用PHP函数 trigger_error()来产生的                Parse 解析错误(脚本终止运行)                E_PARSE        编译时语法解析错误。解析错误仅仅由分析器产生                Warning 警告错误(脚本不终止运行)                E_WARNING        运行时警告 (非致命错误)。仅给出提示信息，但是脚本不会终止运行                E_CORE_WARNING        PHP初始化启动过程中发生的警告 (非致命错误) 。类似 E_WARNING，但是是由PHP引擎核心产生的                E_COMPILE_WARNING        编译时警告 (非致命错误)。类似 E_WARNING，但是是由Zend脚本引擎产生的                E_USER_WARNING        用户产生的警告信息。类似 E_WARNING, 但是是由用户自己在代码中使用PHP函数 trigger_error()来产生的                Notice 通知错误(脚本不终止运行)                E_NOTICE        运行时通知。表示脚本遇到可能会表现为错误的情况，但是在可以正常运行的脚本里面也可能会有类似的通知                E_USER_NOTICE        用户产生的通知信息。类似 E_NOTICE, 但是是由用户自己在代码中使用PHP函数 trigger_error()来产生的    2.set_exception_handler设置异常处理函数，当程序中产生的异常没有进行自己捕捉的话，会统一由此处的函数处理。特别在使用第三方类库的时候，如果出现使用上的问题，可以方便的定位问题。//设置处理异常函数set_exception_handler([$this, &#39;handleException&#39;])//处理异常函数public function handleException($objException) {    //非Exception异常，进行处理    if (!$objException instanceof Exception) {        if (method_exists($objException, &#39;getMessage&#39;)) {            throw new Exception($objException-&amp;gt;getMessage());        } else {            throw new Exception(&#39;未知错误&#39;);        }    }    $this-&amp;gt;getHandleException()-&amp;gt;report($objException);    if (!$this-&amp;gt;objApp-&amp;gt;runningInConsole()) {        //非控制台运行，生成http响应并发送        $this-&amp;gt;getHandleException()-&amp;gt;render($objException)-&amp;gt;send();    }}3.set_error_handler设置错误处理函数，此函数可以捕捉php产生的Warning、Notice级别错误。这些错误不会影响程序的正常执行，对于捕获的错误，可用于分类记录。//设置处理错误函数set_error_handler([$this, &#39;handleError&#39;])//错误处理函数public function handleError($strErrNo, $strErrStr, $strErrFile, $intErrLine) {    if (!(error_reporting() &amp;amp; $strErrNo)) {        //如果出现的错误不在定义接受的错误范围内，则转交给php自身处理        return false;    }    //日志记录    $strLog = sprintf(&quot;\\n errno:%s \\n errstr:%s \\n errfile:%s \\n errline:%s \\n&quot;, $strErrNo, $strErrStr, $strErrFile, $intErrLine);    $this-&amp;gt;objApp-&amp;gt;make(&#39;log&#39;)-&amp;gt;log($strLog, Config::get(&#39;const.Log.LOG_ERR&#39;));}4.register_shutdown_function设置php在终止执行时的处理函数，也可以看作是脚本执行结束前最后一个函数。如下情况都可认为脚本执行结束：  脚本正常结束  异常  die  exit  脚本错误可通过error_get_last获取脚本运行产生的最后一个错误，通过type来判断，是否为致命错误，再进行需要的逻辑处理。//设置程序结束处理函数register_shutdown_function([$this, &#39;handleShutDown&#39;])//自定义程序结束处理public function handleShutDown() {    if (!is_null($arrError = error_get_last()) &amp;amp;&amp;amp; $this-&amp;gt;isFatal($arrError[&#39;type&#39;])) {        //日志记录        $strLog = sprintf(&quot;\\n errno:%s \\n errstr:%s \\n errfile:%s \\n errline:%s \\n&quot;, $arrError[&#39;type&#39;], $arrError[&#39;message&#39;], $arrError[&#39;file&#39;], $arrError[&#39;line&#39;]);        $strLog = $this-&amp;gt;objApp-&amp;gt;make(&#39;log&#39;)-&amp;gt;log($strLog, Config::get(&#39;const.Log.LOG_ERR&#39;));    }}//是否为致命错误protected function isFatal($strType) {    return in_array($strType, [E_ERROR, E_CORE_ERROR, E_COMPILE_ERROR, E_USER_ERROR, E_PARSE]);}参考资料php错误预定义常量php运行时配置php异常处理PHP7中的异常与错误处理apache访问日志access_log"
  },
  
  {
    "title": "mysql安装",
    "url": "/posts/install-mysql/",
    "categories": "",
    "tags": "mysql",
    "date": "2018-08-14 16:20:00 +0800",
    





    "snippet": "  介绍在linux上使用二进制文件来安装mysql服务。依赖安装1.libaio[root@vagrant bmsource]# yum install libaio2.numactl[root@vagrant local]# yum install numactlmysql安装1.下载下载地址查看本机操作系统，64位的，所以选择下载64位的安装包。[root@vagrant bmsource]# uname -aLinux vagrant.localhost 2.6.32-573.el6.x86_64 #1 SMP Thu Jul 23 15:44:03 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux2.安装解压tar文件[root@vagrant bmsource]# cp /www/htdocs/mysql-8.0.12-linux-glibc2.12-x86_64.tar /bmsource/mysql-8.0.12-linux-glibc2.12-x86_64.tar[root@vagrant bmsource]# tar -zxf mysql-8.0.12-linux-glibc2.12-x86_64.tar[root@vagrant bmsource]# tar xvf mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz将解压后的文件移到/usr/local/mysql[root@vagrant bmsource]# mv mysql-8.0.12-linux-glibc2.12-x86_64 /usr/local/mysql环境配置1.用户组与用户为了可以运行mysql，需要创建mysql组与mysql用户。[root@vagrant bmsource]# groupadd mysql[root@vagrant bmsource]# useradd mysql -g mysql 2.mysql目录组与用户修改mysql目录所属的组与用户。[root@vagrant local]# chown -R mysql:mysql mysql/3.mysql运行目录mysql运行目录/mysql用于存放数据文件，pid，log等信息。[root@vagrant etc]# cd /[root@vagrant /]# mkdir mysql[root@vagrant /]# chown -R mysql:mysql mysql/数据目录/mysql/data[root@vagrant etc]# cd /mysql[root@vagrant mysql]# mkdir data[root@vagrant mysql]# chown -R mysql:mysql data日志目录/mysql/logs[root@vagrant etc]# cd /mysql[root@vagrant mysql]# mkdir logs[root@vagrant mysql]# chown -R mysql:mysql logs临时目录/mysql/tmpdir[root@vagrant etc]# cd /mysql[root@vagrant mysql]# mkdir tmpdir[root@vagrant mysql]# chown -R mysql:mysql tmpdir4.配置文件mysql的良好运行与参数配置至关重要，这里创建my.cnf文件，然后进行一些初始化的修改。my.cnf[root@vagrant etc]# cd /etc[root@vagrant etc]# touch my.cnf[root@vagrant etc]# chown mysql:mysql my.cnf5.环境变量为了使用mysql命令方便，可以将其添加到PATH环境变量中。[root@vagrant /]# vim /etc/profile--addexport PATH=$PATH:/usr/local/mysql/bin[root@vagrant /]# source /etc/profile使用数据库1.初始化数据库建立系统库与表等。初始化过程中如果报unknown variable，先把相关的变量注释掉。[root@vagrant etc]# /usr/local/mysql/bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/mysql/data2.启动服务将mysql服务复制到/etc/init.d[root@vagrant init.d]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld[root@vagrant init.d]# service mysqld startStarting MySQL... SUCCESS! [root@vagrant init.d]# netstat -anp|grep 3306tcp        0      0 :::33060                    :::*                        LISTEN      10138/mysqld        tcp        0      0 :::3306                     :::*                        LISTEN      10138/mysqld添加开机启动[root@vagrant /]# chkconfig --add mysqld[root@vagrant /]# chkconfig --list mysqldmysqld          0:off   1:off   2:on    3:on    4:on    5:on    6:off3.更新root密码初始化mysql时生成的root用户，默认是没有密码的，为了安全需要为其设置一个密码。mysql&amp;gt; alter user &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;123456&#39;;4.添加用户为了给外部使用，需要创建其他的用户。create user test@127.0.0.1 identified by &#39;123456&#39;;在使用test账号登录的时候，出现了此错误。[root@vagrant ~]# mysql -h 127.0.0.1 -u test -pEnter password: ERROR 2061 (HY000): Authentication plugin &#39;caching_sha2_password&#39; reported error: Authentication requires secure connection.经过查询，发现密码加密的方式默认为caching_sha2_password，此种方式的加密需要安全连接。删除此账号，重新创建账号使用加密方式为mysql_native_password。mysql&amp;gt; create user test@127.0.0.1 identified with mysql_native_password by &#39;123456&#39;;为账号增加数据库权限。mysql&amp;gt; grant all privileges on devmanager.* to test@127.0.0.1;Query OK, 0 rows affected (0.09 sec)mysql&amp;gt; show grants for test@127.0.0.1;+--------------------------------------------------------------+| Grants for test@127.0.0.1                                    |+--------------------------------------------------------------+| GRANT USAGE ON *.* TO `test`@`127.0.0.1`                     || GRANT ALL PRIVILEGES ON `devmanager`.* TO `test`@`127.0.0.1` |+--------------------------------------------------------------+程序连接数据库当使用php代码连接mysql8.0时，遇到了如下2个问题。1.PDO::__construct(): Server sent charset (255) unknown to the client修改my.cnf中如下编码配置[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]collation-server = utf8_unicode_cicharacter-set-server = utf82.The server requested authentication method unknown to the client因为php版本为5.6.18还不支持mysql8.0默认的caching_sha2_password密码插件，所以php连接mysql的用户需要以mysql_native_password插件创建，同时my.cnf的mysqld下需要有如下配置default-authentication-plugin=mysql_native_password重启mysql服务后，测试正常[root@vagrant ~]# service mysqld restart参考资料Installing MySQL on Unix/Linux Using Generic Binariesmysql之my.cnf阿里数据库内核月报mysql8.0初探mysql 用户及权限管理PHP错误：SQLSTATE[HY000] [2054] The server requested authentication method unknown to the client"
  },
  
  {
    "title": "redis上线的问题",
    "url": "/posts/redis-online-wrong/",
    "categories": "",
    "tags": "php, redis",
    "date": "2018-08-03 18:00:00 +0800",
    





    "snippet": "  记一次上线后redis出现的问题及处理方法。前言在此项目之前，有一个项目用到了redis，那个项目中的key数较少（2W左右），目前没出现问题（如果之后key数上升，有些地方也需要进行调整），使自己的判断出现了问题，以为redis是可以随便用的，然后就产生了下面的问题。问题及处理1.key数的增长异常原因：因为系统采用redis作为session的存储，在每次有web请求时都会创建一个session，而提供出去的接口访问特别密集（一天200W次），导致了增加了很多session的key。解决：当接收接口调用时，不开启session。2.keys的阻塞原因：当key数增加时，由于接口中会使用keys查询账号信息，导致查询时间增长，阻塞其他查询。解决：修改系统中keys查询改为键查询。3.del的阻塞原因：当删除较大的key值时，需要的时间会变长，可能阻塞其他查询。解决：修改系统中del为unlink异步删除。4.内存占用过大原因：当缓存如简历（10k左右），头像（15k左右）等信息时，随着key的增多，内存会占用很大。解决：修改系统只有当简历（简历详情页面）与头像（简历详情，面试官列表）被使用时，才进行缓存7天。5.read error on connection原因：在排除了慢查询，cpu，内存，网络问题后，只能猜想是由于rdb的频繁同步引起阻塞导致执行超时解决：修改3台机器的rdb同步时间为6小时一次，一台从机的rdb同步时间为1小时一次。总结1.模糊查询模糊查询指用redis中keys命令，来一次性查询多个匹配模式的key，当想将redis当作数据表使用时，可能会下意识的使用此方法。如果非得需要将redis当数据表使用可通过set数据结构或通过程序代码将数据表在redis与程序中进行序列化与反序列化。keys的性能在服务器中key数较少或并发查询不高时，并不会产生明显的问题；反之当key数增加或并发查询变高时，性能会下降很明显（比如需要几十ms才能完成查询），而由于redis单线程的设计，就会导致后面的查询都要阻塞，就可能会导致查询超时的错误。如下案例为在开发环境下测试的keys（模糊查询）与hgetall（键值访问）随着key数量的变化而产生的性能变化。最终测试结果是，keys性能会越来越差，而hgetall性能基本保持不变。2.大key删除redis中的del命名为同步删除，如果删除的key对应的值较大，在并发情况下可能会出现阻塞，在redis4.0版本后可使用unlink实现异步删除。 3.服务器公用因为之前系统key数较少占用的空间不大，想着不浪费资源的目的，此系统的redis服务器也使用之前系统的，不幸的是因为此系统的故障，导致了原系统也出现了问题。  不同系统千万不要公用服务器  如果要公用，在上线前确保进行非常完善的评估4.压力评估如果在系统上线前能做压力测试是最好的，通过压力测试可以暴露出正常使用较难发现的系统bug和性能问题。如果没有条件做压力测试，则需要根据上线后的预测使用与并发量（这里需要比较准确）来评估系统的性能是否能满足需要，一般包含如下几点：1.连接数这里评估的是并发量是否会超过redis的最大客户端数（maxclients），根据需求适当的选用短链接还是长连接。2.key数这里评估的是随着系统的使用（结合用户数），产生的key数是一个什么量级，如果key有过期时间则结合过期时间进行计算。3.key值大小这里评估的是，key里存储内容的可能大小，结合key数可计算出可能占用的内存是否会超出redis的最大可能内存，如果超出则会发生内存与磁盘的swap（maxmemory=0），影响读写的性能。如果内容大小超过10kb，即使占用内存在最大内存范围内，也可能导致并发请求的性能下降。4.命中率将数据放入redis是为了之后程序可以从里面读取内容，避免从数据库访问，从而降低数据库的压力且提高了读取数据；所以需要考虑放入缓存中的数据，之后会被访问的概率，如果较低可以暂时不放入缓存，将空间留给需要高频访问的数据，避免对空间的浪费。相关文章Redis开发与运维Redis性能问题排查解决手册Redis4.0 新特性尝鲜阿里云 Redis 开发规范redis4.0之lazyfree"
  },
  
  {
    "title": "swoole的进程构成",
    "url": "/posts/swoole-process/",
    "categories": "",
    "tags": "swoole",
    "date": "2018-07-31 14:30:00 +0800",
    





    "snippet": "  介绍swoole模块中，进程的构成。概述swoole的进程由master进程，manager进程，worker进程，task进程组成。master与manager进程只会有一个，worker与task进程根据配置可能会产生多个。worker_num设置启动的Worker进程数，默认为SWOOLE_CPU_NUM（逻辑cpu个数）。最好为cpu的1-4倍，不超过100倍。1.不设置worke_num不手动设置worker进程数，默认为逻辑cpu的个数。逻辑cpu为1，加上master与manager总共为3个。逻辑cpu为4，加上master与manager总共为6个。2.设置worke_num手动启动3个worker进程，加上master与manager总共为5个。手动启动6个worker进程，加上master与manager总共为8个。task_worker_num设置启动的Task进程数，默认不启动，需要自己手动配置。设置worke_num=3，task_worker_num=3worker与task进程，加上master与manager总共为8个。设置worke_num=3，task_worker_num=6worker与task进程，加上master与manager总共为11个。worker进程与task进程的区别从上面可以看出worker进程与task进程是并列的，task进程并不属于某个worker进程，那为什么有了worker还需要task呢？swoole中任务的处理流程如下图，服务器接收到客户端的处理请求可以直接在worker中进行处理，如果处理的耗时较长，可将任务异步投递到空闲的task中处理（如果任务异步处理的话），这样worker就可以接收新的客户端处理请求，从而提高了服务器处理任务的速度。为了验证实际情况是不是如上面说的，进行如下测试，服务端开启3个worker，2个task。  taskworker：当前工作进程为task进程还是worker进程  work_id：当前工作进程的编号[0-(worker_num+task_num-1)]，按worker+task顺序编号  work_pid：当前工作进程对应的系统进程id  src_worker_id：当前task进程处理的任务来自哪个worker进程  task_id：swoole自动生成的任务编号，src_worker_id+task_id为全局唯一服务端代码客户端代码测试结果测试结果多个worker会调用相同的task处理。相同的worker会调用不同的task处理。参考资料Linux查看物理CPU个数、核数、逻辑CPU个数swoole worker_numtask_worker_numswoole_server-&amp;gt;taskswoole_server-&amp;gt;taskwait"
  },
  
  {
    "title": "redis中pconnect与connect",
    "url": "/posts/redis-pconnect-connect/",
    "categories": "",
    "tags": "php, redis",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍phpredis模块中，pconnect与connect连接的区别。概述1.connect每次connect都会新建一个tcp连接；脚本运行结束之后自动断开连接。2.pconnect持久连接，标识id：1.host + port + timeout2.host + persistent_id3.unix socket + timeout每次pconnect会根据标识id在当前运行的httpd（指通过mpm模块创建出来的进程，web请求会被发送到这些进行进程处理，这些进程可处理多次web请求）或php-fpm进程中查找已存在的连接，如果存在则复用连接，否则新建连接；脚本运行结束之后不会自动断开连接，连接会保留在httpd或php-fpm进程中，除非进程关闭或连接空闲时间达到redis设置的timeout（timeout=0为永不超时）。此特性在线程版本里是无效的，pconnect等同于connect。测试准备为了在测试时可以比较方便的观察连接，将apache的并发处理数调整为1。httpd.conf#启用httpd-mpm模块Include conf/extra/httpd-mpm.confhttpd-mpm.conf&amp;lt;IfModule mpm_prefork_module&amp;gt;    StartServers             1    MinSpareServers          1    MaxSpareServers         1    MaxRequestWorkers      1    MaxConnectionsPerChild   0&amp;lt;/IfModule&amp;gt;单次执行多连接测试1.connect$objRedis = new Redis();$bln = $objRedis-&amp;gt;connect(&#39;10.100.3.106&#39;, 6379, 3);var_dump($objRedis-&amp;gt;ping());sleep(10);$bln = $objRedis-&amp;gt;connect(&#39;10.100.3.106&#39;, 6379, 3);var_dump($objRedis-&amp;gt;ping());sleep(10);$bln = $objRedis-&amp;gt;connect(&#39;10.100.3.106&#39;, 6379, 3);var_dump($objRedis-&amp;gt;ping());sleep(10);redis客户端连接信息如下，可以发现3次连接的端口都是不同的，当重新连接时原来的连接会立即断开。2.pconnect1.相同的标识id$objRedis = new Redis();$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha&#39;);var_dump($objRedis-&amp;gt;ping());sleep(10);$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha&#39;);var_dump($objRedis-&amp;gt;ping());sleep(10);$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha&#39;);var_dump($objRedis-&amp;gt;ping());sleep(10);redis客户端连接信息如下，可以发现3次连接的端口都是相同的，脚本执行过程中，age在一直增长，idle会在使用后重新从0开始计算。2.不同的标识id$objRedis = new Redis();$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha1&#39;);var_dump($objRedis-&amp;gt;ping());sleep(10);$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha2&#39;);var_dump($objRedis-&amp;gt;ping());sleep(10);$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha3&#39;);var_dump($objRedis-&amp;gt;ping());sleep(10);redis客户端连接信息如下，可以发现3次连接的端口都是不同的，每次连接时原来的连接不会立即断开，而是要等到timeout时间。多次执行单连接测试1.connect$objRedis = new Redis();$bln = $objRedis-&amp;gt;connect(&#39;10.100.3.106&#39;, 6379, 3);var_dump($objRedis-&amp;gt;ping());redis客户端连接信息如下，可以发现3次执行脚本端口都是不同的，每次都会重新创建连接。2.pconnect$objRedis = new Redis();$bln = $objRedis-&amp;gt;pconnect(&#39;10.100.3.106&#39;, 6379, 3, &#39;haha&#39;);var_dump($objRedis-&amp;gt;ping());redis客户端连接信息如下，可以发现3次执行脚本端口都是相同的，每次执行后idle会更新为0，age（连接创建的时间）则会一直增长。总结1.connect优点：  脚本执行结束会自动关闭连接，无需关心是否会持续占用连接  每次连接都是新的连接，连接之间不会互相影响缺点：  在大量请求时会频繁的建立与关闭连接，占用资源，出现很多TIME_WAIT适用场景：2.pconnect优点：  连接不会随着脚本的结束而关闭，会保留在httpd或php-fpm进程中，直到超时时间或进程关闭  每次连接时，会优先查找是否有可用连接，如果有则复用以前的连接，减少IO开销缺点：  如果存在很多长连接，当超过redis的最大可用连接，会导致之后的连接连接不上  如果不同的web应用都使用长连接，且没有根据应用配置标识id，会导致2个web应用共享连接，当出现如切换db时就会产生问题适用场景：  高并发的http请求，可设置timeout来及时关闭空闲的连接参考资料  高并发下PHP请求Redis异常处理  Apache的三种MPM模式比较：prefork，worker，event  Apache优化：修改最大并发连接数"
  },
  
  {
    "title": "laravel学习（七）-路由",
    "url": "/posts/7-laravel-study-routing/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架中路由的创建与使用。文档英文文档中文文档路由创建1.文件引入框架中的路由配置主要在routes\\web.php与routes\\api.php文件中，那么框架是如何加载文件里的路由的呢?2.路由组如果需要注册拥有相同属性的路由的话，可通过group，在group之前定义共享属性（as,domain,middleware,name,namespace,prefix），最后调用group将共享属性应用到路由中。Route::prefix(&#39;api&#39;)    -&amp;gt;middleware(&#39;api&#39;)    -&amp;gt;namespace($this-&amp;gt;namespace)    -&amp;gt;group(function(){        /*路由注册*/    });如果在group中套group的话，则里面的group会引入上层group的属性，也就是最里面一层的group会包含所有上层group的属性。3.路由注册当框架加载了路由配置文件，就需要将路由注册到应用了，以便之后能使用路由。路由使用当应用接收到http请求时，需要经过路由将请求分发给闭包函数或控制器中的方法进行处理。"
  },
  
  {
    "title": "laravel学习（六）-契约",
    "url": "/posts/6-laravel-study-contracts/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架中契约的主要使用方法。文档英文文档中文文档自我理解契约将服务所要提供的功能与如果实现这些功能进行了分离，在需要使用服务时通过契约进行解析而不是具体的实现，当我们需要修改具体实现时，不需要修改使用的地方，降低代码的耦合性。同时在我们想了解服务所提供的功能时，通过查看契约即可，契约就好比是服务的说明文档了。使用依赖为了能使框架解析契约，需要在服务提供者中将接口与实现进行绑定。$this-&amp;gt;app-&amp;gt;bind(    &#39;App\\Contracts\\EventPusher&#39;,    &#39;App\\Services\\RedisEventPusher&#39;);使用场景1.类构造函数的自动注入2.make对接口的解析3.facade中使用接口"
  },
  
  {
    "title": "laravel学习（五）-外观",
    "url": "/posts/5-laravel-study-facades/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架中外观的主要使用方法。文档英文文档中文文档创建外观1.新建外观外观的新建需要继承于Facades类，并重写getFacadeAccessor用于提供容器解析时所需要的服务别名。namespace Illuminate\\Support\\Facades;class Cache extends Facade{    /**     * 获取服务的注册名     */    protected static function getFacadeAccessor()    {        return &#39;cache&#39;;    }}2.引入外观当我们有了facade，需要怎么配置到程序里呢，从而可以让框架对其进行操作。应用中的facade都是在配置文件config/app.php的aliases中。&#39;aliases&#39; =&amp;gt; [    //自定义的facade    &#39;Cache&#39; =&amp;gt; Illuminate\\Support\\Facades\\Cache::class,],3.加载流程图使用外观1.使用方法在使用外观时，通过类似于类中静态方法的调用方式，即可使用facade中的功能。$user = Cache::get(&#39;user:&#39;.$id);2.使用流程图外观的优缺点1.优点可以很方便，随心所欲的使用facade类提供的功能。2.缺点可能会在单个类中使用很多的facade，导致类的膨胀；而使用依赖注入会随着使用类的增多，构造函数会变长，在感官上引起我们的注意，可能类需要进行功能的重构了。因此在使用facade时，我们需要主观控制类的大小，当类变的比较大时，就需要进行重构了。"
  },
  
  {
    "title": "laravel学习（四）-服务提供者",
    "url": "/posts/4-laravel-study-service-providers/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架中服务提供者的主要使用方法。文档英文文档中文文档创建服务提供者1.常规使用此种使用方法，能满足大部分情况下对服务提供者的使用。class DemoServiceProvider extends ServiceProvider {    /**     * 注册方法，会在容器内被调用     */    public function register() {        //向容器中绑定服务        $this-&amp;gt;app-&amp;gt;singleton(Connection::class, function ($app) {            return new Connection(config(&#39;demo&#39;));        });    }}2.快捷绑定如果只是向容器中注册简单的绑定，可通过如下方法，而不需要手动注册每个服务绑定。class DemoServiceProvider extends ServiceProvider {    /**     * 普通绑定对应关系     */    public $bindings = [        ServerProvider::class =&amp;gt; DigitalOceanServerProvider::class,    ];    /**     * 单例绑定对应关系     */    public $singletons = [        DowntimeNotifier::class =&amp;gt; PingdomDowntimeNotifier::class,    ];}3.延迟加载对于业务类的服务提供者，一般不需要在应用启动时就对其进行加载处理，只有在使用到它的时候才需要。class DemoServiceProvider extends ServiceProvider {    /**     * 标记着服务提供者是延迟加载的     */    protected $defer = true;    /**     * 注册方法，会在容器内被调用     */    public function register() {        $this-&amp;gt;app-&amp;gt;singleton(Connection::class, function ($app) {            return new Connection($app[&#39;config&#39;][&#39;riak&#39;]);        });    }    /**     * 获取服务提供者提供的服务     */    public function provides() {        return [Connection::class];    }}4.事件加载事件加载时对延迟加载的扩展处理，加载延迟服务器的时机不一定是使用了它，而可能是某个事件触发了我们需要对其进行加载，以实现功能需求。class DemoServiceProvider extends ServiceProvider {    /**     * 标记着服务提供者是延迟加载的     */    protected $defer = true;    /**     * 注册方法，会在容器内被调用     */    public function register() {        $this-&amp;gt;app-&amp;gt;singleton(Connection::class, function ($app) {            return new Connection($app[&#39;config&#39;][&#39;riak&#39;]);        });    }    /**     * 获取服务提供者提供的服务     */    public function provides() {        return [Connection::class];    }    /**     * 获取触发加载的事件     * @return array     */    public function when() {        return [];    }}5.启动方法有时我们希望在服务提供者加载后，可以执行某些额外的处理，可以借助于boot方法。class DemoServiceProvider extends ServiceProvider {    /**     * 服务提供者加载后的处理方法     * 此时应用已标记启动，所有的服务提供者都已加载     */    public function boot() {        //额外处理方法        view()-&amp;gt;composer(&#39;view&#39;, function () {            //        });    }}配置服务提供者当我们有了服务提供者，需要怎么配置到程序里呢，从而可以让框架对其进行操作。应用中的服务提供者都是在配置文件config/app.php的providers中。&#39;providers&#39; =&amp;gt; [    //自定义的服务提供者    App\\Providers\\ComposerServiceProvider::class,],即时加载流程图延迟加载流程图"
  },
  
  {
    "title": "laravel学习（三）-服务容器",
    "url": "/posts/3-laravel-study-service-container/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架中服务容器的主要使用方法。文档英文文档中文文档绑定1.bind此方法是最常用的服务绑定方法。函数说明/** * Register a binding with the container. * 绑定服务到容器 * @param  string  $abstract 类别名，实际类名，接口类名 * @param  \\Closure|string|null  $concrete 类的构建闭包，实际类名，null=&amp;gt;$concrete=$abstract * @param  bool  $shared 是否为共享服务 * @return void */function bind($abstract, $concrete = null, $shared = false) {    }典型应用//类别名绑定到构建闭包$this-&amp;gt;app-&amp;gt;bind(&#39;cache&#39;, function ($app) {    return new CacheManager($app);});//类别名绑定到实际类名$this-&amp;gt;app-&amp;gt;bind(&#39;cache&#39;, &#39;Illuminate\\Cache\\CacheManager&#39;);//接口类名绑定到实际类名$this-&amp;gt;app-&amp;gt;bind(&#39;App\\Contracts\\EventPusher&#39;, &#39;App\\Services\\RedisEventPusher&#39;);流程图2.singleton此方法可将服务绑定为共享服务。函数说明/** * Register a shared binding in the container. * 绑定单例服务到容器 * @param  string  $abstract 类别名，实际类名，接口类名 * @param  \\Closure|string|null  $concrete 类的构建闭包，实际类名，null=&amp;gt;$concrete=$abstract * @return void */function singleton($abstract, $concrete = null) {    }典型应用//类别名绑定到构建闭包，服务为共享的$this-&amp;gt;app-&amp;gt;singleton(&#39;cache&#39;, function ($app) {    return new CacheManager($app);});流程图3.instance此方法可将服务的实例直接绑定到容器的共享服务中。函数说明/** * Register an existing instance as shared in the container. * 绑定抽象类型的实例为共享实例 * @param  string  $abstract 类别名，实际类名，接口类名 * @param  mixed   $instance 实例 * @return mixed */function instance($abstract, $instance) {    }典型应用//类实例化$api = new HelpSpot\\API(new HttpClient);//实例绑定$this-&amp;gt;app-&amp;gt;instance(&#39;HelpSpot\\API&#39;, $api);流程图4.when此方法可进行服务的上下文绑定，需要配合ContextualBindingBuilder中的needs与give使用，在解析时使用give代替needs。函数说明/** * Define a contextual binding. * 创建上下文绑定 * @param  string  $concrete 实际类名 * @return \\Illuminate\\Contracts\\Container\\ContextualBindingBuilder */function when($concrete) {}/** * Define the abstract target that depends on the context. * 上下文依赖的抽象类型 * @param  string  $abstract 类别名，实际类名，接口类名，变量名 * @return $this */function needs($abstract) {    }/** * Define the implementation for the contextual binding. * 抽象类型的实现 * @param  \\Closure|string  $implementation 实现闭包，字符串 * @return void */function give($implementation) {    }典型应用//绑定构造函数中简单参数的初始数据，在解析when类的时用到$this-&amp;gt;app-&amp;gt;when(&#39;App\\Http\\Controllers\\UserController&#39;)          -&amp;gt;needs(&#39;$variableName&#39;)          -&amp;gt;give($value);//绑定构造函数中类参数的实现，在解析when类的依赖类时用到//如下2个绑定表示，在解析PhotoController::class与VideoController::class时都需要依赖Filesystem::class，但是根据不同的功能，给予了Filesystem::class不同的实现$this-&amp;gt;app-&amp;gt;when(PhotoController::class)          -&amp;gt;needs(Filesystem::class)          -&amp;gt;give(function () {              return Storage::disk(&#39;local&#39;);          });$this-&amp;gt;app-&amp;gt;when(VideoController::class)          -&amp;gt;needs(Filesystem::class)          -&amp;gt;give(function () {              return Storage::disk(&#39;s3&#39;);          });          流程图5.tag此方法可将多个服务进行标记，在解析时可以使用tag同时解析多个服务。函数说明/** * Assign a set of tags to a given binding. * 为一组绑定设定标记 * @param  array|string  $abstracts 抽象类型 * @param  array|mixed   ...$tags 需要设定的标记 * @return void */function tag($abstracts, $tags) {    }典型应用$this-&amp;gt;app-&amp;gt;bind(&#39;SpeedReport&#39;, function () {    //});$this-&amp;gt;app-&amp;gt;bind(&#39;MemoryReport&#39;, function () {    //});$this-&amp;gt;app-&amp;gt;tag([&#39;SpeedReport&#39;, &#39;MemoryReport&#39;], &#39;reports&#39;);流程图6.extend此方法可对解析后的服务实例添加扩展方法，用于对实例进行装饰处理。函数说明/** * &quot;Extend&quot; an abstract type in the container. * 扩展容器中的服务 * @param  string    $abstract 抽象类型 * @param  \\Closure  $closure 闭包 * @return void * * @throws \\InvalidArgumentException */function extend($abstract, Closure $closure) {    }典型应用//对服务的实例进行装饰处理$this-&amp;gt;app-&amp;gt;extend(Service::class, function($service) {    return new DecoratedService($service);});流程图解析1.make(app)最常用的从容器中解析实例的方法。函数说明/** * Resolve the given type from the container. * 从服务容器中解析服务 * (Overriding Container::make) * @param  string  $abstract 类别名，实际类名，接口类名 * @param  array  $parameters 类依赖的参数 * @return mixed */public function make($abstract, array $parameters = []) {}典型应用$api = $this-&amp;gt;app-&amp;gt;make(&#39;HelpSpot\\API&#39;);流程图2.makeWith(container)在解析类时，可直接传入类的依赖项，而不需要通过容器去解析。函数说明/** * An alias function name for make(). * &amp;lt;br&amp;gt;make方法的别名 * @param  string  $abstract 类别名，实际类名，接口类名 * @param  array  $parameters 类依赖的参数 * @return mixed */public function makeWith($abstract, array $parameters = []) {}典型应用$api = $this-&amp;gt;app-&amp;gt;makeWith(&#39;HelpSpot\\API&#39;, [&#39;id&#39; =&amp;gt; 1]);流程图3.resolve(helpers)如果访问不到$app，可通过此全局辅助函数解析实例。函数说明if (! function_exists(&#39;resolve&#39;)) {    /**     * Resolve a service from the container.     * 从容器中解析类     * @param  string  $name 抽象类型     * @return mixed     */    function resolve($name)    {        return app($name);    }}if (! function_exists(&#39;app&#39;)) {    /**     * Get the available container instance.     * 从容器中解析实例     * @param  string  $abstract 类别名，实际类名，接口类名     * @param  array   $parameters 类依赖的参数     * @return mixed|\\Illuminate\\Foundation\\Application     */    function app($abstract = null, array $parameters = [])    {        if (is_null($abstract)) {            //如果没有抽象类型，返回容器实例            return Container::getInstance();        }        //解析抽象类型        return Container::getInstance()-&amp;gt;make($abstract, $parameters);    }}典型应用$api = resolve(&#39;HelpSpot\\API&#39;);流程图事件注册解析服务时触发的全局事件或服务的事件，可在服务提供者的boot方法中注册。public function boot(){    $this-&amp;gt;app-&amp;gt;resolving(function ($object, $app) {        //注册全局解析方法，解析任何类型时都会触发    });        $this-&amp;gt;app-&amp;gt;resolving(HelpSpot\\API::class, function ($api, $app) {        //注册类型解析方法，解析对应类型时才会触发    });}应用的启动在BootProviders中的bootstrap方法里。public function bootstrap(Application $app){    $app-&amp;gt;boot();}注释版代码ApplicationContainer"
  },
  
  {
    "title": "laravel学习（二）-请求周期",
    "url": "/posts/2-laravel-study-request-lifecycle/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架的请求周期，应用是如果处理请求，并返回响应的。文档英文文档中文文档入口文件应用程序对外部请求的响应，都是通过public/index.php文件，这需要在web服务器（apache/nginx）上配置将所有的请求都引导到此文件。应用创建应用创建在bootstrap/app.php文件中，包括Application的实例化与重要接口的共享绑定。内核解析解析获取内核的实例，同时将应用实例与路由器实例注入到内核实例中。处理http请求获取到内核实例后，就需要调用内核中的handle方法来处理http请求。发送响应请求经过内核处理后，我们会获取到响应的实例，这时需要将响应发送到客户端。应用结束当响应发送给客户端后，我们的请求周期也算是到结束了，最后在做一个收尾的动作。"
  },
  
  {
    "title": "laravel学习（一）-核心架构",
    "url": "/posts/1-laravel-study-architecture/",
    "categories": "",
    "tags": "php, laravel",
    "date": "2018-06-06 20:50:00 +0800",
    





    "snippet": "  介绍laravel框架的主要架构，服务是如何绑定到容器，又如何从容器中获取服务。概述在laravel中，传统意义上的web网站被称作为应用，应用中的所有服务放在服务容器中，当需要使用服务时，可以从服务容器中解析。服务主要包括框架自带的、通过composer引入的第三方库、为了实现业务功能自行添加的。服务是指为了实现某些特定功能而写的类。在使用类的时候，传统做法是在需要的地方进行实例化，或者通过工厂进行实例化。而在laravel中服务（类）的实例化是通过服务容器统一处理的，包括常规类的解析、标记的一组类的解析、上下文绑定类的解析、类对外部服务依赖的自动解析、接口到具体的实现的解析、类实例的扩展处理，基于服务容器的作用可构建大型、可维护、可扩展的应用网站。架构图此图主要是展示服务容器（Service Container），服务提供者（Service Providers），外观（Facades），契约（Contracts）之间的关系。架构说明1.服务容器用于管理应用中的服务，提供添加服务与解析服务的接口，对于服务构造方法(__construct)中的依赖项，可自动进行解析注入。如果服务不依赖接口，且服务非共享的，可以不绑定到容器中，在使用服务时同样可以通过容器解析。2.服务提供者用于向服务容器中绑定服务，laravel框架自带了很多服务提供者，如果自己需要绑定新服务也应该通过服务提供者。  即时加载：应用启动的时候  延迟加载：使用到服务的时候  事件加载：服务提供者配置了when，当when触发时加载3.外观提供访问服务容器可用类中方法的静态接口，在使用应用中通用的功能时比较简单，不需要通过长类名进行进行解析服务。4.契约提供了服务要实现功能的接口，需要借助于服务提供者将接口与实现进行绑定，在通过容器解析接口时，实际是解析的接口的实现。通过接口定义的服务，可以方便的知道服务提供的功能，如果接口的实现变了可以很容易的进行修改，降低应用的耦合性。"
  },
  
  {
    "title": "RabbitMQ学习-高可用",
    "url": "/posts/8-rabbitmq-study-HignAvailable/",
    "categories": "",
    "tags": "rabbitmq, php",
    "date": "2018-05-19 20:50:00 +0800",
    





    "snippet": "  介绍RabbitMQ中，如何来实现高可用。架构图服务器为了保证RabbitMQ服务器的可用性，线上环境一般都使用镜像集群，当集群中某些节点不可用时，集群还是可以工作的。镜像集群搭建方法生产者1.交换器持久化正常的业务交换器定义好后一般都会一直使用，即使服务器重启也不会消失。#在定义交换器时(一般在消费者处)，控制如下2个参数durable：trueauto_delete：false2.队列持久化正常的业务队列定义好后一般都会一直使用，即使服务器重启也不会消失。#在定义队列时(一般在消费者处)，控制如下2个参数durable：trueauto_delete：false3.消息持久化为了确保消息在服务器出问题的时候也不会丢失，需要将消息持久到磁盘。消息真正的持久化实际需要依赖以下几点：  消息投递模式设置为2（持久）  消息发送到了持久化交换器  消息最终到达持久化队列#在定义消息时增加属性properties：[&#39;delivery_mode&#39; =&amp;gt; AMQPMessage::DELIVERY_MODE_PERSISTENT]4.备用交换器官方文档为了确保能跟踪到所有发送给交换器的消息，在我们预想接收的消息外，可以设置备用交换器，来捕获其他未被路由的消息。//备用交换器参数$arrArgument = new Wire\\AMQPTable([    &#39;alternate-exchange&#39; =&amp;gt; $strAeExchangeName]);//创建交换器，增加备用交换器设置$this-&amp;gt;getChannel()-&amp;gt;exchange_declare($strExchangeName, $strExchangeType, false, true, false, false, false, $arrArgument);5.生产者确认官方文档为了确保生产者能成功的将消息推送给RabbitMQ服务器，需要使用生产者确认。//开启信道确认模式$this-&amp;gt;getChannel()-&amp;gt;confirm_select();//设置信道回调方法$this-&amp;gt;getChannel()-&amp;gt;set_ack_handler(function(AMQPMessage $objMessage) {    $this-&amp;gt;ackHandler($objMessage);});$this-&amp;gt;getChannel()-&amp;gt;set_nack_handler(function(AMQPMessage $objMessage) {    $this-&amp;gt;nackHandler($objMessage);});6.代码示例生产者消费者1.消费者不下线在大部分业务中，消费者都是启动之后就不停止的，但是如果RabbitMQ服务器异常导致连接不上，就不能正常消费队列中的消息，这时消费者需要能够自动切换其他可连接的服务器。while (1) {    try {        while (1) {            $this-&amp;gt;getChannel()-&amp;gt;wait();        }    } catch (\\Exception $e) {        //日志记录        //重建        $this-&amp;gt;reset();        if (!$this-&amp;gt;build($this-&amp;gt;arrInitParam)) {            //日志记录            break;        }    }}2.消费者正常下线当消费者逻辑需要进行更新时，就需要停止消费者的运行，如果直接将守护进程关闭，可能会导致逻辑处理到一半被终止了，从而产生不可预知的问题。可在消费者的回调方法中，增加对标识键的判断，如果存在标识键则处理完此条消息后停止消费消息，同时关闭信道与连接。/** * 消费者是否已停止 */private function isConsumerStop() {    $this-&amp;gt;blnConsumerStop = Cache::exec(&#39;exists&#39;, $this-&amp;gt;arrInitParam[&#39;redis_key&#39;]);    return $this-&amp;gt;blnConsumerStop;}/** * 信息处理 */private function dealMessage(AMQPMessage $objMessage) {    //消息消费失败是否重进队列    $blnIsRequeue = isset($this-&amp;gt;arrInitParam[&#39;is_requeue&#39;]) ? $this-&amp;gt;arrInitParam[&#39;is_requeue&#39;] : false;    //业务确认是否成功    $blnAck = $this-&amp;gt;receiveMessage($objMessage-&amp;gt;body);    if ($blnAck) {        $objMessage-&amp;gt;delivery_info[&#39;channel&#39;]-&amp;gt;basic_ack($objMessage-&amp;gt;delivery_info[&#39;delivery_tag&#39;]);    } else {        //$objMessage-&amp;gt;delivery_info[&#39;channel&#39;]-&amp;gt;basic_nack($objMessage-&amp;gt;delivery_info[&#39;delivery_tag&#39;], false, $blnReQueue);        $objMessage-&amp;gt;delivery_info[&#39;channel&#39;]-&amp;gt;basic_reject($objMessage-&amp;gt;delivery_info[&#39;delivery_tag&#39;], $blnIsRequeue);    }    //消费者是否需要停止    if ($this-&amp;gt;isConsumerStop()) {        $objMessage-&amp;gt;delivery_info[&#39;channel&#39;]-&amp;gt;basic_cancel($objMessage-&amp;gt;delivery_info[&#39;consumer_tag&#39;]);    }}/** * 开始运行 */public function run() {    while (1) {        try {            while (1) {                if ($this-&amp;gt;blnConsumerStop) {                    //消费者已停止                    $this-&amp;gt;reset();                    throw new Exception(&#39;consumer stop&#39;);                } else {                    $this-&amp;gt;getChannel()-&amp;gt;wait();                }            }        } catch (Exception $e) {            //消费者已停止            if ($this-&amp;gt;blnConsumerStop) {                break;            }            //设置错误信息            $strErrorMsg = $e-&amp;gt;getMessage();            $strErrorMsg = sprintf(&quot;type:%s\\r\\n param:%s\\r\\n error:%s\\r\\n&quot;, $this-&amp;gt;getType() . &#39;_run&#39;, json_encode($this-&amp;gt;arrInitParam), $strErrorMsg);            //错误日志记录            Log::log($strErrorMsg, Config::get(&#39;const.Log.LOG_MQERR&#39;));            //重建            $this-&amp;gt;reset();            if (!$this-&amp;gt;build($this-&amp;gt;arrInitParam)) {                //日志记录                break;            }        }    }}3.消费者逻辑变更标记值变化，处理完消息后就不处理，杀死进程4.单条信息获取为了确保消费者在消费消息时能够进行确认成功消费，每次只能队列中获取一条消息。//每次只接受一条信息$this-&amp;gt;getChannel()-&amp;gt;basic_qos(null, 1, null);5.死信队列官方文档当消费者在消费某个消息失败后，如果将消息重新投入队列，则此消息会被其它消费者依次接收到，如果一直不能成功消费，则会阻碍其他消息的消费。可以将消费失败的消息，投入到死信队列，通过其他逻辑对它们进行处理，从而不影响正常的功能。//死信交换器参数$arrArgument = new Wire\\AMQPTable([    &#39;x-dead-letter-exchange&#39; =&amp;gt; $strDqExchangeName,    &#39;x-dead-letter-routing-key&#39; =&amp;gt; $strDqRouteKey]);//创建队列，增加死信队列设置$this-&amp;gt;getChannel()-&amp;gt;queue_declare($strQueueName, false, true, false, false, false, $arrArgument);6.消费者确认官方文档为了确保消费者成功的消费的消息，从而从队列中删除此消息，需要使用消费者确认模式。//接收消息$this-&amp;gt;getChannel()-&amp;gt;basic_consume($arrQueue[&#39;queue_name&#39;], &#39;&#39;, false, false, false, false, function(AMQPMessage $objMessage) {    $this-&amp;gt;dealMessage($objMessage);});//业务确认是否成功$blnAck = $this-&amp;gt;receiveMessage($objMessage-&amp;gt;body);if ($blnAck) {    $objMessage-&amp;gt;delivery_info[&#39;channel&#39;]-&amp;gt;basic_ack($objMessage-&amp;gt;delivery_info[&#39;delivery_tag&#39;]);} else {    $objMessage-&amp;gt;delivery_info[&#39;channel&#39;]-&amp;gt;basic_reject($objMessage-&amp;gt;delivery_info[&#39;delivery_tag&#39;], $blnIsRequeue);}7.代码示例消费者性能硬件配置主要包括网络配置、磁盘管理、处理器核心数等。软件配置通过不同AMQP参数的配置，来合理控制性能。消息持久化在消息投递时，如果设置消息持久化存储的话，性能大致会降低1/2左右（降低后投递速度也有4000/s左右）。要根据实际使用场景来觉得是否需要使用持久化存储（是否能接受消息的丢失）。消息确认如果在订阅队列时设置no-ack=true，服务器在将消息投递后就可以无须关注，消费者在处理完消息后也无须再发送确认信息给服务器，这样就可以加快消费者消费的速度。带来的问题是，如果消息消费失败，则消息会用永久丢失了。路由算法和绑定规则通常情况下，topic交换器上的绑定相比direct或fanout来说，会占用更多内存。消息投递参考如下消息流程图，RabbitMQ内部被优化为尽快的将消息投递给消费者。在制定容量规划与消息进出速率的时，应该尽可能让队列保持为空的状态，这样消息可以不经过内存或磁盘存储直接到消费者，从而提高效率。Tips：需要时刻关注队列中消息数，提高消费者处理速度，避免消息大批量滞留。"
  },
  
  {
    "title": "RabbitMQ学习-集群",
    "url": "/posts/7-rabbitmq-study-Cluster/",
    "categories": "",
    "tags": "rabbitmq, php",
    "date": "2018-05-18 20:50:00 +0800",
    





    "snippet": "  介绍RabbitMQ中，如何搭建普通集群与镜像集群。机器准备这里我们建立一个3台机器组成的集群，事先先在3台机器上安装好RabbitMQ服务。机器IP：10.100.3.10610.100.2.23410.100.2.235普通集群1.概要每台物理机是一个节点，消息实体只保存在一个节点上。当节点出现故障时：  消息持久化：当节点恢复时，可获取此节点未消费的消息  消息未持久化：则会丢失此节点上未消费的消息当从A节点消费B节点上消息时，会通过消费者消费的队列找到该队列所在的节点，从此节点获取获取后，返回给消费者。节点内部元数据  队列元数据：队列名称和它们的属性（是否可持久化，是否自动删除）  交换器元数据：交换器名称，类型和属性（是否持久化等）  绑定元数据：一张简单的表格展示了如何将消息路由到队列  vhost元数据：为虚拟主机内的队列，交换器和绑定提供命名空间和安全属性队列  队列的所有者节点：存储队列的元数据、状态、内容  非队列的所有者节点：保存队列的元数据和指向队列所有者的指针队列类似于节点上运行的进程，每个进程拥有自己的进程ID（集群中的Erlang地址），信道将消息进行匹配后，会建立到队列PID的连接，然后将消息发送过去。交换器不同于队列拥有自己的进程，交换器只是队列与路由键的关系表，当消息发送到交换器时，信道会将消息上的路由键与交换器的关系表进行匹配，从而决定将消息路由到哪个队列。由于交换器只是一张关系表，所以交换器会在整个集群中进行同步复制，集群中每个节点都拥有每个交换器的信息，节点故障时可以不用重新声明交换器。节点类型  内存节点（ram）：队列、交换机、绑定、用户、权限、vhost的元数据都存储在内存中  磁盘节点（disk）：元数据存放在磁盘上。一个集群至少要有一个磁盘节点，用来保存集群的配置信息正常使用时都使用磁盘节点，除非需要改进有高队列、交换或绑定的性能集群（将部分节点调整为内存节点）。RAM节点并不提供更高的消息速率。磁盘节点适合队列长存服务器的应用；内存节点适合RPC等频繁创建或销毁队列的应用。2.hosts配置在每个主机的/etc/hosts文件中加入如下配置，便于节点间访问：#rabbitmq_node110.100.3.106 DEV-HROEx64#rabbitmq_node210.100.2.234 DEV-mHRO#rabbitmq_node310.100.2.235 DEV-mHRO64如果需要主机名比较一致，可以修改主机名。[root@DEV-HROEx64 ~]# vim /etc/sysconfig/networkNETWORKING=yesHOSTNAME=DEV-HROEx64#HOSTNAME=rabbitmq_node1[root@DEV-HROEx64 ~]# reboot3.Erlang Cookie设置RabbitMQ节点之间和命令行工具（如rabbitmqctl）是使用Cookie来确认是否允许互相通信的。对于多个能够通信的节点必须要有相同的Erlang Cookie。Cookie是一组随机的数字+字母的字符串，最大为255字节。当Erlang Cookie文件不存在时，Erlang VM将尝试在RabbitMQ服务器启动时创建一个随机生成的值。.erlang.cookie文件一般在如下2个地方：1. /var/lib/rabbitmq/.erlang.cookie2. $HOME/.erlang.cookie#这里我们将rabbitmq_node2与rabbitmq_node3上的cookie，都使用rabbitmq_node1上的cookie[root@DEV-mHRO otp_src_20.3]# scp -r root@rabbitmq_node1:/root/.erlang.cookie /root/.erlang.cookie [root@DEV-mHRO64 bmsource]# scp -r root@rabbitmq_node1:/root/.erlang.cookie /root/.erlang.cookie #确认一下3台机器上的cookie是否一致#rabbitmq_node1# cat /root/.erlang.cookie ISIHBJETBSGTLNHVJLTQ#rabbitmq_node2# cat /root/.erlang.cookie ISIHBJETBSGTLNHVJLTQ#rabbitmq_node3# cat /root/.erlang.cookie ISIHBJETBSGTLNHVJLTQ4.重启RabbitMQ服务#启动RabbitMQ服务#rabbitmq_node1[root@DEV-HROEx64 ~]# rabbitmq-server -detached#rabbitmq_node2[root@DEV-HROEx64 ~]# rabbitmq-server -detached#rabbitmq_node3[root@DEV-HROEx64 ~]# rabbitmq-server -detached#查看每个节点集群状态#rabbitmq_node1[root@DEV-HROEx64 ~]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-HROEx64&#39;[{nodes,[{disc,[&#39;rabbit@DEV-HROEx64&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-HROEx64&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-HROEx64&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-HROEx64&#39;,[]}]}]#rabbitmq_node2[root@DEV-mHRO otp_src_20.3]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-mHRO&#39;[{nodes,[{disc,[&#39;rabbit@DEV-mHRO&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-mHRO&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-mHRO&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-mHRO&#39;,[]}]}]#rabbitmq_node3[root@DEV-mHRO64 bmsource]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-mHRO64&#39;[{nodes,[{disc,[&#39;rabbit@DEV-mHRO64&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-mHRO64&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-mHRO64&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-mHRO64&#39;,[]}]}]5.创建集群通过将rabbitmq_node2与rabbitmq_node3加入到rabbitmq_node1中，我们可以搭建一个集群。在rabbitmq-server启动时，会一起启动节点和应用，它预先设置RabbitMQ应用为standalone模式。要将一个节点加入到现有的集群中，需要停止这个应用并将节点设置为原始状态，然后就为加入集群准备好了。如果使用rabbitmqctl stop，应用和节点都将被关闭，而使用rabbitmqctl stop_app仅仅关闭应用。#rabbitmq_node2加入到rabbitmq_node1[root@DEV-mHRO otp_src_20.3]# rabbitmqctl stop_appStopping rabbit application on node &#39;rabbit@DEV-mHRO&#39;[root@DEV-mHRO otp_src_20.3]# rabbitmqctl join_cluster rabbit@DEV-HROEx64Clustering node &#39;rabbit@DEV-mHRO&#39; with &#39;rabbit@DEV-HROEx64&#39;[root@DEV-mHRO otp_src_20.3]# rabbitmqctl start_appStarting node &#39;rabbit@DEV-mHRO&#39;#rabbitmq_node3加入到rabbitmq_node1[root@DEV-mHRO64 bmsource]# rabbitmqctl stop_appStopping rabbit application on node &#39;rabbit@DEV-mHRO64&#39;You have mail in /var/spool/mail/root[root@DEV-mHRO64 bmsource]# rabbitmqctl join_cluster rabbit@DEV-HROEx64Clustering node &#39;rabbit@DEV-mHRO64&#39; with &#39;rabbit@DEV-HROEx64&#39;[root@DEV-mHRO64 bmsource]# rabbitmqctl start_appStarting node &#39;rabbit@DEV-mHRO64&#39;#查看每个节点集群状态#rabbitmq_node1[root@DEV-HROEx64 ~]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-HROEx64&#39;[{nodes,[{disc,[&#39;rabbit@DEV-HROEx64&#39;,&#39;rabbit@DEV-mHRO&#39;,&#39;rabbit@DEV-mHRO64&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-mHRO64&#39;,&#39;rabbit@DEV-mHRO&#39;,&#39;rabbit@DEV-HROEx64&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-HROEx64&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-mHRO64&#39;,[]},          {&#39;rabbit@DEV-mHRO&#39;,[]},          {&#39;rabbit@DEV-HROEx64&#39;,[]}]}]#rabbitmq_node2[root@DEV-mHRO otp_src_20.3]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-mHRO&#39;[{nodes,[{disc,[&#39;rabbit@DEV-HROEx64&#39;,&#39;rabbit@DEV-mHRO&#39;,&#39;rabbit@DEV-mHRO64&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-mHRO64&#39;,&#39;rabbit@DEV-HROEx64&#39;,&#39;rabbit@DEV-mHRO&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-HROEx64&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-mHRO64&#39;,[]},          {&#39;rabbit@DEV-HROEx64&#39;,[]},          {&#39;rabbit@DEV-mHRO&#39;,[]}]}]#rabbitmq_node3[root@DEV-mHRO64 bmsource]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-mHRO64&#39;[{nodes,[{disc,[&#39;rabbit@DEV-HROEx64&#39;,&#39;rabbit@DEV-mHRO&#39;,&#39;rabbit@DEV-mHRO64&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-HROEx64&#39;,&#39;rabbit@DEV-mHRO&#39;,&#39;rabbit@DEV-mHRO64&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-HROEx64&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-HROEx64&#39;,[]},          {&#39;rabbit@DEV-mHRO&#39;,[]},          {&#39;rabbit@DEV-mHRO64&#39;,[]}]}]上面集群中各节点都是磁盘节点，如果希望节点是内存节点，可以参考如下设置方法。[root@DEV-mHRO otp_src_20.3]# rabbitmqctl stop_appStopping rabbit application on node &#39;rabbit@DEV-mHRO&#39;[root@DEV-mHRO otp_src_20.3]# rabbitmqctl join_cluster --ram rabbit@DEV-HROEx64Clustering node &#39;rabbit@DEV-mHRO&#39; with &#39;rabbit@DEV-HROEx64&#39;[root@DEV-mHRO otp_src_20.3]# rabbitmqctl start_appStarting node &#39;rabbit@DEV-mHRO&#39;#查看集群状态[root@DEV-HROEx64 ~]# rabbitmqctl cluster_statusCluster status of node &#39;rabbit@DEV-HROEx64&#39;[{nodes,[{disc,[&#39;rabbit@DEV-HROEx64&#39;,&#39;rabbit@DEV-mHRO64&#39;]},         {ram,[&#39;rabbit@DEV-mHRO&#39;]}]}, {running_nodes,[&#39;rabbit@DEV-mHRO&#39;,&#39;rabbit@DEV-mHRO64&#39;,&#39;rabbit@DEV-HROEx64&#39;]}, {cluster_name,&amp;lt;&amp;lt;&quot;rabbit@DEV-HROEx64&quot;&amp;gt;&amp;gt;}, {partitions,[]}, {alarms,[{&#39;rabbit@DEV-mHRO&#39;,[]},          {&#39;rabbit@DEV-mHRO64&#39;,[]},          {&#39;rabbit@DEV-HROEx64&#39;,[]}]}]如果原先集群的挂载的节点(rabbit@DEV-HROEx64)从集群(rabbit@DEV-HROEx64)脱离了，在重新挂载到集群时，会报如下错误。[root@DEV-HROEx64 /]# rabbitmqctl join_cluster rabbit@DEV-HROEx64Clustering node &#39;rabbit@DEV-HROEx64&#39; with &#39;rabbit@DEV-HROEx64&#39;Error: cannot_cluster_node_with_itself可将节点挂载到集群中的任意有效节点(rabbit@DEV-mHRO)，则节点也会进入到集群中。[root@DEV-HROEx64 /]# rabbitmqctl join_cluster rabbit@DEV-mHRO6.从集群中移除节点6.1.在要脱离的节点机器上[root@DEV-mHRO otp_src_20.3]# rabbitmqctl stop_appStopping rabbit application on node &#39;rabbit@DEV-mHRO&#39;You have mail in /var/spool/mail/root[root@DEV-mHRO otp_src_20.3]# rabbitmqctl resetResetting node &#39;rabbit@DEV-mHRO&#39;[root@DEV-mHRO otp_src_20.3]# rabbitmqctl start_appStarting node &#39;rabbit@DEV-mHRO&#39;6.2.在其他节点机器上#模拟rabbitmq_node2没服务了[root@DEV-mHRO otp_src_20.3]# rabbitmqctl stop_appStopping rabbit application on node &#39;rabbit@DEV-mHRO&#39;#在rabbitmq_node1上移除rabbitmq_node2[root@DEV-HROEx64 ~]# rabbitmqctl forget_cluster_node rabbit@DEV-mHRORemoving node &#39;rabbit@DEV-mHRO&#39; from cluster7.web管理端查看集群状态7.1.新增集群账号在集群中任意一个节点上，新增一个可用账号。#rabbitmq_node1添加账号[root@DEV-HROEx64 ~]# rabbitmqctl add_user admin admin[root@DEV-HROEx64 ~]# rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;Setting permissions for user &quot;admin&quot; in vhost &quot;/&quot;[root@DEV-HROEx64 ~]# rabbitmqctl set_user_tags admin administratorSetting tags for user &quot;admin&quot; to [administrator]7.2.开启rabbitmq_management插件为了监控数据的准确性需要开启每台服务器的rabbitmq_management插件。#rabbitmq_node1[root@DEV-HROEx64 ~]# rabbitmq-plugins enable rabbitmq_management#rabbitmq_node2[root@DEV-mHRO ~]# rabbitmq-plugins enable rabbitmq_management#rabbitmq_node3[root@DEV-mHRO64 ~]# rabbitmq-plugins enable rabbitmq_management7.3.登录web管理端查看集群状态8.集群使用测试为了验证集群的可用性，我们将消息发送到rabbitmq_node1上的队列，在rabbitmq_node2与rabbitmq_node3获取队列里的消息。8.1.测试代码生产-node1消费-node2消费-node38.2.web管理端信息镜像集群1.概要与普通集群不同的是，镜像集群会把队列结构与消息存放在多个节点，消息会在镜像节点间同步，从而实现高可用的架构。由于需要进行节点间的同步，所以镜像集群在性能方面会降低；如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大量消耗。所以这种模式应用于可靠性要求较高的场合中。Tips：如果将消息存储置于SSD的话，就可以极大提升持久化消息通信的性能。2.如何配置镜像功能，需要通过RabbitMQ策略来实现。策略可以控制一个集群内某个vhost中的队列与交换器的镜像行为。在集群的任意节点创建策略，策略都会同步到其他节点。- Pattern：正则表达式，【\\^】代表所有队列，【\\^test】代表test开头的队列- HA mode：可选【all,exactly,nodes】，正常都使用【all】，如果使用【exactly,nodes】还需要配置HA params3.环境准备镜像集群是普通集群的扩展使用，所以可以参照普通集群的搭建方式事先进行搭建。4.创建镜像策略4.1.web管理端4.2.cli命令行[root@DEV-HROEx64 ~]# rabbitmqctl set_policy -p / test_policy2 &#39;^&#39; &#39;{&quot;ha-mode&quot;:&quot;all&quot;}&#39;Setting policy &quot;test_policy2&quot; for pattern &quot;^&quot; to &quot;{\\&quot;ha-mode\\&quot;:\\&quot;all\\&quot;}&quot; with priority &quot;0&quot;4.3.策略查看检查3台机器上的策略已经同步为一致了。#rabbitmq_node1[root@DEV-HROEx64 ~]# rabbitmqctl list_policiesListing policies/	test_policy2	all	^	{&quot;ha-mode&quot;:&quot;all&quot;}	0/	test_policy	    all	^	{&quot;ha-mode&quot;:&quot;all&quot;}	0#rabbitmq_node2[root@DEV-mHRO ~]# rabbitmqctl list_policiesListing policies/	test_policy2	all	^	{&quot;ha-mode&quot;:&quot;all&quot;}	0/	test_policy	    all	^	{&quot;ha-mode&quot;:&quot;all&quot;}	0#rabbitmq_node3[root@DEV-mHRO64 ~]# rabbitmqctl list_policiesListing policies/	test_policy2	all	^	{&quot;ha-mode&quot;:&quot;all&quot;}	0/	test_policy	    all	^	{&quot;ha-mode&quot;:&quot;all&quot;}	05.镜像集群使用测试测试代码同上面普通集群的测试代码。参考资料普通集群镜像集群"
  },
  
  {
    "title": "RabbitMQ学习-交换器",
    "url": "/posts/6-rabbitmq-study-exchange/",
    "categories": "",
    "tags": "rabbitmq, php",
    "date": "2018-05-12 20:50:00 +0800",
    





    "snippet": "  介绍RabbitMQ中，不同交换器的特性与常用使用方法。rabbit消息处理结构fanout官方文档1.概述将发送到此交换器的消息，推送给所有与它绑定的队列中。可实现生产者发送一条消息，多个消费者都可进行消费的架构。此交换器，在使用queue_bind方法时会忽视传入的$routing_key参数。2.Publish/Subscribe(发布/订阅)1.结构图2.注意事项生产者：1.消息推送到定义的交换器2.不主动将消息推送到队列(通过绑定)，而是等待消费者定义队列与此交换器绑定3.在有队列绑定到交换器前，产生的消息都将会丢弃4.如果想消息持久化，需要配置消息参数[&#39;delivery_mode&#39; =&amp;gt; AMQPMessage::DELIVERY_MODE_PERSISTENT]消费者：1.队列可以手动进行指定，配合队列持久化，消费者程序停止运行后，队列不删除，存在绑定关系，队列能继续接受到消息，等待下次有消费者访问时使用2.队列可以自动生成，队列不需要持久化，消费者程序停止运行后，队列自动删除，不存在绑定关系，队列不能继续接受消息3.消息一般只接受从绑定到交换器之后的消息，除非绑定是已存在且有消息的队列3.代码示例生产者消费者-持久化队列消费者-非持久化队列direct官方文档1.概述将发送到此交换器的消息，推送给binding key(exchange)与routing key(queue)完全匹配的队列中。可实现生产者发送一条消息，消费者根据情况，进行选择消费的架构。当推送消息的routekey没有队列与其进行绑定时，则消息会被丢弃。2.Routing(路由)1.结构图2.注意事项生产者：1.根据需求对交换器发送不同routekey的消息消费者：1.同一队列可以绑定多个routekey2.不同队列可以绑定同个routekey，类似于fanout功能3.代码示例生产者消费者-同一队列可以绑定多个routekey-info,warning消费者-同一队列可以绑定多个routekey-error消费者-不同队列可以绑定同个routekey-info1消费者-不同队列可以绑定同个routekey-info2topic1.概述官方文档将发送到此交换器的消息，推送给binding key(exchange)与routing key(queue)模糊匹配的队列中。可实现生产者发送一条消息，消费者根据情况，进行选择消费的架构。当推送消息的routekey没有队列与其进行绑定时，则消息会被丢弃。routekey规则：使用【.】连接的标识符【[a-z0-9]+】，上限为255字节。如【mobile.android.miaomi】*：可以匹配一个标识符，如【mobile.*.*】,【*.android.*】#：可匹配0个或多个标识符，如【mobile.#】，注意【#】前面的【.】不能少2.Topics(主题)1.结构图2.注意事项生产者：1.根据需求对交换器发送不同routekey的消息消费者：1.同一队列可以绑定多个routekey2.不同队列可以绑定同个routekey，类似于fanout功能3.当队列绑定多个routekey时，即使消息满足多个routekey也只会进一次队列4.当队列绑定【#】时，会接受所有消息3.代码示例生产者消费者-*.android.*消费者-*.*.iphone-computer.#消费者-#headersRPC1.概述官方文档此节内容并不是exchange的一种类型，而是通过RabbitMQ实现Remote Procedure Call（远程过程调用）。客户端可以发送请求给远程服务器，远程服务器来实现具体的逻辑运算，再将运算结果返回给客户端，从而可搭建运算中心，运算中心根据需求可进行扩展。2.rpc demo1.结构图2.注意事项客户端：1.在请求服务器时，需要预定义响应队列（随机队列），用于服务器完成逻辑处理时，可以把返回信息推送到此队列中，便于客户端接收2.对于发送的每条消息需要增加唯一的correlation_id属性，当客户端接收响应时判断是否为响应自己的请求服务器：1.为了请求的更好处理与多服务的分配，设置一次只接受一个请求3.代码示例客户端服务器Deal Letter1.概述此节内容并不是exchange的一种类型，而是介绍RabbitMQ中的死信。当消息出现如下情况时，会变成一条死信：1.消息被拒绝（业务处理失败）（basic.reject or basic.nack）并且requeue=false 2.消息TTL过期 3.队列达到最大长度对于有些死信，在业务上可能并希望永远丢掉，而是希望有别的处理，这时就需要对死信进行收集。可以对收集死信的队列，增加如下参数：1.x-dead-letter-exchange(交换器)：将死信消息推送给哪个交换器2.x-dead-letter-routing-key(路由键)：推送消息时，附加的路由键（参见direct-routing文档），如果不设置则使用原消息的routekey，用于交换器进行消息路由2.rpc demo1.结构图2.注意事项1.为了保证死信消息能正常接收，需要有一个queue与死信exchange通过routekey进行绑定3.代码示例客户端服务器-line 43Alternate Exchange1.概述此节内容并不是exchange的一种类型，而是介绍RabbitMQ中的备用交换器。对于有些未被路由的消息（业务垃圾消息，攻击消息），在业务上可能并不希望永远丢掉，而是希望有别的处理，这时就需要对这些消息进行收集。可以对收集未路由消息的交换器，增加如下参数：1.alternate-exchange(交换器)：将未路由的消息推送给哪个交换器2.demo1.结构图2.注意事项1.为了保证未被路由的消息能正常接收，需要设置备用交换器的类别为fanout，这样任意与此交换器绑定的队列都能接受到消息，而不需要考虑routing key3.代码示例生产者"
  },
  
  {
    "title": "RabbitMQ学习-php-amqplib",
    "url": "/posts/5-rabbitmq-study-php-amqplib/",
    "categories": "",
    "tags": "rabbitmq, php",
    "date": "2018-05-08 20:50:00 +0800",
    





    "snippet": "  介绍php-amqplib中的类，类之间的关系，常见的使用方法。概述项目git地址。此库是使用纯php实现的AMQP 0-9-1协议，通过它可以让我们很方便的来使用rabbitmq的功能。使用方法这里以一个简单的exchange=redirect的例子，来通过代码演示怎么实现生产者与消费者。1.生产者戳这里看完整producer代码use Lib\\PhpAmqpLib\\Connection\\AMQPStreamConnection;use Lib\\PhpAmqpLib\\Message\\AMQPMessage;$strExchange = &#39;exchange_direct_simple&#39;;$strQueue = &#39;queue_direct_simple&#39;;$objConnection = new AMQPStreamConnection(&#39;127.0.0.1&#39;, 5672, &#39;admin&#39;, &#39;admin&#39;);$objChannel = $objConnection-&amp;gt;channel();$objChannel-&amp;gt;queue_declare($strQueue, false, true, false, false);$objChannel-&amp;gt;exchange_declare($strExchange, &#39;direct&#39;, false, true, false);$objChannel-&amp;gt;queue_bind($strQueue, $strExchange);$objMessage = new AMQPMessage(&#39;hello world!&#39;);$objChannel-&amp;gt;basic_publish($objMessage, $strExchange);$objChannel-&amp;gt;close();$objConnection-&amp;gt;close();2.消费者戳这里看完整consumer代码use Lib\\PhpAmqpLib\\Connection\\AMQPStreamConnection;use Lib\\PhpAmqpLib\\Message\\AMQPMessage;$strExchange = &#39;exchange_direct_simple&#39;;$strQueue = &#39;queue_direct_simple&#39;;$strConsumerTag = &#39;consumer_direct_simple&#39;;$objConnection = new AMQPStreamConnection(&#39;127.0.0.1&#39;, 5672, &#39;admin&#39;, &#39;admin&#39;);$objChannel = $objConnection-&amp;gt;channel();$objChannel-&amp;gt;queue_declare($strQueue, false, true, false, false);$objChannel-&amp;gt;exchange_declare($strExchange, &#39;direct&#39;, false, true, false);$objChannel-&amp;gt;queue_bind($strQueue, $strExchange);//定义回调函数function callback_func($objMessage) {    echo &quot; [x] Received &quot;, $objMessage-&amp;gt;body, &quot;\\n&quot;;}//php中止时执行的函数function shutdown($objChannel, $objConnection) {    //关闭信道与断开连接    $objChannel-&amp;gt;close();    $objConnection-&amp;gt;close();}register_shutdown_function(&#39;shutdown&#39;, $objChannel, $objConnection);$objChannel-&amp;gt;basic_consume($strQueue, $strConsumerTag, false, true, false, false, &#39;callback_func&#39;);//阻塞等待服务器推送消息while (count($objChannel-&amp;gt;callbacks)) {    $objChannel-&amp;gt;wait();}代码结构类的归类戳这里看详细说明UML代码流程创建connection创建channelwait处理发送消息(producer)接收消息(consumer)代码注释戳这里看代码注释参考资料消费者应答和发送者确认"
  },
  
  {
    "title": "RabbitMQ学习-web管理页面",
    "url": "/posts/4-rabbitmq-study-web-management/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2018-05-08 20:50:00 +0800",
    





    "snippet": "  介绍如何配置与使用RabbitMQ的web管理页面。配置网页插件1.启用插件需要使用到rabbitmq-plugins命令。[root@vagrant otp_src_20.3]# rabbitmq-plugins enable rabbitmq_management查看是否启用成功，15672端口是否处于监听状态。[root@vagrant otp_src_20.3]# netstat -anp|grep 15672tcp        0      0 0.0.0.0:15672               0.0.0.0:*                   LISTEN      29468/beam.smp      tcp        0      0 10.100.255.115:15672        10.100.255.1:59372          ESTABLISHED 29468/beam.smp    如果需要关闭的话，可使用如下命令。[root@vagrant otp_src_20.3]# rabbitmq-plugins disable rabbitmq_management2.网站初体验可通过ip:15672的形式来访问网站。如果访问不了，可尝试使用如下一些解决方法。      使用域名本地虚拟机，直接通过ip访问不了，在C:\\Windows\\System32\\drivers\\etc\\hosts中增加如下配置：10.100.255.115 test.51job.com之后使用test.51job.com:15672访问。        开启端口号iptables -I INPUT -p tcp --dport 15672 -j ACCEPT        配置插件使用目录mkdir /etc/rabbitmq  3.用户添加与权限设置刚刚看到了网站，可惜没有账号密码怎么办呢，请往下看。#新增一个账号(admin)，并设置密码(admin)[root@vagrant otp_src_20.3]# rabbitmqctl add_user admin admin#设置账号的目录，读写权限[root@vagrant otp_src_20.3]# rabbitmqctl set_permissions -p / admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;#设置账号的角色，可有哪些操作权限[root@vagrant otp_src_20.3]# rabbitmqctl set_user_tags admin administrator4.网站再体验使用刚刚设置的账号与密码，就可以登录进来了。网页插件功能说明1.Overview-概览Totals：总况Nodes：节点Ports and contextsExport definitionsImport definitions2.Connections-连接3.Channels-信道4.Exchanges-交换器5.Queues-队列6.Admin-账号管理"
  },
  
  {
    "title": "RabbitMQ学习-服务器命令",
    "url": "/posts/3-rabbitmq-study-server-command/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2018-05-08 19:50:00 +0800",
    





    "snippet": "  介绍RabbitMQ服务端命令的使用方法与作用。rabbitmq-serverRabbitMQ节点一般指RabbitMQ应用程序和其所在的Erlang节点，当运行在Erlang节点上的应用程序崩溃时，Erlang会自动尝试重启应用程序（如果Erlang本身没有崩溃）。启动节点#前台启动rabbitmq-server#后台启动（守护进程）rabbitmq-server -detached#增加启动变量RABBITMQ_NODE_PORT=5673 rabbitmq-server -detached关闭#只关闭应用程序，可用于加入及退出集群的操作[root@vagrant rabbitmq]# rabbitmqctl stop_appStopping rabbit application on node rabbit@vagrant ...#关闭整个节点[root@vagrant rabbitmq]# rabbitmqctl stopStopping and halting node rabbit@vagrant ...rabbitmqctl此命令用于管理RabbitMQ节点。#可在指定节点上执行命令rabbitmqctl -n nodename commondTips：如下有些命令，在低版本里会没有。集群管理join_cluster将当前节点添加到集群中，使用此命令前需要先停止节点应用。  clusternode：现有集群中的任意节点  –ram：标记新加入的节点是否为内存节点，默认为磁盘节点#命令格式join_cluster clusternode [--ram]#示例rabbitmqctl stop_apprabbitmqctl join_cluster rabbit@DEV-HROEx64rabbitmqctl start_appcluster_status查看集群状态。#命令格式cluster_status#示例rabbitmqctl cluster_statuschange_cluster_node_type修改集群节点类型，使用此命令前需要先停止节点应用。  type：disc或ram#命令格式change_cluster_node_type type#示例rabbitmqctl stop_apprabbitmqctl change_cluster_node_type discrabbitmqctl start_appforget_cluster_node远程从集群中移除节点，被移除的节点需要处于离线状态，操作的节点需要处于在线状态，除非使用--offline参数。  –offline：允许从离线节点中远程删除其它节点#命令格式forget_cluster_node [--offline]#示例rabbitmqctl forget_cluster_node rabbit@DEV-mHROsync_queue同步集群中状态为未同步的队列，此命令将导致队列阻塞，发布者与消费者将不能使用此队列。如果未同步的队列有正常消费者消费消息的话，队列最终会变为同步的。此命令主要用于不活动的队列。#命令格式sync_queue [-p vhost] queue#示例rabbitmqctl sync_queue jobseek_confirm_type1cancel_sync_queue停止队列的同步。#命令格式cancel_sync_queue [-p vhost] queue#示例rabbitmqctl cancel_sync_queue jobseek_confirm_type1purge_queue清空队列中的消息。#命令格式purge_queue [-p vhost] queue#示例rabbitmqctl purge_queue jobseek_confirm_type1用户管理add_user添加用户并设置初始密码。#命令格式add_user username password#示例rabbitmqctl add_user user_test 123456delete_user删除用户。#命令格式delete_user username#示例rabbitmqctl delete_user user_testchange_password修改用户的密码。#命令格式change_password username newpassword#示例rabbitmqctl change_password user_test 654321clear_password删除用户的密码。此操作会导致用户使用密码不能登录(除非使用其他配置登录，如SASL EXTERNAL)。#命令格式clear_password username#示例rabbitmqctl clear_password user_testauthenticate_user验证用户名与密码是否匹配。#命令格式authenticate_user username password#示例rabbitmqctl authenticate_user user_test 123456set_user_tags设置用户角色，同时会清除现有的所有设置。  management：普通管理者，仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对策略进行管理  policymaker：策略制定者，可登陆管理控制台(启用management plugin的情况下), 同时可以对policy进行管理  monitoring：监控者，可登陆管理控制台(启用management plugin的情况下)，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)  administrator：超级管理员，可登陆管理控制台(启用management plugin的情况下)，可查看所有的信息，并且可以对用户，策略(policy)进行操作#命令格式set_user_tags username [tag ...]#示例rabbitmqctl set_user_tags user_test administratorlist_users显示所有用户及用户的角色。#命令格式rabbitmqctl list_users#示例rabbitmqctl list_users访问控制add_vhost创建新的虚拟主机#命令格式add_vhost vhost#示例rabbitmqctl add_vhost testdelete_vhost删除已有的虚拟主机，同时会删除虚拟主机中的交换器、队列、绑定、用户权限、参数和策略。#命令格式delete_vhost vhost#示例rabbitmqctl delete_vhost testlist_vhosts显示所有主机信息，vhostinfoitem可为{name,tracing}#命令格式list_vhosts [vhostinfoitem ...]#示例rabbitmqctl list_vhosts name tracingset_permissions将虚拟主机指派给用户，同时设置相应权限。资源一般可理解为队列，交换器等。  [-p vhost]：需要指派的主机名称，默认为“/”  user：需要指派的用户  conf：用户可配置（交换器与队列的新建或删除）的资源名称，使用正则表达式匹配  write：用户可写（发布消息，需要绑定成功）的资源名称，使用正则表达式匹配  read：用户可读（消息的操作，需要绑定成功）的资源名称，使用正则表达式匹配如下为不同AMQP命令对应的权限            AMQP命令      配置      写      读                  exchange.declare      exchange                            exchange.delete      exchange                            queue.declare      queue                            queue.delete      queue                            queue.bind             queue      exchange              basic.publish             exchange                     basic.get                    queue              basic.consume                    queue              queue.purge                    queue      #命令格式set_permissions [-p vhost] user conf write read#示例rabbitmqctl set_permissions -p vhost-test user-test &quot;.*&quot; &quot;.* &quot;.*&quot;clear_permissions移除用户的在某个虚拟主机上的权限。#命令格式clear_permissions [-p vhost] username#示例rabbitmqctl clear_permissions -p vhost_test user_testlist_permissions显示某虚拟主机下的用户及用户的权限。#命令格式list_permissions [-p vhost]#示例rabbitmqctl list_permissions -p vhost_testlist_user_permissions显示用户所关联的虚拟主机及相应的权限。#命令格式list_user_permissions username#示例rabbitmqctl list_user_permissions user_testset_topic_permissions设置用户在虚拟主机中对于某个主题交换器，可发布或获取消息的routing key。  [-p vhost]：需要指派的主机名称，默认为“/”  user：需要指派的用户  exchange：用户可配置的资源名称，使用正则表达式匹配  write：用户发布消息的routing key，使用正则表达式匹配  read：用户获取消息的routing key，使用正则表达式匹配#命令格式set_topic_permissions [-p vhost] user exchange write read#示例rabbitmqctl set_topic_permissions -p vhost_test user_test amq.topic &quot;^xpz-.*&quot; &quot;^xpz-.*&quot;clear_topic_permissions清除用户在主题交换器上的权限限制。#命令格式clear_topic_permissions [-p vhost] username [exchange]#示例rabbitmqctl clear_topic_permissions -p vhost_test user_test amq.topiclist_topic_permissions显示虚拟主机上所有用户的主题权限限制。#命令格式list_topic_permissions [-p  vhost]#示例rabbitmqctl list_topic_permissions -p vhost_testlist_topic_user_permissions显示用户所关联的虚拟主机及相应的主题权限限制。#命令格式list_user_topic_permissions username#示例rabbitmqctl list_topic_user_permissions user_test虚拟主机限制set_vhost_limits对虚拟主机设置某些限制。definition为json格式的字符串，当值为负数时表示不做任何限制。  max-connections：设置最大连接数  max-queues：设置最多队列数#命令格式set_vhost_limits [-p vhost] definition#示例#设置最大连接数为64rabbitmqctl set_vhost_limits -p vhost_test &#39;{&quot;max-connections&quot;: 64}&#39;#设置最多队列数为256rabbitmqctl set_vhost_limits -p vhost_test &#39;{&quot;max-queues&quot;: 256}&#39;#设置最大连接数为不受限rabbitmqctl set_vhost_limits -p vhost_test &#39;{&quot;max-connections&quot;: -1}&#39;#设置最大连接数为0，不允许任何连接进来rabbitmqctl set_vhost_limits -p vhost_test &#39;{&quot;max-connections&quot;: 0}&#39;clear_vhost_limits清除虚拟主机上的限制。#命令格式clear_vhost_limits [-p vhost]#示例rabbitmqctl clear_vhost_limits -p vhost_testlist_vhost_limits清除虚拟主机上的限制。#命令格式list_vhost_limits [-p vhost] [--global]#示例#显示指定虚拟主机rabbitmqctl list_vhost_limits -p vhost_test#显示所有虚拟主机rabbitmqctl list_vhost_limits --global使用统计list_queues显示队列信息，默认主机为【/】  –offline：主节点不可用的持久化队列  –online：主节点可用的队列  –local：主节点在当前进程上的队列queueinfoitem可选参数  name：队列名称  durable：队列是否持久的，服务器重启后仍存在  auto_delete：当队列不使用时，是否自动删除  arguments：队列参数  policy：有效的队列策略  pid：队列的Erlang进程id  owner_pid：当队列为独占时，连接的Erlang进程id  exclusive：队列是否独占  exclusive_consumer_pid：订阅队列的独占消费者的信道的Erlang进程id  exclusive_consumer_tag：订阅队列的独占消费者的标签  messages_ready：可被消费者消费的消息数  messages_unacknowledged：已被消费者获取，但还未确认的消息数  messages：messages_ready+messages_unacknowledged  messages_ready_ram：内存中，可被消费者消费的消息数  messages_unacknowledged_ram：内存中，已被消费者获取，但还未确认的消息数  messages_ram：内存中，messages_ready+messages_unacknowledged  messages_persistent：队列中的持久化消息数  message_bytes：队列中消息的大小(仅算正文)  message_bytes_ready：队列中消息的大小(仅算正文)，可被消费者消费的消息数  message_bytes_unacknowledged：队列中消息的大小(仅算正文)，已被消费者获取，但还未确认的消息数  message_bytes_ram：队列中在内存消息的大小(仅算正文)  message_bytes_persistent：队列中持久化消息的大小(仅算正文)  head_message_timestamp：队列中第一条消息的timestamp  disk_reads：队列启动后从磁盘读取消息的总次数  disk_writes：队列启动后向磁盘写入消息的总次数  consumers：消费者数量  consumer_utilisation：队列能够立即向消费者传递消息的时间分数（介于0.0和1.0之间）。如果消费者受到网络拥塞或预取计数的限制，则可以小于1.0  memory：队列运行时分配的内存字节数，包括堆栈，堆和内部结构  slave_pids：如果队列是镜像的，则列出镜像的ID(跟随者副本)  synchronised_slave_pids：如果镜像是队列，则列出主（领导者）同步的镜像（跟随者副本）的ID  state：队列状态，一般为running#命令格式list_queues [-p vhost] [--offline | --online | --local] [queueinfoitem ...]#示例rabbitmqctl list_queues name pidlist_exchanges显示交换器信息，默认主机为【/】exchangeinfoitem可选参数  name：交换器名称  type：交换器类型(fanout,direct,headers,topic)  durable：交换器是否持久的，服务器重启后仍存在  auto_delete：当交换器不使用时，是否自动删除  internal：是否内部交换器，  arguments：交换器参数  policy：应用在交换器上的策略名称#命令格式list_exchanges [-p vhost] [exchangeinfoitem ...]#示例rabbitmqctl list_exchanges name typelist_bindings显示绑定信息，默认主机为【/】bindinginfoitem可选参数  source_name：交换器名称  source_kind：exchange  destination_name：队列名称  destination_kind：queue  routing_key：绑定的路由键  arguments：绑定参数#命令格式list_bindings [-p vhost] [bindinginfoitem ...]#示例rabbitmqctl list_bindingslist_connections显示连接信息connectioninfoitem可选参数  pid：与连接关联的Erlang进程id  name：连接的可读名称  port：服务器端口  host：服务器ip  peer_port：客户端端口  peer_host：客户端ip  ssl：是否开启ssl  ssl_protocol：ssl协议  ssl_key_exchange：SSL密钥交换算法（例如“rsa”）  ssl_cipher：SSL密码算法（例如“aes_256_cbc”）  ssl_hash：SSL散列函数（例如“sha”）  peer_cert_subject：对等方SSL证书的主题，RFC4514格式  peer_cert_issuer：对等方SSL证书的颁发者，采用RFC4514格式  peer_cert_validity：对等方SSL证书有效的时间段  state：连接状态（starting,tuning,opening,running,flow,blocking,blocked,closing,closed）  channels：使用连接的信道数量  protocol：AMQP协议版本（0.9.1,0.8.0）  auth_mechanism：使用SASL身份验证机制，例如“PLAIN”  user：连接使用的用户名  vhost：连接的虚拟主机  timeout：连接的超时时间/心跳间隔  frame_max：最大帧大小  channel_max：连接的可用信道数  client_properties：连接的客户端属性  recv_oct：Octets received  recv_cnt：Packets received  send_oct：Octets send  send_cnt：Packets sent  send_pend ：Send queue size  connected_at：连接建立时间#命令格式list_connections [connectioninfoitem ...]#示例rabbitmqctl list_connectionslist_channels显示信道信息channelinfoitem可选参数  pid：与连接关联的Erlang进程id  connection：信道所在的连接  name：信道名称  number：信道编号  user：连接使用的用户名  vhost：连接的虚拟主机  confirm：信道是否处于确认模式  consumer_count：信道的消费者数量  messages_unacknowledged：未被确认的已发布的消息数  messages_unconfirmed：未被消费者确认的消息数  prefetch_count：新消费者的预取限制  global_prefetch_count：整个信道的预取限制#命令格式list_channels [channelinfoitem ...]#示例rabbitmqctl list_channelslist_consumers显示消费者信息#命令格式list_consumers [-p vhost]#示例rabbitmqctl list_consumers策略管理set_policy设置主机的策略，默认主机为【/】  -p：虚拟主机  –priority：策略优先级，数字越大优先级越高  –apply-to：策略应用对象，【queues,exchanges,all】，默认为【all】  name：策略名称  pattern：匹配的资源名称，使用正则表达式匹配  definition：策略定义，使用JSON格式，可参考web管理系统的policies设置页#命令格式set_policy [-p vhost] [--priority priority] [--apply-to apply-to] name pattern definition#示例rabbitmqctl set_policy -p interview ha_policy &#39;^&#39; &#39;{&quot;ha-mode&quot;:&quot;all&quot;}&#39;clear_policy删除主机的策略，默认主机为【/】#命令格式clear_policy [-p vhost] name#示例clear_policy -p interview ha_policylist_policies显示主机的策略，默认主机为【/】#命令格式list_policies [-p vhost]#示例rabbitmqctl list_policies -p interviewrabbitmq-plugins参考资料rabbitmq-serverrabbitmqctlrabbitmq-plugins"
  },
  
  {
    "title": "RabbitMQ学习-遇到的问题",
    "url": "/posts/2-rabbitmq-study-problems/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2018-05-08 18:50:00 +0800",
    





    "snippet": "  介绍在使用过程中碰到的一些问题及相应的解决方法。rabbit服务启动问题1.openssl未支持此问题出现在公司电脑的虚拟机上，在启动rabbit时出现如下错误。[root@vagrant bmsource]# rabbitmq-server startError description:   {error,{missing_dependencies,[crypto,ssl],                                [cowboy,cowlib,rabbitmq_management,                                 rabbitmq_management_agent,                                 rabbitmq_trust_store]}}Log files (may contain more information):   /usr/local/rabbitmq/var/log/rabbitmq/rabbit@vagrant.log   /usr/local/rabbitmq/var/log/rabbitmq/rabbit@vagrant-sasl.logStack trace:   [{rabbit_plugins,ensure_dependencies,1,                    [{file,&quot;src/rabbit_plugins.erl&quot;},{line,185}]},    {rabbit_plugins,prepare_plugins,1,                    [{file,&quot;src/rabbit_plugins.erl&quot;},{line,203}]},    {rabbit,broker_start,0,[{file,&quot;src/rabbit.erl&quot;},{line,300}]},    {rabbit,start_it,1,[{file,&quot;src/rabbit.erl&quot;},{line,424}]},    {init,start_em,1,[]},    {init,do_boot,3,[]}]{&quot;init terminating in do_boot&quot;,{error,{missing_dependencies,[crypto,ssl],[cowboy,cowlib,rabbitmq_management,rabbitmq_management_age}init terminating in do_boot ({error,{missing_dependencies,[crypto,ssl],[cowboy,cowlib,rabbitmq_management,rabbitmq_management_agent)Crash dump is being written to: erl_crash.dump...done查询发现服务器上没有安装openssl的扩展，安装openssl后，重新编译安装erlang。[root@vagrant bmsource]# yum install openssl openssl-devel[root@vagrant bmsource]# rm -rf otp_src_20.3[root@vagrant bmsource]# tar -xvf otp_src_20.3.tar.gz [root@vagrant bmsource]# cd otp_src_20.3[root@vagrant otp_src_20.3]# ./configure --prefix=/usr/local/erlang[root@vagrant otp_src_20.3]# make &amp;amp;&amp;amp; make install启动rabbit，查看状态正常。-detached：表示已守护进程的方式运行。[root@vagrant otp_src_20.3]# rabbitmq-server -detachedWarning: PID file not written; -detached was passed.[root@vagrant otp_src_20.3]# rabbitmqctl statusStatus of node rabbit@vagrant[{pid,29468}, {running_applications,     [{rabbit,&quot;RabbitMQ&quot;,&quot;3.6.15&quot;},      {ranch,&quot;Socket acceptor pool for TCP protocols.&quot;,&quot;1.3.2&quot;},      {ssl,&quot;Erlang/OTP SSL application&quot;,&quot;8.2.4&quot;},      {public_key,&quot;Public key infrastructure&quot;,&quot;1.5.2&quot;},      {asn1,&quot;The Erlang ASN1 compiler version 5.0.5&quot;,&quot;5.0.5&quot;},      {crypto,&quot;CRYPTO&quot;,&quot;4.2.1&quot;},      {rabbit_common,          &quot;Modules shared by rabbitmq-server and rabbitmq-erlang-client&quot;,          &quot;3.6.15&quot;},      {xmerl,&quot;XML parser&quot;,&quot;1.3.16&quot;},      {recon,&quot;Diagnostic tools for production use&quot;,&quot;2.3.2&quot;},      {os_mon,&quot;CPO  CXC 138 46&quot;,&quot;2.4.4&quot;},      {compiler,&quot;ERTS  CXC 138 10&quot;,&quot;7.1.5&quot;},      {mnesia,&quot;MNESIA  CXC 138 12&quot;,&quot;4.15.3&quot;},      {syntax_tools,&quot;Syntax tools&quot;,&quot;2.1.4&quot;},      {sasl,&quot;SASL  CXC 138 11&quot;,&quot;3.1.1&quot;},      {stdlib,&quot;ERTS  CXC 138 10&quot;,&quot;3.4.4&quot;},      {kernel,&quot;ERTS  CXC 138 10&quot;,&quot;5.4.3&quot;}]}, {os,{unix,linux}}, {erlang_version,     &quot;Erlang/OTP 20 [erts-9.3] [source] [64-bit] [smp:1:1] [ds:1:1:10] [async-threads:64] [hipe] [kernel-poll:true]\\n&quot;},2.hosts配置问题此问题出现在阿里云机器上，在启动rabbit时出现如下错误。[root@i-wz9i8fd8lio2yh3oeriz bmsource]# rabbitmq-server -detachedWarning: PID file not written; -detached was passed.ERROR：epmd error for host i-wz9i8fd8lio2yh3oeriz：timeout（time out）查看错误信息，推断可能跟hosts有关系，查询/etc/hosts，发现有奇怪的一行，注释掉先。#10.116.9.118 i-wz9i8fd8lio2yh3oeriz启动rabbit，可正常启动。[root@i-wz9i8fd8lio2yh3oeriz bmsource]# rabbitmq-server -detachedWarning: PID file not written; -detached was passed.[root@i-wz9i8fd8lio2yh3oeriz bmsource]#3.Erlang Cookie问题此问题出现在搭建集群时，在关闭重启rabbit时出现如下错误。[root@DEV-mHRO64 bmsource]# rabbitmqctl stopStopping and halting node &#39;rabbit@DEV-mHRO64&#39;Error: unable to connect to node &#39;rabbit@DEV-mHRO64&#39;: nodedownDIAGNOSTICS===========attempted to contact: [&#39;rabbit@DEV-mHRO64&#39;]rabbit@DEV-mHRO64:  * connected to epmd (port 4369) on DEV-mHRO64  * epmd reports node &#39;rabbit&#39; running on port 25672  * TCP connection succeeded but Erlang distribution failed  * Authentication failed (rejected by the remote node), please check the Erlang cookiecurrent node details:- node name: &#39;rabbitmq-cli-23@DEV-mHRO64&#39;- home dir: /root- cookie hash: r5tor8XZxXSjsNTj8qfTyg==根据错误信息联想，先启动了Rabbit服务，然后将Cookie更新为rabbitmq_node1上的Cookie了，所以验证不了导致错误。没找到其他可用方法，所以通过将进程杀掉的方法来解决。[root@DEV-mHRO64 bmsource]# ps -aux|grep rabbitWarning: bad syntax, perhaps a bogus &#39;-&#39;? See /usr/share/doc/procps-3.2.8/FAQroot     12581  0.1  1.6 3851948 66348 ?       Sl   May24   1:59 /usr/local/erlang/lib/erlang/erts-9.3/bin/beam.smp -W w -A 64 -P 1048576 -t 5000000 -stbt db -zdbbl 128000 -K true -- -root /usr/local/erlang/lib/erlang -progname erl -- -home /root -- -pa /usr/local/rabbitmq/ebin -noshell -noinput -s rabbit boot -sname rabbit@DEV-mHRO64 -boot start_sasl -kernel inet_default_connect_options [{nodelay,true}] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger {file,&quot;/usr/local/rabbitmq/var/log/rabbitmq/rabbit@DEV-mHRO64.log&quot;} -rabbit sasl_error_logger {file,&quot;/usr/local/rabbitmq/var/log/rabbitmq/rabbit@DEV-mHRO64-sasl.log&quot;} -rabbit enabled_plugins_file &quot;/usr/local/rabbitmq/etc/rabbitmq/enabled_plugins&quot; -rabbit plugins_dir &quot;/usr/local/rabbitmq/plugins&quot; -rabbit plugins_expand_dir &quot;/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@DEV-mHRO64-plugins-expand&quot; -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir &quot;/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/rabbit@DEV-mHRO64&quot; -kernel inet_dist_listen_min 25672 -kernel inet_dist_listen_max 25672 -noshell -noinputroot     23573  0.0  0.0 103248   888 pts/2    S+   13:42   0:00 grep rabbit[root@DEV-mHRO64 bmsource]# kill -9 12581测试可正常启动与关闭服务。[root@DEV-mHRO64 bmsource]# rabbitmq-server -detachedWarning: PID file not written; -detached was passed.You have mail in /var/spool/mail/root[root@DEV-mHRO64 bmsource]# netstat -anp|grep 5672tcp        0      0 0.0.0.0:25672               0.0.0.0:*                   LISTEN      29960/beam.smp tcp        0      0 :::5672                     :::*                        LISTEN      29960/beam.smp [root@DEV-mHRO64 bmsource]# netstat -anp|grep 5672You have mail in /var/spool/mail/root[root@DEV-mHRO64 bmsource]# 消息推送接收问题1.生产者发送消费者没接收到在demo示例中，程序一直是正常的，没改过任何东西，在终端运行时出现问题。查询web控制台发现，队列被2个消费者绑定了，但是终端感觉只有一个，还有一个不知道是不是测试没处理好，导致一直在运行。处理方法只能在web控制台关闭连接了。2.消费者中使用生产者业务需要在第1级的消费者中生产供第2级消费者使用的消息，在持续生产消息时出现了如下异常。Memo:[ errno:2  errstr:socket_write(): unable to write to socket [32]: Broken pipe  errfile:/vagrant/htdocs/Interview2/framework/Service/Lib/PhpAmqpLib/Wire/IO/SocketIO.php  errline:163 ]Trace:[文件：/vagrant/htdocs/Interview2/framework/Service/Log/Log.php，方法：getBackTrace，行号：58文件：/vagrant/htdocs/Interview2/framework/Service/Foundation/BootStrap/HandleExceptions.php，方法：log，行号：61文件：，方法：handleError，行号：文件：/vagrant/htdocs/Interview2/framework/Service/Lib/PhpAmqpLib/Wire/IO/SocketIO.php，方法：socket_write，行号：163文件：/vagrant/htdocs/Interview2/framework/Service/Lib/PhpAmqpLib/Connection/AbstractConnection.php，方法：write，行号：320文件：/vagrant/htdocs/Interview2/framework/Service/Lib/PhpAmqpLib/Connection/AbstractConnection.php，方法：write，行号：432文件：/vagrant/htdocs/Interview2/framework/Service/Lib/PhpAmqpLib/Channel/AbstractChannel.php，方法：send_channel_method_frame，行号：224文件：/vagrant/htdocs/Interview2/framework/Service/Lib/PhpAmqpLib/Channel/AMQPChannel.php，方法：send_method_frame，行号：1165文件：/vagrant/htdocs/Interview2/framework/Service/MessageQueue/QueueProducerBase.php，方法：confirm_select，行号：58文件：/vagrant/htdocs/Interview2/app/Service/MessageQueue/Producer/SendMsgProcuder.php，方法：build，行号：35文件：/vagrant/htdocs/Interview2/app/Service/MessageQueue/Producer/SendMsgProcuder.php，方法：init，行号：45问题查找与分析：  1.此异常说明在向服务器publish消息时，连接已经断开了，断开可能原因如下  1.1.由于过了心跳时间（生产者不能像消费者那样一直与服务器交互，发完消息就没有交互了），服务器主动断开了连接  1.2.多次publish消息使用同一个channel解决方法：  1.同一个连接每次publish消息时，都创建新的channel，并刷新连接空闲时间  2.当连接中channel数超过1W或连接闲置一定时间时，重新创建连接protected function producerReset() {    //重置信道    $this-&amp;gt;objChannel = null;    //计数，当channel超过一定数量后重置连接    if ($this-&amp;gt;intCurChannelNum &amp;gt;= 10000) {        $this-&amp;gt;intCurChannelNum = 0;        $this-&amp;gt;objConnection = null;    }    $this-&amp;gt;intCurChannelNum += 1;    //计时，当连接闲置一段时间后重置连接    if (!is_null($this-&amp;gt;intLastConnectTime) &amp;amp;&amp;amp; (time() - $this-&amp;gt;intLastConnectTime &amp;gt;= 2 * $this-&amp;gt;intHeartbeat - 2)) {        $this-&amp;gt;objConnection = null;    }    //刷新连接最近使用时间    $this-&amp;gt;intLastConnectTime = time();}参数绑定问题1.死信队列绑定参数失败在测试死信队列时，想给queue绑定x-dead-letter-exchange，出现如下异常。PHP Fatal error:  Uncaught exception &#39;Lib\\PhpAmqpLib\\Exception\\AMQPProtocolChannelException&#39; with message &#39;PRECONDITION_FAILED - inequivalent arg &#39;x-dead-letter-exchange&#39; for queue &#39;queue_rpc_fibonacci&#39; in vhost &#39;/&#39;: received the value &#39;amq.direct&#39; of type &#39;longstr&#39; but current is none&#39; in /vagrant/htdocs/RabbitMQStudy/Lib/PhpAmqpLib/Channel/AMQPChannel.php:188大意是已存在的queue的x-dead-letter-exchange与想设置的queue的x-dead-letter-exchange不一致解决方法：在web管理端发现已存在一个同名的queue且没有设置queue的x-dead-letter-exchange参数，删除已存在的queue或者新的queue取一个别的名字。应用层问题思考1.消息重复消费场景  场景1：消费者从队列中获取到消息后，相关业务处理结束，但之后消费者异常，导致消息未确认消费。  场景2：消费者从队列中获取到消息后，消费者与服务器连接断开，导致消息未确认消费。解决思路  1.对消息增加全局唯一ID，在消费者消费后将id记录到redis  2.每次在消费之前检测redis是否存在id，存在不进行业务处理（可通知开发者），直接确认消费其它思考  1.因为消费者的异常可能出现在任何时候，所以感觉不能100%保证幂等性。  2.消息id记录到redis之后量会很大，可能考虑设置过期时间2.消费者死机场景  场景1：消费者获取到消息后，内部出现如死循环之类的bug，一直占用消息，导致消息不能被消费解决思路  1.在消费者的逻辑内，自己实现超时机制  2.在连接服务器时，增加心跳参数，让服务器可以主动断开连接，让消息重回队列其它思考  1.其中也可能会遇到重复消费的问题，可参考消息重复消费的解决方法参考资料幂等性消息重复消费"
  },
  
  {
    "title": "RabbitMQ学习-环境准备",
    "url": "/posts/1-rabbitmq-study-prepare-environment/",
    "categories": "",
    "tags": "rabbitmq",
    "date": "2018-05-08 13:50:00 +0800",
    





    "snippet": "  介绍RabbitMQ及其依赖erlang的安装。下载并安装erlang1.下载安装文件可去erlang官网查看可用版本，这里安装最新版本。[root@iZwz9i8fd8lio2yh3oerizZ /]# cd /bmsource[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# wget http://erlang.org/download/otp_src_20.3.tar.gz解压安装文件[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# tar -xvf otp_src_20.3.tar.gz2.完成安装将erlang安装到/usr/local/erlang目录。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# cd otp_src_20.3[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# ./configure --prefix=/usr/local/erlang configure: error: No curses library functions foundconfigure: error: /bin/sh &#39;/bmsource/otp_src_20.3/erts/configure&#39; failed for erts出现error信息，提示没有找到curses类，这里需要安装一下。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# yum install ncurses-devel继续安装。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# ./configure --prefix=/usr/local/erlang [root@iZwz9i8fd8lio2yh3oerizZ bmsource]# make &amp;amp;&amp;amp; make install等待一段时间后，安装完成，可以在/usr/local/erlang/看到相关信息。[root@iZwz9i8fd8lio2yh3oerizZ otp_src_20.3]# ll /usr/local/erlang/total 8drwxr-xr-x. 2 root root 4096 May  8 07:05 bindrwxr-xr-x. 3 root root 4096 May  8 07:04 lib测试erlang是否可正常使用。[root@iZwz9i8fd8lio2yh3oerizZ otp_src_20.3]# /usr/local/erlang/bin/erlErlang/OTP 20 [erts-9.3] [source] [64-bit] [smp:1:1] [ds:1:1:10] [async-threads:10] [hipe] [kernel-poll:false]Eshell V9.3  (abort with ^G)1&amp;gt; 3.环境变量为了以后可以方便使用，将erlang路径配置到环境变量中。修改/etc/profile文件，在最后加入如下配置，然后使配置生效。export ERLANG_HOME=/usr/local/erlangexport PATH=$ERLANG_HOME/bin:$PATH[root@iZwz9i8fd8lio2yh3oerizZ otp_src_20.3]# vim /etc/profile[root@iZwz9i8fd8lio2yh3oerizZ otp_src_20.3]# source /etc/profile可以直接通过erl进行使用。[root@iZwz9i8fd8lio2yh3oerizZ otp_src_20.3]# erlerl   erlc  [root@vagrant otp_src_20.3]# erlErlang/OTP 20 [erts-9.3] [source] [64-bit] [smp:1:1] [ds:1:1:10] [async-threads:10] [hipe] [kernel-poll:false]Eshell V9.3  (abort with ^G)1&amp;gt; 下载并安装RabbitMQ这里使用绿色包的方式来安装，如果需要通过rpm方式，可去RabbitMQ官网查看。1.下载安装文件可去RabbitMQ的Git查询可用版本，这里使用最新版本。注意使用带generic-unix标识的。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-generic-unix-3.6.15.tar.xz解压文件，需要先使用xz，如果没有安装一下。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# yum install xz[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# xz -d rabbitmq-server-generic-unix-3.6.15.tar.xz[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# tar -xvf rabbitmq-server-generic-unix-3.6.15.tar2.完成安装将解压好的文件复制到/usr/local即可。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# cp -R rabbitmq_server-3.6.15/ /usr/local/rabbitmq3.环境变量为了以后可以方便使用，将rabbitmq路径配置到环境变量中。修改/etc/profile文件，在最后加入如下配置，然后使配置生效。export PATH=/usr/local/rabbitmq/sbin:$PATH[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# vim /etc/profile[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# source /etc/profile4.工作文件夹rabbitmq正常工作使用如下2个文件夹，通常在运行rabbitmq服务时，会自动创建出来，不需要手动创建。日志文件夹用于存储rabbitmq的运行日志。/usr/local/rabbitmq/var/log/rabbitmq数据文件夹rabbitmq使用mnesia数据库存储服务器信息，如队列元数据，虚拟主机等。/usr/local/rabbitmq/var/lib/rabbitmq/mnesia/节点名称"
  },
  
  {
    "title": "升级php版本从7.1.0到7.2.5",
    "url": "/posts/upgrading-php7.1.0-to-php7.2.5/",
    "categories": "",
    "tags": "php, linux",
    "date": "2018-05-06 20:30:00 +0800",
    





    "snippet": "  最近需要学习lavavel框架，框架需要php7.1.10以上的版本，所以将阿里云机器上的php进行升级，这里记录一下升级的过程。下载并安装php7.2.51.下载安装文件-O：表示将下载后的文件进行重命名[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# wget http://am1.php.net/get/php-7.2.5.tar.bz2/from/this/mirror -O php-7.2.5.tar.bz2解压安装文件[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# tar -xvf php-7.2.5.tar.bz2 2.获取7.1.0版本的configure这次只是php版本的升级，希望所有的扩展需求同7.1.0版本的，所以这里获取一下7.1.0安装的配置信息。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# php -i|grep configureConfigure Command =&amp;gt;  &#39;./configure&#39;  &#39;--prefix=/usr/local/php &#39;--with-apxs2=/www/bin/apxs&#39; &#39;--with-curl&#39; &#39;--with-freetype-dir&#39; &#39;--with-gd&#39; &#39;--with-gettext&#39; &#39;--with-iconv-dir&#39; &#39;--with-kerberos&#39; &#39;--with-libdir=lib64&#39; &#39;--with-libxml-dir&#39; &#39;--with-mysqli&#39; &#39;--with-openssl&#39; &#39;--with-pcre-regex&#39; &#39;--with-pdo-mysql&#39; &#39;--with-pdo-sqlite&#39; &#39;--with-pear&#39; &#39;--with-png-dir&#39; &#39;--with-xmlrpc&#39; &#39;--with-xsl&#39; &#39;--with-zlib&#39; &#39;--enable-fpm&#39; &#39;--enable-bcmath&#39; &#39;--enable-libxml&#39; &#39;--enable-inline-optimization&#39; &#39;--enable-gd-native-ttf&#39; &#39;--enable-mbregex&#39; &#39;--enable-mbstring&#39; &#39;--enable-opcache&#39; &#39;--enable-pcntl&#39; &#39;--enable-shmop&#39; &#39;--enable-soap&#39; &#39;--enable-sockets&#39; &#39;--enable-sysvsem&#39; &#39;--enable-xml&#39; &#39;--enable-zip&#39;3.完成安装通过上面获取到的配置可知，7.1.0版本的安装位置为/usr/local/php，所以将新版本安装到/usr/local/php7.2.5。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# cd php-7.2.5[root@iZwz9i8fd8lio2yh3oerizZ bmsource]#  ./configure --prefix=/usr/local/php7.2.5 --with-apxs2=/www/bin/apxs  --with-curl  --with-freetype-dir  --with-gd  --with-gettext  --with-iconv-dir  --with-kerberos  --with-libdir=lib64  --with-libxml-dir   --with-mysqli  --with-openssl  --with-pcre-regex  --with-pdo-mysql  --with-pdo-sqlite  --with-pear  --with-png-dir  --with-xmlrpc  --with-xsl  --with-zlib  --enable-fpm  --enable-bcmath  --enable-libxml  --enable-inline-optimization  --enable-gd-native-ttf  --enable-mbregex  --enable-mbstring  --enable-opcache  --enable-pcntl  --enable-shmop  --enable-soap  --enable-sockets  --enable-sysvsem  --enable-xml  --enable-zip[root@iZwz9i8fd8lio2yh3oerizZ php-7.2.5]#  make &amp;amp;&amp;amp; make install修改配置1.php.ini因为在configure的时候加了--with-apxs2=/www/bin/apxs配置，所以php安装完成后会自动更新/www/modules/libphp7.so。这时新安装的目录中还没有php.ini配置文件，可以将原来的配置文件复制过来。[root@iZwz9i8fd8lio2yh3oerizZ php-7.2.5]# cp /usr/local/php/lib/php.ini /usr/local/php7.2.5/lib/php.ini2.环境变量使用php -v查看版本，发现还是之前的版本，此时需要修改PATH变量，将php路径修改为新版本的路径。[root@iZwz9i8fd8lio2yh3oerizZ ~]# php -vPHP 7.1.0 (cli) (built: May  5 2018 15:38:09) ( ZTS )Copyright (c) 1997-2018 The PHP GroupZend Engine v3.2.0, Copyright (c) 1998-2018 Zend Technologies查看当前PATH变量信息。[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# env |grep PATHPATH=/usr/local/php/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin方法1：export直接设置，注意这里是替换原来php的目录[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# export PATH=&#39;/usr/local/php7.2.5/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin&#39;方法2：如果以前环境变量还没有，可以修改/etc/profile文件，在最后一行加入配置export PATH=&quot;/usr/local/php7.2.5/bin:$PATH&quot;，表示在原有设置的基础上增加新的设置。[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# vim /etc/profile重新编译第三方扩展如果使用了原php版本编译的扩展，因为php升级了，所以相应的扩展也需要重新编译。1.redis扩展php-redis扩展注意：phpize与php-config需要使用新版本的。[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# tar -xvf redis-3.1.2.tgz [root@iZwz9i8fd8lio2yh3oerizZ bmsource]# cd redis-3.1.2[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# phpize[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# ./configure --with-php-config=/usr/local/php7.2.5/bin/php-config[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# make &amp;amp;&amp;amp; make install将新编译的扩展，复制到php加载的扩展目录。[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# cp /usr/local/php7.2.5/lib/php/extensions/no-debug-zts-20170718/redis.so /www/modules/redis7.2.5.so修改php.ini使用新的扩展，extension=redis7.2.5.so。[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# vim /usr/local/php7.2.5/lib/php.ini 2.mcrypt扩展注意：phpize与php-config需要使用新版本的。[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2] cd /bmsource/[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# wget http://pecl.php.net/get/mcrypt-1.0.1.tgz[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# tar -xvf mcrypt-1.0.1.tgz[root@iZwz9i8fd8lio2yh3oerizZ bmsource]# cd mcrypt-1.0.1[root@iZwz9i8fd8lio2yh3oerizZ mcrypt-1.0.1]# phpize[root@iZwz9i8fd8lio2yh3oerizZ mcrypt-1.0.1]# ./configure --with-php-config=/usr/local/php7.2.5/bin/php-config[root@iZwz9i8fd8lio2yh3oerizZ mcrypt-1.0.1]# make &amp;amp;&amp;amp; make install将新编译的扩展，复制到php加载的扩展目录。[root@iZwz9i8fd8lio2yh3oerizZ mcrypt-1.0.1]# cp /usr/local/php7.2.5/lib/php/extensions/no-debug-zts-20170718/mcrypt.so /www/modules/mcrypt7.2.5.so修改php.ini使用新的扩展，extension=mcrypt7.2.5.so。[root@iZwz9i8fd8lio2yh3oerizZ redis-3.1.2]# vim /usr/local/php7.2.5/lib/php.ini "
  }
  
]

